#!/usr/bin/env python3
"""
FFHQæ ‡å‡†äººè„¸å¯¹é½å™¨
åŸºäºå®˜æ–¹FFHQæ•°æ®é›†é¢„å¤„ç†ç®—æ³•ï¼Œä½¿ç”¨dlib 68ç‚¹å…³é”®ç‚¹æ£€æµ‹
ä¸“ä¸ºHyperStyle + StyleGAN2ä¼˜åŒ–
"""

import numpy as np
import PIL.Image
import scipy.ndimage
import dlib
import cv2
import os
from typing import Optional, Union

class FFHQFaceAligner:
    def __init__(self, 
                 predictor_path: str = "./models/shape_predictor_68_face_landmarks.dat",
                 output_size: int = 1024,
                 transform_size: int = 4096,
                 enable_padding: bool = True):
        """
        åˆå§‹åŒ–FFHQæ ‡å‡†äººè„¸å¯¹é½å™¨
        
        Args:
            predictor_path: dlib 68ç‚¹å…³é”®ç‚¹æ£€æµ‹å™¨æ¨¡å‹è·¯å¾„
            output_size: è¾“å‡ºå›¾åƒå°ºå¯¸
            transform_size: ä¸­é—´å˜æ¢å°ºå¯¸
            enable_padding: æ˜¯å¦å¯ç”¨è¾¹ç•Œå¡«å……
        """
        self.output_size = output_size
        self.transform_size = transform_size
        self.enable_padding = enable_padding
        
        # æ£€æŸ¥dlibæ¨¡å‹æ–‡ä»¶
        if not os.path.exists(predictor_path):
            raise FileNotFoundError(
                f"dlibæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {predictor_path}\n"
                f"è¯·ä»ä»¥ä¸‹é“¾æ¥ä¸‹è½½:\n"
                f"http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2"
            )
        
        # åˆå§‹åŒ–dlibæ£€æµ‹å™¨
        self.detector = dlib.get_frontal_face_detector()
        self.predictor = dlib.shape_predictor(predictor_path)
        
        print("âœ… FFHQæ ‡å‡†äººè„¸å¯¹é½å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def get_landmarks(self, image_path: str) -> Optional[np.ndarray]:
        """
        ä½¿ç”¨dlibæå–68ä¸ªå…³é”®ç‚¹
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            
        Returns:
            landmarks: shape=(68, 2) çš„å…³é”®ç‚¹æ•°ç»„ æˆ– None
        """
        try:
            # åŠ è½½å›¾åƒ
            img = dlib.load_rgb_image(image_path)
            
            # æ£€æµ‹äººè„¸
            dets = self.detector(img, 1)
            
            if len(dets) == 0:
                print(f"âš ï¸ æœªæ£€æµ‹åˆ°äººè„¸: {os.path.basename(image_path)}")
                return None
            
            if len(dets) > 1:
                print(f"âš ï¸ æ£€æµ‹åˆ°å¤šå¼ äººè„¸ï¼Œä½¿ç”¨ç¬¬ä¸€å¼ : {os.path.basename(image_path)}")
            
            # æå–ç¬¬ä¸€å¼ äººè„¸çš„å…³é”®ç‚¹
            shape = self.predictor(img, dets[0])
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            landmarks = np.array([[p.x, p.y] for p in shape.parts()])
            
            return landmarks
            
        except Exception as e:
            print(f"âŒ å…³é”®ç‚¹æå–å¤±è´¥ {image_path}: {e}")
            return None
    
    def align_face(self, image_path: str) -> Optional[PIL.Image.Image]:
        """
        ä½¿ç”¨å®˜æ–¹FFHQç®—æ³•å¯¹é½äººè„¸
        
        Args:
            image_path: è¾“å…¥å›¾åƒè·¯å¾„
            
        Returns:
            aligned_image: å¯¹é½åçš„PILå›¾åƒ æˆ– None
        """
        try:
            # æå–å…³é”®ç‚¹
            lm = self.get_landmarks(image_path)
            if lm is None:
                return None
            
            # æŒ‰ç…§å®˜æ–¹FFHQç®—æ³•åˆ†ç»„å…³é”®ç‚¹
            lm_chin = lm[0:17]      # ä¸‹å·´è½®å»“
            lm_eyebrow_left = lm[17:22]   # å·¦çœ‰æ¯›
            lm_eyebrow_right = lm[22:27]  # å³çœ‰æ¯›
            lm_nose = lm[27:31]     # é¼»æ¢
            lm_nostrils = lm[31:36] # é¼»å­”
            lm_eye_left = lm[36:42] # å·¦çœ¼
            lm_eye_right = lm[42:48] # å³çœ¼
            lm_mouth_outer = lm[48:60] # å˜´å·´å¤–è½®å»“
            lm_mouth_inner = lm[60:68] # å˜´å·´å†…è½®å»“
            
            # è®¡ç®—å…³é”®å‡ ä½•é‡ï¼ˆå®˜æ–¹FFHQç®—æ³•ï¼‰
            eye_left = np.mean(lm_eye_left, axis=0)
            eye_right = np.mean(lm_eye_right, axis=0)
            eye_avg = (eye_left + eye_right) * 0.5
            eye_to_eye = eye_right - eye_left
            
            mouth_left = lm_mouth_outer[0]
            mouth_right = lm_mouth_outer[6]
            mouth_avg = (mouth_left + mouth_right) * 0.5
            eye_to_mouth = mouth_avg - eye_avg
            
            # é€‰æ‹©å®šå‘è£å‰ªçŸ©å½¢ï¼ˆå®˜æ–¹FFHQæ ¸å¿ƒç®—æ³•ï¼‰
            x = eye_to_eye - np.flipud(eye_to_mouth) * [-1, 1]
            x /= np.hypot(*x)
            x *= max(np.hypot(*eye_to_eye) * 2.4, np.hypot(*eye_to_mouth) * 2.2)
            y = np.flipud(x) * [-1, 1]
            c = eye_avg + eye_to_mouth * 0.05
            quad = np.stack([c - x - y, c - x + y, c + x + y, c + x - y])
            qsize = np.hypot(*x) * 2
            
            # è¯»å–åŸå§‹å›¾åƒ
            img = PIL.Image.open(image_path)
            
            # ç¼©å°å¤„ç†ï¼ˆæå‡é€Ÿåº¦ï¼‰
            shrink = int(np.floor(qsize / self.output_size * 0.5))
            if shrink > 1:
                rsize = (
                    int(np.rint(float(img.size[0]) / shrink)), 
                    int(np.rint(float(img.size[1]) / shrink))
                )
                img = img.resize(rsize, PIL.Image.LANCZOS)
                quad /= shrink
                qsize /= shrink
            
            # è£å‰ª
            border = max(int(np.rint(qsize * 0.15)), 5)
            crop = (
                int(np.floor(min(quad[:, 0]))), 
                int(np.floor(min(quad[:, 1]))), 
                int(np.ceil(max(quad[:, 0]))), 
                int(np.ceil(max(quad[:, 1])))
            )
            crop = (
                max(crop[0] - border, 0), 
                max(crop[1] - border, 0), 
                min(crop[2] + border, img.size[0]), 
                min(crop[3] + border, img.size[1])
            )
            
            if crop[2] - crop[0] < img.size[0] or crop[3] - crop[1] < img.size[1]:
                img = img.crop(crop)
                quad -= crop[0:2]
            
            # å¡«å……ï¼ˆå®˜æ–¹FFHQè¾¹ç•Œå¤„ç†ï¼‰
            pad = (
                int(np.floor(min(quad[:, 0]))), 
                int(np.floor(min(quad[:, 1]))), 
                int(np.ceil(max(quad[:, 0]))), 
                int(np.ceil(max(quad[:, 1])))
            )
            pad = (
                max(-pad[0] + border, 0), 
                max(-pad[1] + border, 0), 
                max(pad[2] - img.size[0] + border, 0), 
                max(pad[3] - img.size[1] + border, 0)
            )
            
            if self.enable_padding and max(pad) > border - 4:
                pad = np.maximum(pad, int(np.rint(qsize * 0.3)))
                img_array = np.pad(
                    np.float32(img), 
                    ((pad[1], pad[3]), (pad[0], pad[2]), (0, 0)), 
                    'reflect'
                )
                
                h, w, _ = img_array.shape
                y, x, _ = np.ogrid[:h, :w, :1]
                
                # ç¾½åŒ–è¾¹ç•Œ
                mask = np.maximum(
                    1.0 - np.minimum(np.float32(x) / pad[0], np.float32(w-1-x) / pad[2]), 
                    1.0 - np.minimum(np.float32(y) / pad[1], np.float32(h-1-y) / pad[3])
                )
                
                blur = qsize * 0.02
                img_array += (scipy.ndimage.gaussian_filter(img_array, [blur, blur, 0]) - img_array) * np.clip(mask * 3.0 + 1.0, 0.0, 1.0)
                img_array += (np.median(img_array, axis=(0,1)) - img_array) * np.clip(mask, 0.0, 1.0)
                
                img = PIL.Image.fromarray(np.uint8(np.clip(np.rint(img_array), 0, 255)), 'RGB')
                quad += pad[:2]
            
            # æœ€ç»ˆå˜æ¢åˆ°æ ‡å‡†å°ºå¯¸
            img = img.transform(
                (self.transform_size, self.transform_size), 
                PIL.Image.QUAD, 
                (quad + 0.5).flatten(), 
                PIL.Image.BILINEAR
            )
            
            if self.output_size < self.transform_size:
                img = img.resize((self.output_size, self.output_size), PIL.Image.LANCZOS)
            
            return img
            
        except Exception as e:
            print(f"âŒ äººè„¸å¯¹é½å¤±è´¥ {image_path}: {e}")
            return None
    
    def align_face_cv2(self, image_input: Union[str, np.ndarray]) -> Optional[np.ndarray]:
        """
        å¯¹é½äººè„¸å¹¶è¿”å›OpenCVæ ¼å¼ï¼ˆBGRï¼‰
        
        Args:
            image_input: å›¾åƒè·¯å¾„æˆ–numpyæ•°ç»„
            
        Returns:
            aligned_image: BGRæ ¼å¼çš„numpyæ•°ç»„ æˆ– None
        """
        if isinstance(image_input, np.ndarray):
            # ä¸´æ—¶ä¿å­˜numpyæ•°ç»„ä¸ºæ–‡ä»¶
            temp_path = "/tmp/temp_face_align.jpg"
            cv2.imwrite(temp_path, image_input)
            aligned_pil = self.align_face(temp_path)
            os.remove(temp_path)
        else:
            aligned_pil = self.align_face(image_input)
        
        if aligned_pil is None:
            return None
        
        # è½¬æ¢ä¸ºOpenCVæ ¼å¼
        aligned_rgb = np.array(aligned_pil)
        aligned_bgr = cv2.cvtColor(aligned_rgb, cv2.COLOR_RGB2BGR)
        
        return aligned_bgr
    
    def batch_align(self, image_dir: str, output_dir: str) -> list:
        """
        æ‰¹é‡å¯¹é½äººè„¸
        
        Args:
            image_dir: è¾“å…¥å›¾åƒç›®å½•
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            success_paths: æˆåŠŸå¤„ç†çš„è¾“å‡ºè·¯å¾„åˆ—è¡¨
        """
        os.makedirs(output_dir, exist_ok=True)
        
        # æ”¯æŒçš„å›¾åƒæ ¼å¼
        extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']
        image_paths = []
        
        for ext in extensions:
            image_paths.extend([
                f for f in os.listdir(image_dir) 
                if f.lower().endswith(ext.lower())
            ])
        
        success_paths = []
        
        for i, filename in enumerate(image_paths):
            input_path = os.path.join(image_dir, filename)
            print(f"ğŸ“· å¯¹é½å›¾åƒ {i+1}/{len(image_paths)}: {filename}")
            
            try:
                aligned = self.align_face(input_path)
                if aligned is None:
                    continue
                
                # ä¿å­˜å¯¹é½ç»“æœ
                name, ext = os.path.splitext(filename)
                output_path = os.path.join(output_dir, f"{name}_aligned{ext}")
                aligned.save(output_path, quality=95)
                
                success_paths.append(output_path)
                
            except Exception as e:
                print(f"âŒ å¤„ç†å¤±è´¥ {filename}: {e}")
                continue
        
        print(f"ğŸ‰ æ‰¹é‡å¯¹é½å®Œæˆ! æˆåŠŸ: {len(success_paths)}/{len(image_paths)}")
        return success_paths
    
    def verify_alignment(self, aligned_image: Union[PIL.Image.Image, np.ndarray]) -> dict:
        """
        éªŒè¯å¯¹é½è´¨é‡ï¼ˆä¸FFHQæ ‡å‡†å¯¹æ¯”ï¼‰
        
        Args:
            aligned_image: å¯¹é½åçš„å›¾åƒ
            
        Returns:
            metrics: è´¨é‡æŒ‡æ ‡å­—å…¸
        """
        try:
            # è½¬æ¢ä¸ºPILæ ¼å¼ç”¨äºéªŒè¯
            if isinstance(aligned_image, np.ndarray):
                if aligned_image.shape[2] == 3 and aligned_image.dtype == np.uint8:
                    # BGR -> RGB
                    rgb_image = cv2.cvtColor(aligned_image, cv2.COLOR_BGR2RGB)
                    pil_image = PIL.Image.fromarray(rgb_image)
                else:
                    pil_image = PIL.Image.fromarray(aligned_image)
            else:
                pil_image = aligned_image
            
            # ä¸´æ—¶ä¿å­˜ç”¨äºdlibåˆ†æ
            temp_path = "/tmp/temp_verify.jpg"
            pil_image.save(temp_path)
            
            # é‡æ–°æ£€æµ‹å…³é”®ç‚¹
            landmarks = self.get_landmarks(temp_path)
            os.remove(temp_path)
            
            if landmarks is None:
                return {'valid': False, 'error': 'æ— æ³•é‡æ–°æ£€æµ‹å…³é”®ç‚¹'}
            
            # è®¡ç®—FFHQæ ‡å‡†æŒ‡æ ‡
            eye_left = np.mean(landmarks[36:42], axis=0)
            eye_right = np.mean(landmarks[42:48], axis=0)
            mouth_left = landmarks[48]
            mouth_right = landmarks[54]
            
            # åŒçœ¼æ°´å¹³åº¦
            eye_to_eye = eye_right - eye_left
            eye_angle = abs(np.degrees(np.arctan2(eye_to_eye[1], eye_to_eye[0])))
            
            # åŒçœ¼é—´è·ï¼ˆåº”è¯¥ç¬¦åˆFFHQæ¯”ä¾‹ï¼‰
            eye_distance = np.linalg.norm(eye_to_eye)
            expected_distance = self.output_size * 0.25  # FFHQæ ‡å‡†æ¯”ä¾‹
            distance_ratio = eye_distance / expected_distance
            
            # çœ¼å˜´æ¯”ä¾‹
            mouth_center = (mouth_left + mouth_right) * 0.5
            eye_center = (eye_left + eye_right) * 0.5
            eye_to_mouth_distance = np.linalg.norm(mouth_center - eye_center)
            eye_mouth_ratio = eye_to_mouth_distance / eye_distance
            
            return {
                'valid': True,
                'eye_angle': eye_angle,
                'distance_ratio': distance_ratio,
                'eye_mouth_ratio': eye_mouth_ratio,
                'ffhq_compliant': (
                    eye_angle < 3.0 and 
                    0.85 < distance_ratio < 1.15 and
                    1.1 < eye_mouth_ratio < 1.6
                )
            }
            
        except Exception as e:
            return {'valid': False, 'error': str(e)}

def main():
    """æµ‹è¯•å‡½æ•°"""
    import sys
    
    if len(sys.argv) != 3:
        print("ç”¨æ³•: python face_aligner.py input.jpg output.jpg")
        print("è¯·ç¡®ä¿å·²ä¸‹è½½dlibæ¨¡å‹æ–‡ä»¶:")
        print("wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2")
        print("bzip2 -d shape_predictor_68_face_landmarks.dat.bz2")
        return
    
    input_path = sys.argv[1]
    output_path = sys.argv[2]
    
    try:
        # åˆ›å»ºå¯¹é½å™¨
        aligner = FFHQFaceAligner()
        
        # å¯¹é½äººè„¸
        print(f"ğŸ“· ä½¿ç”¨FFHQæ ‡å‡†ç®—æ³•å¯¹é½: {input_path}")
        aligned = aligner.align_face(input_path)
        
        if aligned is not None:
            # ä¿å­˜ç»“æœ
            aligned.save(output_path, quality=95)
            print(f"âœ… å¯¹é½å®Œæˆ: {output_path}")
            
            # éªŒè¯è´¨é‡
            metrics = aligner.verify_alignment(aligned)
            if metrics['valid']:
                print(f"ğŸ“Š FFHQæ ‡å‡†éªŒè¯: {'âœ… åˆæ ¼' if metrics['ffhq_compliant'] else 'âš ï¸  éœ€è¦è°ƒæ•´'}")
                print(f"   çœ¼éƒ¨è§’åº¦: {metrics['eye_angle']:.2f}Â°")
                print(f"   è·ç¦»æ¯”ä¾‹: {metrics['distance_ratio']:.3f}")
                print(f"   çœ¼å˜´æ¯”ä¾‹: {metrics['eye_mouth_ratio']:.3f}")
            else:
                print(f"âš ï¸ è´¨é‡éªŒè¯å¤±è´¥: {metrics['error']}")
        else:
            print("âŒ å¯¹é½å¤±è´¥")
            
    except FileNotFoundError as e:
        print(f"âŒ {e}")
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")

if __name__ == "__main__":
    main()
