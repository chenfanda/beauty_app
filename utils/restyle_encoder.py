#!/usr/bin/env python3
"""
ReStyleç¼–ç å™¨ - ç®€åŒ–ç‰ˆæœ¬
å»é™¤å†—ä½™ä»£ç ï¼Œä¿ç•™æ ¸å¿ƒåŠŸèƒ½
"""

import torch
import torch.nn as nn
import torchvision.transforms as transforms
import numpy as np
import cv2
from PIL import Image
import os
import sys
from typing import Union, Optional

class ReStyleEncoder:
    def __init__(self, 
                 model_path: str,
                 stylegan_path: str = None,
                 id_model_path: str = None,
                 device: str = 'auto',
                 n_iters: int = 5):
        """
        åˆå§‹åŒ–ReStyleç¼–ç å™¨
        """
        # è®¾å¤‡è®¾ç½®
        if device == 'auto':
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = torch.device(device)
            
        print(f"ğŸ–¥ï¸  ReStyleä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # è®¾ç½®é»˜è®¤è·¯å¾„
        if stylegan_path is None:
            script_dir = os.path.dirname(os.path.abspath(__file__))
            project_root = os.path.dirname(script_dir)
            stylegan_path = os.path.join(project_root, 'models', 'stylegan2', 'stylegan2-ffhq-config-f.pt')
        
        if id_model_path is None:
            script_dir = os.path.dirname(os.path.abspath(__file__))
            project_root = os.path.dirname(script_dir)
            id_model_path = os.path.join(project_root, 'models', 'encoders', 'model_ir_se50.pth')
        
        # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
        self._check_files(model_path, stylegan_path, id_model_path)
        
        self.n_iters = n_iters
        
        # è®¾ç½®ç¯å¢ƒ
        self._setup_environment()
        
        # åŠ è½½æ¨¡å‹
        self.model, self.opts = self._load_restyle_model(model_path)
        self.generator, self.latent_avg = self._load_stylegan2(stylegan_path)
        self.id_loss = self._load_id_loss_model(id_model_path) if self.use_id_loss else None
        
        # é¢„å¤„ç†å˜æ¢
        self.transform = transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.ToTensor(),
            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
        ])
        
        print(f"âœ… ReStyleç¼–ç å™¨åˆå§‹åŒ–å®Œæˆ (è¿­ä»£æ¬¡æ•°: {n_iters}, ID loss: {'å¯ç”¨' if self.use_id_loss else 'ç¦ç”¨'})")
    
    def _check_files(self, model_path: str, stylegan_path: str, id_model_path: str):
        """æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å­˜åœ¨æ€§"""
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"ReStyleæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        
        if not os.path.exists(stylegan_path):
            raise FileNotFoundError(f"StyleGAN2æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {stylegan_path}")
        
        self.use_id_loss = os.path.exists(id_model_path)
        if self.use_id_loss:
            self.id_model_path = id_model_path
            print(f"âœ… å°†ä½¿ç”¨ID lossæ¨¡å‹: {os.path.basename(id_model_path)}")
        else:
            print(f"âš ï¸  ID lossæ¨¡å‹ä¸å­˜åœ¨ï¼Œå°†è·³è¿‡: {id_model_path}")
    
    def _setup_environment(self):
        """è®¾ç½®ç¯å¢ƒè·¯å¾„"""
        script_dir = os.path.dirname(os.path.abspath(__file__))
        paths_to_add = [
            os.path.join(script_dir, 'restyle-encoder'),
            os.path.join(script_dir, 'stylegan2-pytorch')
        ]
        
        for path in paths_to_add:
            if os.path.exists(path) and path not in sys.path:
                sys.path.insert(0, path)
    
    def _load_restyle_model(self, model_path: str):
        """åŠ è½½ReStyleæ¨¡å‹"""
        print(f"ğŸ“¥ åŠ è½½ReStyleæ¨¡å‹: {os.path.basename(model_path)}")
        
        from models.e4e import e4e
        from argparse import Namespace
        
        # åŠ è½½æ£€æŸ¥ç‚¹
        ckpt = torch.load(model_path, map_location=self.device)
        
        # è·å–é…ç½®
        opts = ckpt.get('opts', {})
        if isinstance(opts, dict):
            # è®¾ç½®å¿…è¦çš„é…ç½®é¡¹
            opts.update({
                'n_iters_per_batch': self.n_iters,
                'resize_outputs': False,
                'start_from_latent_avg': True,
                'checkpoint_path': model_path
            })
            opts = Namespace(**opts)
        else:
            opts.checkpoint_path = model_path
        
        # åˆ›å»ºå¹¶åŠ è½½æ¨¡å‹
        net = e4e(opts)
        net.load_state_dict(ckpt['state_dict'])
        net = net.to(self.device)
        net.eval()
        
        print("âœ… ReStyleæ¨¡å‹åŠ è½½å®Œæˆ")
        return net, opts
    
    def _load_stylegan2(self, stylegan_path: str):
        """åŠ è½½StyleGAN2ç”Ÿæˆå™¨"""
        print(f"ğŸ“¥ åŠ è½½StyleGAN2ç”Ÿæˆå™¨: {os.path.basename(stylegan_path)}")
        
        from model import Generator
        
        ckpt = torch.load(stylegan_path, map_location=self.device)
        
        # è·å–ç”Ÿæˆå™¨æƒé‡å’Œlatentå¹³å‡å€¼
        generator_weights = ckpt['g_ema']
        latent_avg = ckpt.get('latent_avg', None)
        
        if latent_avg is not None:
            latent_avg = latent_avg.to(self.device)
            print("ğŸ¯ æ‰¾åˆ°é¢„è®¡ç®—çš„latentå¹³å‡å€¼")
        
        # åˆ›å»ºå¹¶åŠ è½½ç”Ÿæˆå™¨
        generator = Generator(1024, 512, 8, channel_multiplier=2)
        generator.load_state_dict(generator_weights)
        generator = generator.to(self.device)
        generator.eval()
        
        print("âœ… StyleGAN2ç”Ÿæˆå™¨åŠ è½½å®Œæˆ")
        return generator, latent_avg
    
    def _load_id_loss_model(self, id_model_path: str):
        """åŠ è½½ID lossæ¨¡å‹"""
        print(f"ğŸ“¥ åŠ è½½ID lossæ¨¡å‹: {os.path.basename(id_model_path)}")
        
        try:
            from models.encoders.model_irse import Backbone
            
            class IDLoss(nn.Module):
                def __init__(self, model_path, device):
                    super(IDLoss, self).__init__()
                    self.facenet = Backbone(input_size=112, num_layers=50, drop_ratio=0.6, mode='ir_se')
                    state_dict = torch.load(model_path, map_location=device)
                    self.facenet.load_state_dict(state_dict)
                    self.facenet.eval()
                    self.pool = torch.nn.AdaptiveAvgPool2d((256, 256))
                    self.face_pool = torch.nn.AdaptiveAvgPool2d((112, 112))
                
                def extract_feats(self, x):
                    if x.shape[2] != 256:
                        x = self.pool(x)
                    x = x[:, :, 35:223, 32:220]  # è£å‰ªæ„Ÿå…´è¶£åŒºåŸŸ
                    x = self.face_pool(x)
                    return self.facenet(x)
                
                def forward(self, y_hat, y):
                    n_samples = y.shape[0]
                    y_feats = self.extract_feats(y).detach()
                    y_hat_feats = self.extract_feats(y_hat)
                    
                    loss = 0
                    for i in range(n_samples):
                        cos_sim = torch.dot(y_hat_feats[i], y_feats[i]) / (torch.norm(y_feats[i]) * torch.norm(y_hat_feats[i]))
                        loss += 1 - cos_sim
                    
                    return loss / n_samples
            
            id_loss_model = IDLoss(id_model_path, self.device).to(self.device)
            print("âœ… ID lossæ¨¡å‹åŠ è½½å®Œæˆ")
            return id_loss_model
            
        except Exception as e:
            print(f"âŒ ID lossæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return None
    
    def preprocess_image(self, image_input: Union[str, np.ndarray, Image.Image]) -> torch.Tensor:
        """é¢„å¤„ç†å›¾åƒ"""
        if isinstance(image_input, str):
            pil_image = Image.open(image_input).convert('RGB')
        elif isinstance(image_input, np.ndarray):
            rgb_image = cv2.cvtColor(image_input, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(rgb_image)
        elif isinstance(image_input, Image.Image):
            pil_image = image_input.convert('RGB')
        else:
            raise TypeError(f"ä¸æ”¯æŒçš„è¾“å…¥ç±»å‹: {type(image_input)}")
        
        tensor = self.transform(pil_image).unsqueeze(0)
        return tensor.to(self.device)
    
    def encode_image(self, image_input: Union[str, np.ndarray, Image.Image]) -> torch.Tensor:
        """ç¼–ç å›¾åƒåˆ°StyleGAN2æ½œåœ¨ç©ºé—´ - ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬"""
        # é¢„å¤„ç†å›¾åƒ
        inputs = self.preprocess_image(image_input)
        print(f"ğŸ” è¾“å…¥å¼ é‡å½¢çŠ¶: {inputs.shape}")
        
        with torch.no_grad():
            batch_size = inputs.size(0)
            
            # åˆå§‹åŒ–latent codes
            if self.latent_avg is not None:
                latent_codes = self.latent_avg.unsqueeze(0).repeat(batch_size, 18, 1)
                y_hat = self.generator([latent_codes], input_is_latent=True, randomize_noise=False)[0]
            else:
                latent_codes = torch.zeros(batch_size, 18, 512).to(self.device)
                y_hat = self.generator([latent_codes], input_is_latent=True, randomize_noise=False)[0]
            
            # è°ƒæ•´å›¾åƒå°ºå¯¸åˆ°256x256
            if y_hat.size(2) != 256:
                y_hat = torch.nn.functional.interpolate(y_hat, size=(256, 256), mode='bilinear', align_corners=False)
            
            # è¿­ä»£ä¼˜åŒ–
            for iter_idx in range(self.n_iters):
                # å‡†å¤‡è¾“å…¥ï¼š[åŸå§‹å›¾åƒ, å½“å‰é‡å»ºå›¾åƒ]
                inputs_iter = torch.cat([inputs, y_hat], dim=1)
                
                # é€šè¿‡ç¼–ç å™¨è·å–latentåç§»
                delta_latents = self.model.encoder(inputs_iter)
                delta_latents = delta_latents.view(batch_size, 18, 512)
                
                # æ›´æ–°latent codes
                latent_codes = latent_codes + delta_latents
                
                # ç”Ÿæˆæ–°å›¾åƒ
                y_hat = self.generator([latent_codes], input_is_latent=True, randomize_noise=False)[0]
                
                # è°ƒæ•´å›¾åƒå°ºå¯¸
                if y_hat.size(2) != 256:
                    y_hat = torch.nn.functional.interpolate(y_hat, size=(256, 256), mode='bilinear', align_corners=False)
                
                print(f"ğŸ”„ å®Œæˆè¿­ä»£ {iter_idx + 1}/{self.n_iters}")
            
            # è®¡ç®—ID lossï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.id_loss is not None:
                try:
                    id_loss_value = self.id_loss(y_hat, inputs)
                    print(f"ğŸ“Š ID loss: {float(id_loss_value):.4f}")
                except Exception as e:
                    print(f"âš ï¸  ID lossè®¡ç®—å¤±è´¥: {e}")
            
            # æå–æœ€ç»ˆçš„latent codes
            final_latent = latent_codes[0] if batch_size == 1 else latent_codes
            
        print(f"âœ… è·å¾—æ½œåœ¨å‘é‡ï¼Œå½¢çŠ¶: {final_latent.shape}")
        return final_latent
    
    def save_latent(self, latent: torch.Tensor, save_path: str):
        """ä¿å­˜æ½œåœ¨å‘é‡"""
        save_dir = os.path.dirname(save_path)
        if save_dir:
            os.makedirs(save_dir, exist_ok=True)
        
        if len(latent.shape) == 2:
            latent = latent.unsqueeze(0)
            
        save_data = {
            'latent': latent.cpu(),
            'shape': list(latent.shape),
            'encoder': 'restyle',
            'n_iters': self.n_iters
        }
        
        torch.save(save_data, save_path)
        print(f"ğŸ’¾ æ½œåœ¨å‘é‡ä¿å­˜åˆ°: {save_path}")
    
    def encode_and_save(self, image_path: str, output_path: str) -> bool:
        """ç¼–ç å›¾åƒå¹¶ä¿å­˜"""
        try:
            latent = self.encode_image(image_path)
            self.save_latent(latent, output_path)
            return True
        except Exception as e:
            print(f"âŒ ç¼–ç ä¿å­˜å¤±è´¥: {e}")
            return False

def main():
    """æµ‹è¯•å‡½æ•°"""
    if len(sys.argv) < 4:
        print("ç”¨æ³•: python restyle_encoder.py model.pt input.jpg output.pt [--iters N]")
        return
    
    model_path = sys.argv[1]
    input_path = sys.argv[2]
    output_path = sys.argv[3]
    
    # è§£æè¿­ä»£æ¬¡æ•°
    n_iters = 5
    if '--iters' in sys.argv:
        iters_idx = sys.argv.index('--iters')
        if iters_idx + 1 < len(sys.argv):
            n_iters = int(sys.argv[iters_idx + 1])
    
    try:
        encoder = ReStyleEncoder(model_path, n_iters=n_iters)
        if encoder.encode_and_save(input_path, output_path):
            print("âœ… ç¼–ç å®Œæˆ!")
        else:
            print("âŒ ç¼–ç å¤±è´¥!")
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")

if __name__ == "__main__":
    main()
