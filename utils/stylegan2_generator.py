#!/usr/bin/env python3
"""
StyleGAN2å›¾åƒç”Ÿæˆå™¨
ä»æ½œåœ¨å‘é‡ç”Ÿæˆé«˜è´¨é‡äººè„¸å›¾åƒ
"""

import torch
import torch.nn as nn
import numpy as np
import cv2
from PIL import Image
import pickle
import os
from typing import Union, Optional

class StyleGAN2Generator:
    def __init__(self, 
                 model_path: str,
                 device: str = 'auto',
                 truncation_psi: float = 0.7):
        """
        åˆå§‹åŒ–StyleGAN2ç”Ÿæˆå™¨
        
        Args:
            model_path: StyleGAN2æ¨¡å‹æ–‡ä»¶è·¯å¾„ (.pkl æˆ– .pt)
            device: è®¡ç®—è®¾å¤‡
            truncation_psi: æˆªæ–­å‚æ•°ï¼Œæ§åˆ¶ç”Ÿæˆå¤šæ ·æ€§ (0.0-1.0)
        """
        # è®¾å¤‡è®¾ç½®
        if device == 'auto':
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = torch.device(device)
            
        print(f"ğŸ–¥ï¸  StyleGAN2ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        self.truncation_psi = truncation_psi
        
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"StyleGAN2æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        
        # åŠ è½½ç”Ÿæˆå™¨
        self.generator = self.load_generator(model_path)
        
        # Wç©ºé—´å¹³å‡å€¼ï¼ˆç”¨äºæˆªæ–­ï¼‰
        self.w_avg = None
        if truncation_psi < 1.0:
            self.compute_w_avg()
        
        print("âœ… StyleGAN2ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def load_generator(self, model_path: str) -> nn.Module:
        """
        åŠ è½½StyleGAN2ç”Ÿæˆå™¨
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
            
        Returns:
            generator: StyleGAN2ç”Ÿæˆå™¨
        """
        try:
            print(f"ğŸ“¥ åŠ è½½StyleGAN2æ¨¡å‹: {os.path.basename(model_path)}")
            
            file_ext = os.path.splitext(model_path)[1].lower()
            
            if file_ext == '.pkl':
                # å®˜æ–¹pickleæ ¼å¼ - éœ€è¦ç‰¹æ®Šå¤„ç†
                try:
                    # æ–¹æ³•1: æ ‡å‡†pickleåŠ è½½ï¼ˆé€‚ç”¨äºå®˜æ–¹StyleGAN2-ADA-PyTorchæ¨¡å‹ï¼‰
                    with open(model_path, 'rb') as f:
                        model_data = pickle.load(f)
                    
                    # æå–ç”Ÿæˆå™¨
                    if isinstance(model_data, dict):
                        if 'G_ema' in model_data:
                            generator = model_data['G_ema']
                        elif 'G' in model_data:
                            generator = model_data['G']
                        else:
                            raise ValueError("æ— æ³•ä»pickleæ–‡ä»¶ä¸­æ‰¾åˆ°ç”Ÿæˆå™¨é”®")
                    else:
                        generator = model_data
                        
                except Exception as pickle_error:
                    print(f"âš ï¸ æ ‡å‡†pickleåŠ è½½å¤±è´¥: {pickle_error}")
                    print("ğŸ”„ å°è¯•ä½¿ç”¨legacyæ–¹æ³•åŠ è½½...")
                    
                    # æ–¹æ³•2: ä½¿ç”¨legacyåŠ è½½ï¼ˆé€‚ç”¨äºæ—§ç‰ˆæœ¬æˆ–ç‰¹æ®Šæ ¼å¼ï¼‰
                    try:
                        # è¿™éœ€è¦å®‰è£…å®˜æ–¹StyleGAN2-ADA-PyTorchçš„dnnlibå’Œtorch_utils
                        import dnnlib
                        import torch_utils
                        
                        # ä½¿ç”¨å®˜æ–¹çš„legacyåŠ è½½æ–¹æ³•
                        with open(model_path, 'rb') as f:
                            legacy_data = dnnlib.util.load_pkl(f)
                        
                        if 'G_ema' in legacy_data:
                            generator = legacy_data['G_ema']
                        elif 'G' in legacy_data:
                            generator = legacy_data['G']
                        else:
                            raise ValueError("æ— æ³•ä»legacy pickleä¸­æ‰¾åˆ°ç”Ÿæˆå™¨")
                            
                    except ImportError:
                        print("âŒ ç¼ºå°‘dnnlib/torch_utilsä¾èµ–")
                        print("ğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
                        print("   1. ä¸‹è½½å®˜æ–¹StyleGAN2-ADA-PyTorchä»“åº“")
                        print("   2. å°†dnnlibå’Œtorch_utilsç›®å½•å¤åˆ¶åˆ°é¡¹ç›®ä¸­")
                        print("   3. æˆ–è€…è½¬æ¢pklä¸ºptæ ¼å¼ä½¿ç”¨")
                        raise RuntimeError("æ— æ³•åŠ è½½StyleGAN2 pickleæ–‡ä»¶")
                    
            elif file_ext == '.pt':
                # PyTorchæ ¼å¼
                checkpoint = torch.load(model_path, map_location=self.device)
                
                if isinstance(checkpoint, dict):
                    if 'generator' in checkpoint:
                        generator = checkpoint['generator']
                    elif 'G_ema' in checkpoint:
                        generator = checkpoint['G_ema']
                    elif 'G' in checkpoint:
                        generator = checkpoint['G']
                    elif 'state_dict' in checkpoint:
                        raise NotImplementedError(
                            "éœ€è¦StyleGAN2æ¨¡å‹æ¶æ„å®šä¹‰æ¥åŠ è½½state_dictã€‚"
                            "è¯·æä¾›å®Œæ•´çš„æ¨¡å‹æ–‡ä»¶è€Œéä»…æƒé‡æ–‡ä»¶ã€‚"
                        )
                    else:
                        # å‡è®¾æ•´ä¸ªcheckpointå°±æ˜¯æ¨¡å‹
                        generator = checkpoint
                else:
                    generator = checkpoint
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹æ–‡ä»¶æ ¼å¼: {file_ext}")
            
            # ç§»åŠ¨åˆ°è®¾å¤‡å¹¶è®¾ä¸ºè¯„ä¼°æ¨¡å¼
            generator = generator.to(self.device)
            generator.eval()
            
            # éªŒè¯ç”Ÿæˆå™¨
            if not hasattr(generator, '__call__'):
                raise ValueError("åŠ è½½çš„å¯¹è±¡ä¸æ˜¯æœ‰æ•ˆçš„ç”Ÿæˆå™¨æ¨¡å‹")
            
            print("âœ… StyleGAN2æ¨¡å‹åŠ è½½å®Œæˆ")
            return generator
            
        except Exception as e:
            print(f"âŒ StyleGAN2æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("ğŸ’¡ å¸¸è§è§£å†³æ–¹æ¡ˆ:")
            print("   1. ç¡®ä¿ä½¿ç”¨å®˜æ–¹StyleGAN2-ADA-PyTorchçš„æ¨¡å‹æ–‡ä»¶")
            print("   2. æ£€æŸ¥æ˜¯å¦éœ€è¦å®‰è£…dnnlibå’Œtorch_utilsä¾èµ–")
            print("   3. å°è¯•ä½¿ç”¨.ptæ ¼å¼çš„æ¨¡å‹æ–‡ä»¶")
            raise
    
    def compute_w_avg(self, num_samples: int = 10000):
        """
        è®¡ç®—Wç©ºé—´çš„å¹³å‡å€¼ï¼ˆç”¨äºæˆªæ–­ï¼‰
        
        Args:
            num_samples: ç”¨äºè®¡ç®—å¹³å‡å€¼çš„æ ·æœ¬æ•°
        """
        try:
            print(f"ğŸ“Š è®¡ç®—Wç©ºé—´å¹³å‡å€¼ (æ ·æœ¬æ•°: {num_samples})")
            
            w_samples = []
            batch_size = 100
            
            with torch.no_grad():
                for i in range(0, num_samples, batch_size):
                    current_batch = min(batch_size, num_samples - i)
                    
                    # ç”ŸæˆéšæœºZå‘é‡
                    z = torch.randn(current_batch, 512).to(self.device)
                    
                    # æ˜ å°„åˆ°Wç©ºé—´
                    if hasattr(self.generator, 'mapping'):
                        w = self.generator.mapping(z)
                    else:
                        # å°è¯•ç›´æ¥è°ƒç”¨ç”Ÿæˆå™¨çš„mappingéƒ¨åˆ†
                        try:
                            w = self.generator.style(z)
                        except:
                            # å¦‚æœæ²¡æœ‰å•ç‹¬çš„mappingï¼Œè·³è¿‡æˆªæ–­
                            print("âš ï¸ æ— æ³•è®¿é—®mappingç½‘ç»œï¼Œè·³è¿‡æˆªæ–­è®¡ç®—")
                            return
                    
                    w_samples.append(w.cpu())
            
            # è®¡ç®—å¹³å‡å€¼
            all_w = torch.cat(w_samples, dim=0)
            self.w_avg = torch.mean(all_w, dim=0, keepdim=True).to(self.device)
            
            print("âœ… Wç©ºé—´å¹³å‡å€¼è®¡ç®—å®Œæˆ")
            
        except Exception as e:
            print(f"âš ï¸ Wå¹³å‡å€¼è®¡ç®—å¤±è´¥ï¼Œè·³è¿‡æˆªæ–­: {e}")
            self.w_avg = None
    
    def apply_truncation(self, w: torch.Tensor, psi: Optional[float] = None) -> torch.Tensor:
        """
        åº”ç”¨æˆªæ–­æŠ€å·§
        
        Args:
            w: Wç©ºé—´å‘é‡
            psi: æˆªæ–­å‚æ•°ï¼ŒNoneåˆ™ä½¿ç”¨é»˜è®¤å€¼
            
        Returns:
            truncated_w: æˆªæ–­åçš„Wå‘é‡
        """
        if psi is None:
            psi = self.truncation_psi
        
        if psi >= 1.0 or self.w_avg is None:
            return w
        
        # æˆªæ–­å…¬å¼: w_truncated = w_avg + psi * (w - w_avg)
        return self.w_avg + psi * (w - self.w_avg)
    
    def generate_from_latent(self, 
                           latent: torch.Tensor,
                           truncation_psi: Optional[float] = None,
                           return_tensor: bool = False) -> Union[Image.Image, torch.Tensor]:
        """
        ä»æ½œåœ¨å‘é‡ç”Ÿæˆå›¾åƒ
        
        Args:
            latent: æ½œåœ¨å‘é‡
            truncation_psi: æˆªæ–­å‚æ•°
            return_tensor: æ˜¯å¦è¿”å›å¼ é‡æ ¼å¼
            
        Returns:
            image: ç”Ÿæˆçš„å›¾åƒ
        """
        try:
            latent = latent.to(self.device)
            
            with torch.no_grad():
                # åº”ç”¨æˆªæ–­
                if truncation_psi is not None or self.truncation_psi < 1.0:
                    latent = self.apply_truncation(latent, truncation_psi)
                
                # ç”Ÿæˆå›¾åƒ
                if hasattr(self.generator, 'synthesis'):
                    # æ ‡å‡†StyleGAN2æ¶æ„
                    image = self.generator.synthesis(latent)
                else:
                    # å®Œæ•´ç”Ÿæˆå™¨è°ƒç”¨
                    image = self.generator(latent, None)
                
                if return_tensor:
                    return image
                else:
                    return self.tensor_to_pil(image)
                    
        except Exception as e:
            print(f"âŒ å›¾åƒç”Ÿæˆå¤±è´¥: {e}")
            raise
    
    def tensor_to_pil(self, tensor: torch.Tensor) -> Image.Image:
        """
        å°†ç”Ÿæˆçš„å¼ é‡è½¬æ¢ä¸ºPILå›¾åƒ
        
        Args:
            tensor: å›¾åƒå¼ é‡ [B, C, H, W] æˆ– [C, H, W]
            
        Returns:
            image: PILå›¾åƒ
        """
        try:
            # ç¡®ä¿æ˜¯å•å¼ å›¾åƒ
            if len(tensor.shape) == 4:
                tensor = tensor[0]  # å–ç¬¬ä¸€å¼ å›¾åƒ
            
            # ç§»åŠ¨åˆ°CPU
            tensor = tensor.cpu().detach()
            
            # StyleGAN2è¾“å‡ºèŒƒå›´é€šå¸¸æ˜¯[-1, 1]ï¼Œè½¬æ¢ä¸º[0, 1]
            tensor = (tensor + 1) / 2
            tensor = torch.clamp(tensor, 0, 1)
            
            # è½¬æ¢ä¸ºnumpy [C, H, W] -> [H, W, C]
            image_np = tensor.permute(1, 2, 0).numpy()
            
            # è½¬æ¢ä¸º0-255èŒƒå›´
            image_np = (image_np * 255).astype(np.uint8)
            
            # è½¬æ¢ä¸ºPILå›¾åƒ
            return Image.fromarray(image_np)
            
        except Exception as e:
            print(f"âŒ å¼ é‡è½¬PILå¤±è´¥: {e}")
            raise
    
    def tensor_to_cv2(self, tensor: torch.Tensor) -> np.ndarray:
        """
        å°†ç”Ÿæˆçš„å¼ é‡è½¬æ¢ä¸ºOpenCVå›¾åƒ
        
        Args:
            tensor: å›¾åƒå¼ é‡
            
        Returns:
            image: OpenCVå›¾åƒ (BGRæ ¼å¼)
        """
        # å…ˆè½¬æ¢ä¸ºPILï¼Œå†è½¬æ¢ä¸ºOpenCV
        pil_image = self.tensor_to_pil(tensor)
        
        # PIL (RGB) -> OpenCV (BGR)
        opencv_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
        
        return opencv_image
    
    def generate_and_save(self, 
                         latent_path: str, 
                         output_path: str,
                         truncation_psi: Optional[float] = None) -> bool:
        """
        ä»æ½œåœ¨å‘é‡æ–‡ä»¶ç”Ÿæˆå¹¶ä¿å­˜å›¾åƒ
        
        Args:
            latent_path: æ½œåœ¨å‘é‡æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºå›¾åƒè·¯å¾„
            truncation_psi: æˆªæ–­å‚æ•°
            
        Returns:
            success: æ˜¯å¦æˆåŠŸ
        """
        try:
            # åŠ è½½æ½œåœ¨å‘é‡
            latent_data = torch.load(latent_path, map_location=self.device)
            
            # æå–æ½œåœ¨å‘é‡
            if isinstance(latent_data, dict) and 'latent' in latent_data:
                latent = latent_data['latent']
            else:
                latent = latent_data
            
            latent = latent.to(self.device)
            
            # ç”Ÿæˆå›¾åƒ
            image = self.generate_from_latent(latent, truncation_psi)
            
            # ä¿å­˜å›¾åƒ
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©è´¨é‡
            file_ext = os.path.splitext(output_path)[1].lower()
            if file_ext in ['.jpg', '.jpeg']:
                image.save(output_path, 'JPEG', quality=95, optimize=True)
            else:
                image.save(output_path, 'PNG', optimize=True)
            
            print(f"ğŸ’¾ å›¾åƒä¿å­˜åˆ°: {output_path}")
            return True
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆä¿å­˜å¤±è´¥: {e}")
            return False
    
    def batch_generate(self, latent_dir: str, output_dir: str) -> list:
        """
        æ‰¹é‡ä»æ½œåœ¨å‘é‡ç”Ÿæˆå›¾åƒ
        
        Args:
            latent_dir: æ½œåœ¨å‘é‡ç›®å½•
            output_dir: è¾“å‡ºå›¾åƒç›®å½•
            
        Returns:
            success_paths: æˆåŠŸç”Ÿæˆçš„å›¾åƒè·¯å¾„åˆ—è¡¨
        """
        os.makedirs(output_dir, exist_ok=True)
        
        # æŸ¥æ‰¾æ‰€æœ‰æ½œåœ¨å‘é‡æ–‡ä»¶
        latent_files = [f for f in os.listdir(latent_dir) if f.endswith('.pt')]
        success_paths = []
        
        for i, filename in enumerate(latent_files):
            latent_path = os.path.join(latent_dir, filename)
            name = os.path.splitext(filename)[0]
            
            # ç§»é™¤å¯èƒ½çš„"_latent"åç¼€
            if name.endswith('_latent'):
                name = name[:-7]
            
            output_path = os.path.join(output_dir, f"{name}_generated.jpg")
            
            print(f"ğŸ¨ ç”Ÿæˆå›¾åƒ {i+1}/{len(latent_files)}: {filename}")
            
            if self.generate_and_save(latent_path, output_path):
                success_paths.append(output_path)
        
        print(f"ğŸ‰ æ‰¹é‡ç”Ÿæˆå®Œæˆ! æˆåŠŸ: {len(success_paths)}/{len(latent_files)}")
        return success_paths
    
    def generate_random_image(self, 
                            seed: Optional[int] = None,
                            truncation_psi: Optional[float] = None) -> Image.Image:
        """
        ç”Ÿæˆéšæœºå›¾åƒ
        
        Args:
            seed: éšæœºç§å­
            truncation_psi: æˆªæ–­å‚æ•°
            
        Returns:
            image: ç”Ÿæˆçš„éšæœºå›¾åƒ
        """
        if seed is not None:
            torch.manual_seed(seed)
            np.random.seed(seed)
        
        # ç”ŸæˆéšæœºZå‘é‡
        z = torch.randn(1, 512).to(self.device)
        
        # æ˜ å°„åˆ°Wç©ºé—´
        with torch.no_grad():
            if hasattr(self.generator, 'mapping'):
                w = self.generator.mapping(z)
            else:
                w = z  # å¦‚æœæ²¡æœ‰mappingï¼Œç›´æ¥ä½¿ç”¨z
        
        # ç”Ÿæˆå›¾åƒ
        return self.generate_from_latent(w, truncation_psi)
    
    def get_model_info(self) -> dict:
        """
        è·å–æ¨¡å‹ä¿¡æ¯
        
        Returns:
            info: æ¨¡å‹ä¿¡æ¯å­—å…¸
        """
        info = {
            'device': str(self.device),
            'truncation_psi': self.truncation_psi,
            'has_w_avg': self.w_avg is not None,
            'model_type': type(self.generator).__name__
        }
        
        # å°è¯•è·å–æ›´å¤šä¿¡æ¯
        try:
            if hasattr(self.generator, 'img_resolution'):
                info['resolution'] = self.generator.img_resolution
            if hasattr(self.generator, 'img_channels'):
                info['channels'] = self.generator.img_channels
            if hasattr(self.generator, 'z_dim'):
                info['z_dim'] = self.generator.z_dim
            if hasattr(self.generator, 'w_dim'):
                info['w_dim'] = self.generator.w_dim
        except:
            pass
        
        return info

def main():
    """æµ‹è¯•å‡½æ•°"""
    import sys
    
    if len(sys.argv) < 4:
        print("ç”¨æ³•:")
        print("  ä»æ½œåœ¨å‘é‡ç”Ÿæˆ: python stylegan2_generator.py model.pkl latent.pt output.jpg")
        print("  ç”Ÿæˆéšæœºå›¾åƒ: python stylegan2_generator.py model.pkl --random output.jpg [seed]")
        print("  æ‰¹é‡ç”Ÿæˆ: python stylegan2_generator.py model.pkl latent_dir/ output_dir/ --batch")
        return
    
    model_path = sys.argv[1]
    
    try:
        # åˆ›å»ºç”Ÿæˆå™¨
        generator = StyleGAN2Generator(model_path)
        
        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        info = generator.get_model_info()
        print(f"ğŸ“Š æ¨¡å‹ä¿¡æ¯: {info}")
        
        if sys.argv[2] == '--random':
            # éšæœºç”Ÿæˆæ¨¡å¼
            output_path = sys.argv[3]
            seed = int(sys.argv[4]) if len(sys.argv) > 4 else None
            
            print(f"ğŸ² ç”Ÿæˆéšæœºå›¾åƒ (ç§å­: {seed})")
            image = generator.generate_random_image(seed)
            image.save(output_path, quality=95)
            print(f"âœ… éšæœºå›¾åƒä¿å­˜åˆ°: {output_path}")
            
        elif len(sys.argv) > 4 and sys.argv[4] == '--batch':
            # æ‰¹é‡ç”Ÿæˆæ¨¡å¼
            latent_dir = sys.argv[2]
            output_dir = sys.argv[3]
            
            print(f"ğŸ“ æ‰¹é‡ç”Ÿæˆ: {latent_dir} -> {output_dir}")
            success_paths = generator.batch_generate(latent_dir, output_dir)
            print(f"âœ… æ‰¹é‡ç”Ÿæˆå®Œæˆï¼Œå…±ç”Ÿæˆ {len(success_paths)} å¼ å›¾åƒ")
            
        else:
            # å•ä¸ªæ½œåœ¨å‘é‡ç”Ÿæˆ
            latent_path = sys.argv[2]
            output_path = sys.argv[3]
            
            print(f"ğŸ¨ ä»æ½œåœ¨å‘é‡ç”Ÿæˆ: {latent_path}")
            if generator.generate_and_save(latent_path, output_path):
                print("âœ… ç”Ÿæˆå®Œæˆ!")
            else:
                print("âŒ ç”Ÿæˆå¤±è´¥!")
        
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
