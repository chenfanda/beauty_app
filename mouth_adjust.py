#!/usr/bin/env python3
"""
ä¼˜åŒ–ç‰ˆå˜´å·´è°ƒæ•´è„šæœ¬ - å®Œå…¨å¤åˆ¶é¼»å­è„šæœ¬çš„æˆåŠŸæ¨¡å¼
ä¸å†è‡ªå·±å‘æ˜ï¼Œç›´æ¥å¤ç”¨æˆåŠŸçš„ä»£ç ç»“æ„
"""

import cv2
import numpy as np
import mediapipe as mp
import argparse
import os
from typing import List, Tuple, Optional

class Mouth3DAdjustment:
    def __init__(self):
        # MediaPipeè®¾ç½®ï¼ˆå®Œå…¨å¤åˆ¶é¼»å­è„šæœ¬ï¼‰
        self.mp_face_mesh = mp.solutions.face_mesh
        self.face_mesh = self.mp_face_mesh.FaceMesh(
            static_image_mode=True,
            max_num_faces=1,
            refine_landmarks=True,
            min_detection_confidence=0.8,
            min_tracking_confidence=0.8
        )
        
        # ç›¸æœºå‚æ•°
        self.camera_matrix = None
        self.dist_coeffs = None
        
        # ğŸ¯ ä½¿ç”¨æ­£ç¡®çš„MediaPipeå˜´éƒ¨ç‚¹å®šä¹‰
        # å¤–å˜´å”‡è½®å»“ï¼šç”¨äºmaskç»˜åˆ¶å’Œä¸»è¦å˜å½¢
        self.MOUTH_OUTER = [61, 146, 91, 181, 84, 17, 314, 405, 321, 375, 291, 308]
        # å†…å˜´å”‡è½®å»“ï¼šå¯ç”¨äºé—­åˆ/å¼€å˜´åˆ¤æ–­å’Œè¾…åŠ©å˜å½¢
        self.MOUTH_INNER = [78, 95, 88, 178, 87, 14, 317, 402, 318, 324, 308, 415]
        # å˜´è§’ç‚¹ï¼ˆæœ€å¸¸ç”¨ï¼‰
        self.MOUTH_CORNERS = [61, 291]
        # é€‰æ‹©å…³é”®çš„ä¸Šä¸‹å”‡ç‚¹
        self.MOUTH_KEY_POINTS = [84, 17, 314, 405]  # ä¸Šä¸‹å”‡ä¸­å¿ƒåŒºåŸŸ
        
        # æ ‡å‡†3Dé¢éƒ¨æ¨¡å‹å…³é”®ç‚¹ï¼ˆå®Œå…¨å¤åˆ¶é¼»å­è„šæœ¬ï¼‰
        self.face_model_3d = np.array([
            [0.0, 0.0, 0.0],           # é¼»å°– (1)
            [0.0, -330.0, -65.0],      # ä¸‹å·´ (152)  
            [-225.0, 170.0, -135.0],   # å·¦çœ¼å¤–è§’ (33)
            [225.0, 170.0, -135.0],    # å³çœ¼å¤–è§’ (263)
            [-150.0, -150.0, -125.0],  # å·¦å˜´è§’ (61)
            [150.0, -150.0, -125.0],   # å³å˜´è§’ (291)
        ], dtype=np.float32)
        
        # å¯¹åº”çš„MediaPipeç´¢å¼•ï¼ˆå®Œå…¨å¤åˆ¶é¼»å­è„šæœ¬ï¼‰
        self.pnp_indices = [1, 152, 33, 263, 61, 291]
    
    def setup_camera(self, image_shape):
        """è®¾ç½®ç›¸æœºå‚æ•°ï¼ˆå®Œå…¨å¤åˆ¶é¼»å­è„šæœ¬ï¼‰"""
        h, w = image_shape[:2]
        focal_length = w
        center = (w/2, h/2)
        
        self.camera_matrix = np.array([
            [focal_length, 0, center[0]],
            [0, focal_length, center[1]],
            [0, 0, 1]
        ], dtype=np.float32)
        
        self.dist_coeffs = np.zeros((4,1), dtype=np.float32)
    
    def detect_landmarks_3d(self, image):
        """æ£€æµ‹é¢éƒ¨å…³é”®ç‚¹å¹¶è®¡ç®—3Då§¿æ€ï¼ˆå®Œå…¨å¤åˆ¶é¼»å­è„šæœ¬ï¼‰"""
        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        results = self.face_mesh.process(rgb_image)
        
        if not results.multi_face_landmarks:
            return None, None
        
        landmarks_2d = []
        h, w = image.shape[:2]
        for landmark in results.multi_face_landmarks[0].landmark:
            x = int(landmark.x * w)
            y = int(landmark.y * h)
            landmarks_2d.append([x, y])
        
        landmarks_2d = np.array(landmarks_2d, dtype=np.float32)
        
        if self.camera_matrix is None:
            self.setup_camera(image.shape)
        
        # æå–ç”¨äºPnPçš„å…³é”®ç‚¹
        image_points = []
        for idx in self.pnp_indices:
            if idx < len(landmarks_2d):
                image_points.append(landmarks_2d[idx])
        
        if len(image_points) < 6:
            print("PnPå…³é”®ç‚¹ä¸è¶³")
            return landmarks_2d, None
        
        image_points = np.array(image_points, dtype=np.float32)
        
        # PnPæ±‚è§£3Då§¿æ€
        try:
            success, rotation_vector, translation_vector = cv2.solvePnP(
                self.face_model_3d, image_points, 
                self.camera_matrix, self.dist_coeffs,
                flags=cv2.SOLVEPNP_ITERATIVE
            )
            
            if not success:
                print("PnPæ±‚è§£å¤±è´¥")
                return landmarks_2d, None
            
            return landmarks_2d, (rotation_vector, translation_vector)
            
        except Exception as e:
            print(f"PnPæ±‚è§£å¼‚å¸¸: {e}")
            return landmarks_2d, None
    
    def estimate_face_pose_3d(self, rotation_vector):
        """åŸºäº3Dæ—‹è½¬å‘é‡ä¼°è®¡é¢éƒ¨å§¿æ€ï¼ˆå®Œå…¨å¤åˆ¶é¼»å­è„šæœ¬ï¼‰"""
        if rotation_vector is None:
            return "frontal"
        
        rotation_matrix, _ = cv2.Rodrigues(rotation_vector)
        sy = np.sqrt(rotation_matrix[0,0] * rotation_matrix[0,0] + rotation_matrix[1,0] * rotation_matrix[1,0])
        
        if sy > 1e-6:
            y = np.arctan2(-rotation_matrix[2,0], sy)
        else:
            y = np.arctan2(-rotation_matrix[2,0], sy)
        
        yaw = np.degrees(y)
        print(f"3Då§¿æ€æ£€æµ‹: Yaw = {yaw:.1f}åº¦")
        
        if abs(yaw) < 15:
            return "frontal"
        elif yaw > 15:
            return "right_profile"
        else:
            return "left_profile"
    
    def create_3d_mouth_mask(self, image_shape, landmarks_2d, pose_3d):
        """åŸºäº3Då§¿æ€åˆ›å»ºæ›´ç²¾ç¡®çš„å˜´å·´maskï¼ˆå®Œå…¨å¤åˆ¶é¼»å­è„šæœ¬çš„é€»è¾‘ï¼‰"""
        h, w = image_shape[:2]
        mask = np.zeros((h, w), dtype=np.uint8)
        
        # æ”¶é›†å˜´å·´å…³é”®ç‚¹ï¼ˆä½¿ç”¨æ­£ç¡®çš„è½®å»“ç‚¹ï¼‰
        mouth_indices = self.MOUTH_OUTER  # ä½¿ç”¨å®Œæ•´çš„å¤–å˜´å”‡è½®å»“
        mouth_points = []
        
        for idx in mouth_indices:
            if idx < len(landmarks_2d):
                mouth_points.append(landmarks_2d[idx])
        
        if len(mouth_points) >= 3:
            mouth_points = np.array(mouth_points, dtype=np.int32)
            hull = cv2.convexHull(mouth_points)
            
            # è®¡ç®—å˜´å·´çš„å®é™…å°ºå¯¸
            mouth_center = np.mean(hull.reshape(-1, 2), axis=0)
            mouth_width = np.max(hull[:, :, 0]) - np.min(hull[:, :, 0])
            mouth_height = np.max(hull[:, :, 1]) - np.min(hull[:, :, 1])
            
            print(f"å˜´å·´å°ºå¯¸: {mouth_width:.0f}x{mouth_height:.0f}åƒç´ ")
            
            # 3Då§¿æ€è‡ªé€‚åº”æ‰©å±•ï¼ˆå®Œå…¨å¤åˆ¶é¼»å­è„šæœ¬ï¼‰
            if pose_3d == "frontal":
                horizontal_expand = 1.6
                vertical_expand = 1.6
            else:  # ä¾§è„¸
                horizontal_expand = 1.3
                vertical_expand = 1.3
            
            # æ ¹æ®å›¾ç‰‡å°ºå¯¸è°ƒæ•´ï¼ˆå®Œå…¨å¤åˆ¶é¼»å­è„šæœ¬ï¼‰
            total_pixels = h * w
            if total_pixels > 1000000:  # å¤§å›¾
                horizontal_expand *= 1.1
                vertical_expand *= 1.05
            elif total_pixels < 100000:  # å°å›¾
                horizontal_expand *= 0.9
                vertical_expand *= 0.95
            
            # åˆ†åˆ«å¤„ç†æ°´å¹³å’Œå‚ç›´æ–¹å‘çš„æ‰©å±•
            expanded_hull = []
            for point in hull.reshape(-1, 2):
                dx = point[0] - mouth_center[0]
                dy = point[1] - mouth_center[1]
                
                new_x = mouth_center[0] + dx * horizontal_expand
                new_y = mouth_center[1] + dy * vertical_expand
                
                expanded_hull.append([new_x, new_y])
            
            expanded_hull = np.array(expanded_hull, dtype=np.int32)
            
            # è¿›ä¸€æ­¥é™åˆ¶å‚ç›´æ‰©å±•ï¼ˆå®Œå…¨å¤åˆ¶é¼»å­è„šæœ¬ï¼‰
            min_y = np.min(expanded_hull[:, 1])
            max_y = np.max(expanded_hull[:, 1])
            
            max_vertical_expansion = mouth_height * 1.2
            
            if (max_y - min_y) > mouth_height + max_vertical_expansion:
                center_y = (min_y + max_y) / 2
                target_height = mouth_height + max_vertical_expansion
                
                for i, point in enumerate(expanded_hull):
                    if point[1] < center_y:
                        expanded_hull[i][1] = max(point[1], center_y - target_height/2)
                    else:
                        expanded_hull[i][1] = min(point[1], center_y + target_height/2)
            
            cv2.fillPoly(mask, [expanded_hull], 255)
            
            # éªŒè¯maskä¸ä¼šå½±å“åˆ°çœ¼ç›å’Œé¼»å­ï¼ˆå®Œå…¨å¤åˆ¶é¼»å­è„šæœ¬çš„è¾¹ç•Œä¿æŠ¤é€»è¾‘ï¼‰
            eye_y = min(landmarks_2d[33][1], landmarks_2d[263][1])
            nose_y = landmarks_2d[1][1] if 1 < len(landmarks_2d) else h//3
            chin_y = landmarks_2d[152][1] if 152 < len(landmarks_2d) else h*2//3
            
            mask_top = np.min(expanded_hull[:, 1])
            mask_bottom = np.max(expanded_hull[:, 1])
            
            # è¾¹ç•Œä¿æŠ¤ï¼ˆå®Œå…¨å¤åˆ¶é¼»å­è„šæœ¬ï¼‰
            if mask_top < eye_y + 10:
                mask[:int(eye_y + 10), :] = 0
                print("âš ï¸  Maskä¸Šè¾¹ç•Œè£å‰ªï¼Œé¿å…å½±å“çœ¼éƒ¨")
            
            if mask_bottom > chin_y - 5:
                mask[int(chin_y - 5):, :] = 0
                print("âš ï¸  Maskä¸‹è¾¹ç•Œè£å‰ªï¼Œé¿å…å½±å“ä¸‹å·´")
            
            print(f"3D Mask: å§¿æ€={pose_3d}, æ°´å¹³æ‰©å±•={horizontal_expand:.1f}x, å‚ç›´æ‰©å±•={vertical_expand:.1f}x")
        
        return mask
    
    def apply_3d_mouth_transform(self, image, landmarks_2d, pose_info, transform_type="thickness", intensity=0.3):
        """åº”ç”¨3Dæ„ŸçŸ¥çš„å˜´å·´å˜å½¢ï¼ˆå®Œå…¨å¤åˆ¶é¼»å­è„šæœ¬çš„ç»“æ„ï¼‰"""
        if pose_info is None:
            print("3Då§¿æ€ä¿¡æ¯æ— æ•ˆï¼Œä½¿ç”¨2Dæ¨¡å¼")
            return image
        
        rotation_vector, translation_vector = pose_info
        pose_3d = self.estimate_face_pose_3d(rotation_vector)
        
        # 3Då§¿æ€è‡ªé€‚åº”å¼ºåº¦è°ƒæ•´ï¼ˆé™ä½è¡°å‡ï¼‰
        if pose_3d != "frontal":
            intensity = intensity * 0.9  # é™ä½è¡°å‡ï¼šä»0.7æ”¹ä¸º0.9
            print(f"3Dä¾§è„¸æ£€æµ‹ï¼Œå¼ºåº¦è°ƒæ•´åˆ°: {intensity:.2f}")
        else:
            print(f"3Dæ­£è„¸æ£€æµ‹ï¼Œå¼ºåº¦ä¿æŒ: {intensity:.2f}")
        
        # æ„å»ºå˜å½¢æ§åˆ¶ç‚¹
        src_points = []
        dst_points = []
        
        if transform_type == "thickness":
            # å˜´å”‡å¢åšï¼šä½¿ç”¨å¤–å˜´å”‡è½®å»“çš„å…³é”®ç‚¹
            print(f"å˜´å”‡å¢åš - æ­£ç¡®å¤–è½®å»“ç‚¹: {pose_3d}")
            
            # è®¡ç®—å˜´å·´ä¸­å¿ƒï¼ˆç”¨å˜´è§’ï¼‰
            mouth_center = np.array([(landmarks_2d[61][0] + landmarks_2d[291][0]) / 2,
                                   (landmarks_2d[61][1] + landmarks_2d[291][1]) / 2])
            
            # ä½¿ç”¨å˜´è§’ + å…³é”®çš„ä¸Šä¸‹å”‡ç‚¹
            for idx in self.MOUTH_CORNERS + self.MOUTH_KEY_POINTS:
                if idx < len(landmarks_2d):
                    point = landmarks_2d[idx]
                    src_points.append(point)
                    
                    # å‘å¤–æ‰©å±•
                    vec = point - mouth_center
                    expansion_factor = 1 + intensity * 0.4
                    new_point = mouth_center + vec * expansion_factor
                    dst_points.append(new_point)
        
        elif transform_type == "enlarge":
            # å˜´å·´æ”¾å¤§ï¼šä½¿ç”¨æ›´å¤šå¤–è½®å»“ç‚¹
            print(f"å˜´å·´æ”¾å¤§ - å¤–è½®å»“8ç‚¹: {pose_3d}")
            
            # é€‰æ‹©å¤–è½®å»“çš„8ä¸ªå…³é”®ç‚¹
            key_outer_points = [61, 146, 91, 84, 17, 314, 375, 291]
            
            # è®¡ç®—ä¸­å¿ƒ
            all_points = []
            for idx in key_outer_points:
                if idx < len(landmarks_2d):
                    all_points.append(landmarks_2d[idx])
            mouth_center = np.mean(all_points, axis=0)
            
            # æ‰€æœ‰ç‚¹å‘å¤–æ‰©å±•
            for idx in key_outer_points:
                if idx < len(landmarks_2d):
                    point = landmarks_2d[idx]
                    src_points.append(point)
                    
                    vec = point - mouth_center
                    scale_factor = 1 + intensity * 0.5
                    new_point = mouth_center + vec * scale_factor
                    dst_points.append(new_point)
        
        elif transform_type == "corners":
            # å˜´è§’æŠ¬å‡ï¼šåªç§»åŠ¨å˜´è§’
            print(f"å˜´è§’æŠ¬å‡ - çº¯å˜´è§’: {pose_3d}")
            
            # ç§»åŠ¨å˜´è§’
            for idx in self.MOUTH_CORNERS:
                if idx < len(landmarks_2d):
                    point = landmarks_2d[idx]
                    src_points.append(point)
                    lift_amount = intensity * 20
                    new_point = [point[0], point[1] - lift_amount]
                    dst_points.append(new_point)
            
            # å…³é”®ç‚¹ä¿æŒç¨³å®š
            for idx in self.MOUTH_KEY_POINTS:
                if idx < len(landmarks_2d):
                    src_points.append(landmarks_2d[idx])
                    dst_points.append(landmarks_2d[idx])
        
        elif transform_type == "resize":
            # å˜´å·´ç¼©å°ï¼šä½¿ç”¨å¤–è½®å»“å…³é”®ç‚¹
            print(f"å˜´å·´ç¼©å° - å¤–è½®å»“æ”¶ç¼©: {pose_3d}")
            
            # ä½¿ç”¨6ä¸ªå…³é”®çš„å¤–è½®å»“ç‚¹
            key_points = self.MOUTH_CORNERS + self.MOUTH_KEY_POINTS
            
            # è®¡ç®—ä¸­å¿ƒ
            all_points = []
            for idx in key_points:
                if idx < len(landmarks_2d):
                    all_points.append(landmarks_2d[idx])
            mouth_center = np.mean(all_points, axis=0)
            
            # å‘ä¸­å¿ƒæ”¶ç¼©
            for idx in key_points:
                if idx < len(landmarks_2d):
                    point = landmarks_2d[idx]
                    src_points.append(point)
                    
                    vec = point - mouth_center
                    scale_factor = 1 - intensity * 0.3
                    new_point = mouth_center + vec * scale_factor
                    dst_points.append(new_point)
        
        elif transform_type == "peak":
            # å”‡å³°æŠ¬é«˜ï¼šç§»åŠ¨ä¸Šå”‡ä¸­å¿ƒç‚¹17
            print(f"å”‡å³°æŠ¬é«˜ - ä¸Šå”‡ä¸­å¿ƒ17: {pose_3d}")
            
            # ç§»åŠ¨ä¸Šå”‡ä¸­å¿ƒç‚¹17ï¼ˆåœ¨å¤–è½®å»“ä¸­ï¼‰
            if 17 < len(landmarks_2d):
                point = landmarks_2d[17]
                src_points.append(point)
                lift_amount = intensity * 25
                new_point = [point[0], point[1] - lift_amount]
                dst_points.append(new_point)
            
            # å…¶ä»–å…³é”®ç‚¹ä¿æŒç¨³å®š
            for idx in [61, 291, 84, 314, 405]:
                if idx < len(landmarks_2d):
                    src_points.append(landmarks_2d[idx])
                    dst_points.append(landmarks_2d[idx])
        
        else:
            print(f"âŒ æœªçŸ¥çš„å˜å½¢ç±»å‹: {transform_type}")
            return image
        
        # æ·»åŠ å¤§é‡ç¨³å®šé”šç‚¹ï¼ˆå®Œå…¨å¤åˆ¶é¼»å­è„šæœ¬ï¼‰
        stable_indices = [
            # çœ¼éƒ¨
            33, 133, 362, 263, 7, 163, 144, 145, 153, 154, 155, 173, 157, 158, 159, 160, 161, 246,
            382, 381, 380, 374, 373, 390, 249, 466, 388, 387, 386, 385, 384, 398,
            # é¼»å­åŒºåŸŸ
            1, 2, 6, 19, 20, 8, 9, 10, 49, 131, 134, 278, 360, 363,
            # è„¸éƒ¨è½®å»“
            234, 93, 132, 58, 172, 136, 150, 149, 176, 148, 152, 377, 400, 378, 379, 365, 397, 288, 361, 323, 454
        ]
        
        anchor_count = 0
        for idx in stable_indices:
            if idx < len(landmarks_2d):
                src_points.append(landmarks_2d[idx])
                dst_points.append(landmarks_2d[idx])
                anchor_count += 1
        
        # æ·»åŠ è¾¹ç•Œé”šç‚¹ï¼ˆå®Œå…¨å¤åˆ¶é¼»å­è„šæœ¬ï¼‰
        h, w = image.shape[:2]
        boundary_margin = 50
        boundary_points = [
            [boundary_margin, boundary_margin], 
            [w//2, boundary_margin], 
            [w-boundary_margin, boundary_margin],
            [boundary_margin, h//2], 
            [w-boundary_margin, h//2],
            [boundary_margin, h-boundary_margin], 
            [w//2, h-boundary_margin], 
            [w-boundary_margin, h-boundary_margin]
        ]
        
        for bp in boundary_points:
            src_points.append(bp)
            dst_points.append(bp)
        
        print(f"3Dæ§åˆ¶ç‚¹: å˜´å·´={len(src_points)-anchor_count-8}, é”šç‚¹={anchor_count}, è¾¹ç•Œ=8")
        
        if len(src_points) < 10:
            print("3Dæ§åˆ¶ç‚¹ä¸è¶³")
            return image
        
        # æ‰§è¡ŒTPSå˜æ¢ï¼ˆå®Œå…¨å¤åˆ¶é¼»å­è„šæœ¬ï¼‰
        try:
            src_points = np.array(src_points, dtype=np.float32)
            dst_points = np.array(dst_points, dtype=np.float32)
            
            tps = cv2.createThinPlateSplineShapeTransformer()
            matches = [cv2.DMatch(i, i, 0) for i in range(len(src_points))]
            
            # å®Œå…¨å¤åˆ¶é¼»å­è„šæœ¬çš„å‚æ•°é¡ºåº
            tps.estimateTransformation(
                dst_points.reshape(1, -1, 2), 
                src_points.reshape(1, -1, 2), 
                matches
            )
            
            # TPSå˜å½¢
            transformed = tps.warpImage(image)
            
            if transformed is None:
                print("3D TPSå˜æ¢å¤±è´¥")
                return image
            
            # åˆ›å»º3Dæ„ŸçŸ¥çš„mask
            mouth_mask = self.create_3d_mouth_mask(image.shape, landmarks_2d, pose_3d)
            
            # èåˆï¼ˆå®Œå…¨å¤åˆ¶é¼»å­è„šæœ¬ï¼‰
            mask_3d = cv2.merge([mouth_mask, mouth_mask, mouth_mask]).astype(np.float32) / 255.0
            mask_blurred = cv2.GaussianBlur(mask_3d, (5, 5), 0)
            
            result = image.astype(np.float32) * (1 - mask_blurred) + transformed.astype(np.float32) * mask_blurred
            result = np.clip(result, 0, 255).astype(np.uint8)
            
            print("âœ… 3Då˜å½¢æˆåŠŸ")
            return result
            
        except Exception as e:
            print(f"3Då˜å½¢å¼‚å¸¸: {e}")
            return image
    
    def debug_mouth_detection(self, image, save_dir=None):
        """è°ƒè¯•å˜´å·´æ£€æµ‹ï¼ˆå¤åˆ¶é¼»å­è„šæœ¬çš„è°ƒè¯•é€»è¾‘ï¼‰"""
        landmarks_2d, pose_info = self.detect_landmarks_3d(image)
        if landmarks_2d is None:
            print("æœªæ£€æµ‹åˆ°é¢éƒ¨å…³é”®ç‚¹")
            return image
        
        debug_img = image.copy()
        
        # ç»˜åˆ¶å®é™…çš„å˜´å·´å…³é”®ç‚¹
        mouth_parts = [
            (self.MOUTH_CORNERS, (0, 0, 255), "C"),     # å˜´è§’-çº¢è‰²
            (self.MOUTH_CENTER, (0, 255, 0), "M"),      # ä¸­å¿ƒ-ç»¿è‰²  
            (self.MOUTH_OUTER, (255, 0, 0), "O"),       # å¤–å›´-è“è‰²
            (self.MOUTH_AUX, (0, 255, 255), "A")        # è¾…åŠ©-é»„è‰²
        ]
        
        for indices, color, prefix in mouth_parts:
            for i, idx in enumerate(indices):
                if idx < len(landmarks_2d):
                    point = landmarks_2d[idx].astype(int)
                    cv2.circle(debug_img, tuple(point), 5, color, -1)
                    cv2.putText(debug_img, f"{prefix}{idx}", tuple(point + 8), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
        
        # æ˜¾ç¤º3Då§¿æ€ä¿¡æ¯
        if pose_info is not None:
            rotation_vector, translation_vector = pose_info
            pose_3d = self.estimate_face_pose_3d(rotation_vector)
            cv2.putText(debug_img, f"3D Pose: {pose_3d}", (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
        
        # æ˜¾ç¤º3D mask
        if pose_info is not None:
            pose_3d = self.estimate_face_pose_3d(pose_info[0])
            mouth_mask = self.create_3d_mouth_mask(image.shape, landmarks_2d, pose_3d)
            mask_overlay = debug_img.copy()
            mask_overlay[mouth_mask > 0] = [255, 0, 255]  # ç´«è‰²mask
            debug_img = cv2.addWeighted(debug_img, 0.7, mask_overlay, 0.3, 0)
        
        if save_dir:
            os.makedirs(save_dir, exist_ok=True)
            cv2.imwrite(os.path.join(save_dir, "debug_mouth_3d.png"), debug_img)
            print(f"è°ƒè¯•æ–‡ä»¶ä¿å­˜åˆ°: {save_dir}")
        
        return debug_img
    
    def process_image(self, image, transform_type="thickness", intensity=0.3, save_debug=False, output_path=None):
        """å¤„ç†å›¾åƒï¼ˆå®Œå…¨å¤åˆ¶é¼»å­è„šæœ¬çš„ç»“æ„ï¼‰"""
        landmarks_2d, pose_info = self.detect_landmarks_3d(image)
        if landmarks_2d is None:
            print("æœªæ£€æµ‹åˆ°é¢éƒ¨å…³é”®ç‚¹")
            return image
        
        print(f"âœ… æ£€æµ‹åˆ° {len(landmarks_2d)} ä¸ª2Då…³é”®ç‚¹")
        
        if save_debug and output_path:
            debug_dir = os.path.splitext(output_path)[0] + "_debug"
            self.debug_mouth_detection(image, debug_dir)
        
        return self.apply_3d_mouth_transform(image, landmarks_2d, pose_info, transform_type, intensity)

def main():
    parser = argparse.ArgumentParser(description='3D Face Geometryå˜´å·´è°ƒæ•´å·¥å…· - å®Œå…¨å¤åˆ¶é¼»å­è„šæœ¬æˆåŠŸæ¨¡å¼')
    parser.add_argument('--input', '-i', required=True, help='è¾“å…¥å›¾ç‰‡è·¯å¾„')
    parser.add_argument('--output', '-o', required=True, help='è¾“å‡ºå›¾ç‰‡è·¯å¾„')
    parser.add_argument('--type', '-t', choices=['thickness', 'peak', 'corners', 'resize', 'enlarge'], 
                       default='thickness', help='è°ƒæ•´ç±»å‹')
    parser.add_argument('--intensity', type=float, default=0.3, help='è°ƒæ•´å¼ºåº¦')
    parser.add_argument('--debug', action='store_true', help='3Dè°ƒè¯•æ¨¡å¼')
    parser.add_argument('--save-debug', action='store_true', help='ä¿å­˜è°ƒè¯•æ–‡ä»¶')
    parser.add_argument('--comparison', action='store_true', help='ç”Ÿæˆå¯¹æ¯”å›¾')
    
    args = parser.parse_args()
    
    image = cv2.imread(args.input)
    if image is None:
        print(f"æ— æ³•åŠ è½½å›¾ç‰‡: {args.input}")
        return
    
    print(f"å›¾ç‰‡å°ºå¯¸: {image.shape}")
    
    processor = Mouth3DAdjustment()
    
    if args.debug:
        debug_result = processor.debug_mouth_detection(image)
        cv2.imwrite(args.output, debug_result)
        print(f"3Dè°ƒè¯•å›¾ä¿å­˜åˆ°: {args.output}")
        return
    
    print(f"å¼€å§‹3Då¤„ç† - ç±»å‹: {args.type}, å¼ºåº¦: {args.intensity}")
    result = processor.process_image(image, args.type, args.intensity, args.save_debug, args.output)
    
    cv2.imwrite(args.output, result)
    print(f"å¤„ç†å®Œæˆï¼Œä¿å­˜åˆ°: {args.output}")
    
    if args.comparison:
        comparison_path = args.output.replace('.', '_comparison.')
        comparison = np.hstack([image, result])
        cv2.line(comparison, (image.shape[1], 0), (image.shape[1], image.shape[0]), (0, 255, 0), 2)
        
        cv2.putText(comparison, 'Original', (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        cv2.putText(comparison, f'3D-{args.type}', (image.shape[1] + 20, 40), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        
        cv2.imwrite(comparison_path, comparison)
        print(f"3Då¯¹æ¯”å›¾ä¿å­˜åˆ°: {comparison_path}")
    
    print("\nâœ… å®Œå…¨å¤åˆ¶é¼»å­è„šæœ¬æˆåŠŸæ¨¡å¼:")
    print("â€¢ ç›¸åŒçš„3Då‡ ä½•æ¨¡å‹å’ŒPnPç®—æ³•")
    print("â€¢ ç›¸åŒçš„TPSå‚æ•°é¡ºåº dst->src")
    print("â€¢ ç›¸åŒçš„æ§åˆ¶ç‚¹å’Œé”šç‚¹ç­–ç•¥")
    print("â€¢ ç›¸åŒçš„maskåˆ›å»ºå’Œèåˆé€»è¾‘")

if __name__ == "__main__":
    main()
