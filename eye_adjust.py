#!/usr/bin/env python3
"""
æ”¹è¿›ç‰ˆçœ¼éƒ¨è°ƒæ•´è„šæœ¬ - eye_adjust.py
é‡ç‚¹è§£å†³ï¼š"å¸¦å­"é—®é¢˜çš„æ ¹æœ¬åŸå› 
æŠ€æœ¯ï¼šå…³é”®ç‚¹å¼‚å¸¸æ£€æµ‹ + ç®€åŒ–TPSå˜å½¢ + åˆ†æ­¥è°ƒè¯•
"""

import cv2
import numpy as np
import mediapipe as mp
import argparse
from typing import List, Tuple, Optional

class SafeEyeAdjustment:
    def __init__(self,face_mesh=None):
        # MediaPipeè®¾ç½®
        self.mp_face_mesh = mp.solutions.face_mesh
        if not face_mesh:
            self.face_mesh = self.mp_face_mesh.FaceMesh(
                static_image_mode=True,  # é™æ€å›¾ç‰‡æ¨¡å¼æ›´ç¨³å®š
                max_num_faces=1,
                refine_landmarks=True,
                min_detection_confidence=0.8,  # æé«˜æ£€æµ‹é˜ˆå€¼
                min_tracking_confidence=0.8
            )
        else:
            self.face_mesh = face_mesh
        
        # ç®€åŒ–çš„çœ¼éƒ¨å…³é”®ç‚¹ï¼ˆå¢åŠ æ›´å¤šæ§åˆ¶ç‚¹ä»¥è·å¾—æ›´å¥½æ•ˆæœï¼‰
        self.LEFT_EYE_ENHANCED = [33, 133, 159, 145, 158, 157, 173, 163]   # 8ä¸ªç‚¹ï¼šå†…è§’ã€å¤–è§’ã€ä¸Šä¸‹ç‚¹+ä¸­é—´ç‚¹
        self.RIGHT_EYE_ENHANCED = [362, 263, 386, 374, 387, 388, 466, 381] # 8ä¸ªç‚¹ï¼šå†…è§’ã€å¤–è§’ã€ä¸Šä¸‹ç‚¹+ä¸­é—´ç‚¹
        
        # å®Œæ•´çœ¼éƒ¨è½®å»“ï¼ˆç”¨äºmaskï¼‰
        self.LEFT_EYE_CONTOUR = [33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246]
        self.RIGHT_EYE_CONTOUR = [362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398]
        
        # ç¨³å®šé”šç‚¹ï¼ˆé˜²æ­¢å…¨å±€å˜å½¢ï¼‰
        self.STABLE_ANCHORS = [
            1, 2, 5, 4, 6, 19, 20,        # é¼»å­
            9, 10, 151, 175,              # é¢å¤´å’Œä¸‹å·´
            61, 291, 39, 269, 270,        # å˜´å·´
            234, 93, 132, 454, 323, 361   # è„¸é¢Š
        ]
        
        # ä¿®æ”¹ï¼šä¸åŒæ¨¡å¼ä½¿ç”¨ä¸åŒçš„å¼ºåº¦ä¸Šé™
        self.MAX_INTENSITY_TPS = 0.4      # TPSæ¨¡å¼ä¸Šé™
        self.MAX_INTENSITY_SIMPLE = 0.15  # ç®€å•æ¨¡å¼ä¸Šé™
        self.MIN_EYE_WIDTH = 10    # æœ€å°çœ¼éƒ¨å®½åº¦ï¼ˆåƒç´ ï¼‰
        self.MIN_EYE_HEIGHT = 3    # æœ€å°çœ¼éƒ¨é«˜åº¦ï¼ˆåƒç´ ï¼‰
    
    def detect_landmarks(self, image: np.ndarray) -> Optional[np.ndarray]:
        """æ£€æµ‹é¢éƒ¨å…³é”®ç‚¹"""
        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        results = self.face_mesh.process(rgb_image)
        
        if not results.multi_face_landmarks:
            return None
        
        landmarks = []
        h, w = image.shape[:2]
        for landmark in results.multi_face_landmarks[0].landmark:
            x = int(landmark.x * w)
            y = int(landmark.y * h)
            landmarks.append([x, y])
        
        return np.array(landmarks)
    
    def get_adaptive_intensity(self, image_shape: Tuple[int, int], base_intensity: float) -> float:
        """ä¿®æ”¹ï¼šç®€åŒ–è‡ªé€‚åº”è°ƒæ•´ï¼Œé¿å…è¿‡åº¦è¡°å‡"""
        h, w = image_shape[:2]
        total_pixels = h * w
        
        # ä¿®æ”¹ï¼šæ›´æ¸©å’Œçš„è‡ªé€‚åº”ç­–ç•¥
        if total_pixels > 1000000:  # è¶…è¿‡1Måƒç´ 
            scale_factor = 0.8  # è½»å¾®é™ä½
        elif total_pixels < 100000:  # å°äº100Kåƒç´   
            scale_factor = 1.2  # è½»å¾®æé«˜
        else:
            scale_factor = 1.0  # ä¸­ç­‰å°ºå¯¸ä¿æŒåŸæ ·
        
        adaptive_intensity = base_intensity * scale_factor
        
        print(f"ğŸ”§ è‡ªé€‚åº”å¼ºåº¦è°ƒæ•´:")
        print(f"   å›¾ç‰‡å°ºå¯¸: {w}x{h} ({total_pixels}åƒç´ )")
        print(f"   ç¼©æ”¾å› å­: {scale_factor:.2f}")
        print(f"   åŸå§‹å¼ºåº¦: {base_intensity:.3f} â†’ è°ƒæ•´å: {adaptive_intensity:.3f}")
        
        return adaptive_intensity
    
    def validate_eye_landmarks(self, landmarks: np.ndarray) -> bool:
        """éªŒè¯çœ¼éƒ¨å…³é”®ç‚¹æ˜¯å¦æ­£å¸¸ï¼ˆä½¿ç”¨å¢å¼ºå…³é”®ç‚¹ï¼‰"""
        try:
            # æ£€æŸ¥å·¦çœ¼
            left_eye_points = [landmarks[i] for i in self.LEFT_EYE_ENHANCED if i < len(landmarks)]
            if len(left_eye_points) < 6:  # è‡³å°‘éœ€è¦6ä¸ªç‚¹
                print("è­¦å‘Šï¼šå·¦çœ¼å…³é”®ç‚¹ä¸è¶³")
                return False
            
            left_eye_points = np.array(left_eye_points)
            left_width = np.max(left_eye_points[:, 0]) - np.min(left_eye_points[:, 0])
            left_height = np.max(left_eye_points[:, 1]) - np.min(left_eye_points[:, 1])
            
            # æ£€æŸ¥å³çœ¼
            right_eye_points = [landmarks[i] for i in self.RIGHT_EYE_ENHANCED if i < len(landmarks)]
            if len(right_eye_points) < 6:  # è‡³å°‘éœ€è¦6ä¸ªç‚¹
                print("è­¦å‘Šï¼šå³çœ¼å…³é”®ç‚¹ä¸è¶³")
                return False
            
            right_eye_points = np.array(right_eye_points)
            right_width = np.max(right_eye_points[:, 0]) - np.min(right_eye_points[:, 0])
            right_height = np.max(right_eye_points[:, 1]) - np.min(right_eye_points[:, 1])
            
            # æ£€æŸ¥çœ¼éƒ¨å°ºå¯¸æ˜¯å¦åˆç†
            if left_width < self.MIN_EYE_WIDTH or left_height < self.MIN_EYE_HEIGHT:
                print(f"è­¦å‘Šï¼šå·¦çœ¼å°ºå¯¸å¼‚å¸¸ - å®½åº¦:{left_width}, é«˜åº¦:{left_height}")
                return False
            
            if right_width < self.MIN_EYE_WIDTH or right_height < self.MIN_EYE_HEIGHT:
                print(f"è­¦å‘Šï¼šå³çœ¼å°ºå¯¸å¼‚å¸¸ - å®½åº¦:{right_width}, é«˜åº¦:{right_height}")
                return False
            
            # ä¿®æ­£æ ‡å‡†å·®æ£€æŸ¥ï¼ˆçœ¼éƒ¨å‚ç›´åˆ†å¸ƒæœ¬æ¥å°±å°ï¼‰
            left_std_x = np.std(left_eye_points[:, 0])
            left_std_y = np.std(left_eye_points[:, 1])
            right_std_x = np.std(right_eye_points[:, 0])
            right_std_y = np.std(right_eye_points[:, 1])
            
            # æ”¾å®½æ£€æŸ¥æ¡ä»¶ï¼šæ°´å¹³åˆ†å¸ƒè¦æ±‚ > 2ï¼Œå‚ç›´åˆ†å¸ƒè¦æ±‚ > 1ï¼ˆçœ¼ç›æœ¬æ¥å°±æ‰ï¼‰
            if left_std_x < 2 or right_std_x < 2:
                print(f"è­¦å‘Šï¼šçœ¼éƒ¨æ°´å¹³åˆ†å¸ƒå¼‚å¸¸ - å·¦çœ¼std_x:{left_std_x:.1f}, å³çœ¼std_x:{right_std_x:.1f}")
                return False
            
            if left_std_y < 1 or right_std_y < 1:
                print(f"è­¦å‘Šï¼šçœ¼éƒ¨å‚ç›´åˆ†å¸ƒå¼‚å¸¸ - å·¦çœ¼std_y:{left_std_y:.1f}, å³çœ¼std_y:{right_std_y:.1f}")
                return False
            
            # æ£€æŸ¥çœ¼éƒ¨ä¹‹é—´çš„è·ç¦»æ˜¯å¦åˆç†
            left_center = np.mean(left_eye_points, axis=0)
            right_center = np.mean(right_eye_points, axis=0)
            eye_distance = np.linalg.norm(left_center - right_center)
            
            if eye_distance < 30:  # ä¸¤çœ¼è·ç¦»è‡³å°‘30åƒç´ 
                print(f"è­¦å‘Šï¼šåŒçœ¼è·ç¦»å¼‚å¸¸ - è·ç¦»:{eye_distance:.1f}")
                return False
            
            print(f"âœ… çœ¼éƒ¨å…³é”®ç‚¹éªŒè¯é€šè¿‡")
            print(f"   å·¦çœ¼: å°ºå¯¸({left_width:.0f}x{left_height:.0f}), std({left_std_x:.1f},{left_std_y:.1f})")
            print(f"   å³çœ¼: å°ºå¯¸({right_width:.0f}x{right_height:.0f}), std({right_std_x:.1f},{right_std_y:.1f})")
            print(f"   åŒçœ¼è·ç¦»: {eye_distance:.0f}åƒç´ ")
            return True
            
        except Exception as e:
            print(f"çœ¼éƒ¨å…³é”®ç‚¹éªŒè¯å¤±è´¥: {e}")
            return False
    
    def create_safe_eye_mask(self, image_shape: Tuple[int, int], landmarks: np.ndarray) -> np.ndarray:
        """åˆ›å»ºå®‰å…¨çš„çœ¼éƒ¨åŒºåŸŸmask"""
        h, w = image_shape[:2]
        mask = np.zeros((h, w), dtype=np.uint8)
        
        # åˆ†åˆ«ä¸ºå·¦å³çœ¼åˆ›å»ºmask
        for eye_contour in [self.LEFT_EYE_CONTOUR, self.RIGHT_EYE_CONTOUR]:
            eye_points = []
            for idx in eye_contour:
                if idx < len(landmarks):
                    eye_points.append(landmarks[idx])
            
            if len(eye_points) >= 3:
                eye_points = np.array(eye_points, dtype=np.int32)
                # åˆ›å»ºä¿å®ˆçš„å‡¸åŒ…
                hull = cv2.convexHull(eye_points)
                cv2.fillPoly(mask, [hull], 255)
        
        return mask
    
    def simple_eye_enlarge(self, image: np.ndarray, landmarks: np.ndarray, 
                          intensity: float = 0.1) -> np.ndarray:
        """å¢å¼ºç‰ˆçœ¼ç›æ”¾å¤§ç®—æ³•ï¼ˆæ›´å¤šæ§åˆ¶ç‚¹+è‡ªé€‚åº”å¼ºåº¦ï¼‰"""
        # éªŒè¯å…³é”®ç‚¹
        if not self.validate_eye_landmarks(landmarks):
            print("âŒ çœ¼éƒ¨å…³é”®ç‚¹å¼‚å¸¸ï¼Œè·³è¿‡çœ¼ç›æ”¾å¤§")
            return image
        
        # è‡ªé€‚åº”å¼ºåº¦è°ƒæ•´
        adaptive_intensity = self.get_adaptive_intensity(image.shape, intensity)
        adaptive_intensity = min(adaptive_intensity, self.MAX_INTENSITY_TPS)  # ä½¿ç”¨TPSä¸“ç”¨ä¸Šé™
        
        print(f"åº”ç”¨çœ¼ç›æ”¾å¤§ï¼Œè‡ªé€‚åº”å¼ºåº¦: {adaptive_intensity:.3f}")
        
        src_points = []
        dst_points = []
        
        # å¤„ç†å·¦çœ¼ï¼ˆä½¿ç”¨å¢å¼ºå…³é”®ç‚¹ï¼‰
        left_eye_points = [landmarks[i] for i in self.LEFT_EYE_ENHANCED if i < len(landmarks)]
        if len(left_eye_points) >= 6:
            left_eye_points = np.array(left_eye_points)
            left_center = np.mean(left_eye_points, axis=0)
            
            print(f"å·¦çœ¼ä¸­å¿ƒ: ({left_center[0]:.1f}, {left_center[1]:.1f})")
            
            for i, point in enumerate(left_eye_points):
                src_points.append(point)
                # ä»ä¸­å¿ƒå‘å¤–æ‰©å±•
                vec = point - left_center
                new_point = left_center + vec * (1 + adaptive_intensity)
                dst_points.append(new_point)
                
                distance = np.linalg.norm(new_point - point)
                print(f"   å·¦çœ¼ç‚¹{i}: ç§»åŠ¨ {distance:.2f}åƒç´ ")
        
        # å¤„ç†å³çœ¼ï¼ˆä½¿ç”¨å¢å¼ºå…³é”®ç‚¹ï¼‰
        right_eye_points = [landmarks[i] for i in self.RIGHT_EYE_ENHANCED if i < len(landmarks)]
        if len(right_eye_points) >= 6:
            right_eye_points = np.array(right_eye_points)
            right_center = np.mean(right_eye_points, axis=0)
            
            print(f"å³çœ¼ä¸­å¿ƒ: ({right_center[0]:.1f}, {right_center[1]:.1f})")
            
            for i, point in enumerate(right_eye_points):
                src_points.append(point)
                # ä»ä¸­å¿ƒå‘å¤–æ‰©å±•
                vec = point - right_center
                new_point = right_center + vec * (1 + adaptive_intensity)
                dst_points.append(new_point)
                
                distance = np.linalg.norm(new_point - point)
                print(f"   å³çœ¼ç‚¹{i}: ç§»åŠ¨ {distance:.2f}åƒç´ ")
        
        # æ·»åŠ ç¨³å®šé”šç‚¹
        anchor_count = 0
        for anchor_idx in self.STABLE_ANCHORS:
            if anchor_idx < len(landmarks):
                src_points.append(landmarks[anchor_idx])
                dst_points.append(landmarks[anchor_idx])
                anchor_count += 1
        
        print(f"æ·»åŠ äº† {anchor_count} ä¸ªç¨³å®šé”šç‚¹")
        
        if len(src_points) < 6:
            print("âŒ æ§åˆ¶ç‚¹ä¸è¶³ï¼Œè·³è¿‡å˜å½¢")
            return image
        
        # åˆ›å»ºçœ¼éƒ¨mask
        mask = self.create_safe_eye_mask(image.shape, landmarks)
        mask_area = np.sum(mask > 0)
        print(f"MaskåŒºåŸŸåƒç´ æ•°: {mask_area}")
        
        # åº”ç”¨TPSå˜å½¢
        return self.apply_safe_tps(image, src_points, dst_points, mask)
    
    def apply_safe_tps(self, image: np.ndarray, src_points: List, dst_points: List, 
                      mask: np.ndarray) -> np.ndarray:
        """å®‰å…¨çš„TPSå˜å½¢ï¼ˆå¢å¼ºè°ƒè¯•ï¼‰"""
        try:
            src_points = np.array(src_points, dtype=np.float32)
            dst_points = np.array(dst_points, dtype=np.float32)
            
            if len(src_points) != len(dst_points):
                print("âŒ æºç‚¹å’Œç›®æ ‡ç‚¹æ•°é‡ä¸åŒ¹é…")
                return image
            
            # æ£€æŸ¥ç‚¹çš„ç§»åŠ¨è·ç¦»
            distances = np.linalg.norm(dst_points - src_points, axis=1)
            max_distance = np.max(distances)
            avg_distance = np.mean(distances)
            moving_points = np.sum(distances > 0.1)  # ç§»åŠ¨è¶…è¿‡0.1åƒç´ çš„ç‚¹
            
            print(f"ğŸ“Š TPSå˜å½¢ç»Ÿè®¡:")
            print(f"   æ§åˆ¶ç‚¹æ•°: {len(src_points)}")
            print(f"   ç§»åŠ¨ç‚¹æ•°: {moving_points}")
            print(f"   æœ€å¤§ç§»åŠ¨: {max_distance:.2f}åƒç´ ")
            print(f"   å¹³å‡ç§»åŠ¨: {avg_distance:.2f}åƒç´ ")
            
            # ä¿®æ”¹ï¼šæ”¾å®½ç§»åŠ¨è·ç¦»é™åˆ¶
            if max_distance > 150:  # ä»100æé«˜åˆ°150
                print(f"âŒ ç‚¹ç§»åŠ¨è·ç¦»è¿‡å¤§: {max_distance:.1f}, è·³è¿‡å˜å½¢")
                return image
            
            if moving_points < 4:  # è‡³å°‘è¦æœ‰4ä¸ªç‚¹åœ¨ç§»åŠ¨
                print(f"âŒ ç§»åŠ¨ç‚¹æ•°å¤ªå°‘: {moving_points}, è·³è¿‡å˜å½¢")
                return image
            
            # åˆ›å»ºTPSå˜æ¢å™¨
            tps = cv2.createThinPlateSplineShapeTransformer()
            matches = [cv2.DMatch(i, i, 0) for i in range(len(src_points))]
            
            print("ğŸ”„ å¼€å§‹TPSå˜æ¢...")
            
            # ä¼°è®¡å˜æ¢
            ret = tps.estimateTransformation(
                dst_points.reshape(1, -1, 2),
                src_points.reshape(1, -1, 2),
                matches
            )
            
            print(f"   å˜æ¢ä¼°è®¡è¿”å›å€¼: {ret}")
            
            # åº”ç”¨å˜æ¢
            print("ğŸ”„ åº”ç”¨TPSå˜æ¢...")
            transformed = tps.warpImage(image)
            
            if transformed is None or transformed.size == 0:
                print("âŒ TPSå˜æ¢è¿”å›ç©ºç»“æœ")
                return image
            
            print(f"   å˜æ¢åå›¾åƒå°ºå¯¸: {transformed.shape}")
            
            # æ£€æŸ¥å˜æ¢åçš„å›¾åƒæ˜¯å¦æœ‰æ˜æ˜¾å˜åŒ–
            diff = cv2.absdiff(image, transformed)
            diff_sum = np.sum(diff)
            print(f"   å›¾åƒå·®å¼‚æ€»å’Œ: {diff_sum}")
            
            if diff_sum < 1000:  # å¦‚æœå˜åŒ–å¤ªå°
                print("âš ï¸  å˜æ¢åå›¾åƒå˜åŒ–å¾ˆå°ï¼Œå¯èƒ½TPSå˜æ¢æ— æ•ˆ")
                # ä½†ä»ç„¶ç»§ç»­å¤„ç†
            
            # å®‰å…¨èåˆ
            result = image.copy()
            
            # åˆ›å»º3é€šé“mask
            mask_3d = cv2.merge([mask, mask, mask]).astype(np.float32) / 255.0
            
            # ä¿®æ”¹ï¼šå‡å°‘maskç¾½åŒ–
            mask_blurred = cv2.GaussianBlur(mask_3d, (5, 5), 0)  # ä»(11,11)æ”¹ä¸º(5,5)
            
            print("ğŸ”„ èåˆå›¾åƒ...")
            
            # èåˆ
            result = result.astype(np.float32)
            transformed = transformed.astype(np.float32)
            result = result * (1 - mask_blurred) + transformed * mask_blurred
            result = np.clip(result, 0, 255).astype(np.uint8)
            
            # æ£€æŸ¥æœ€ç»ˆç»“æœçš„å˜åŒ–
            final_diff = cv2.absdiff(image, result)
            final_diff_sum = np.sum(final_diff)
            print(f"   æœ€ç»ˆå·®å¼‚æ€»å’Œ: {final_diff_sum}")
            
            print("âœ… TPSå˜å½¢å®Œæˆ")
            return result
            
        except Exception as e:
            print(f"âŒ TPSå˜å½¢å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            return image
    
    def test_simple_transform(self, image: np.ndarray, intensity: float = 0.1) -> np.ndarray:
        """æµ‹è¯•ç®€å•çš„å±€éƒ¨ç¼©æ”¾å˜æ¢ï¼ˆä¿®å¤ç‰ˆæœ¬ï¼‰"""
        landmarks = self.detect_landmarks(image)
        if landmarks is None or not self.validate_eye_landmarks(landmarks):
            print("âŒ å…³é”®ç‚¹æ£€æµ‹å¤±è´¥")
            return image
        
        print(f"ğŸ”„ å¼€å§‹ç®€å•å˜æ¢ï¼Œå¼ºåº¦: {intensity}")
        result = image.copy()
        
        # å¤„ç†å·¦å³çœ¼
        for eye_name, eye_indices in [("å·¦çœ¼", self.LEFT_EYE_ENHANCED), ("å³çœ¼", self.RIGHT_EYE_ENHANCED)]:
            eye_points = [landmarks[i] for i in eye_indices if i < len(landmarks)]
            if len(eye_points) < 6:
                print(f"âŒ {eye_name}å…³é”®ç‚¹ä¸è¶³: {len(eye_points)}")
                continue
            
            eye_points = np.array(eye_points)
            
            # è®¡ç®—çœ¼éƒ¨è¾¹ç•Œæ¡†
            min_x = int(np.min(eye_points[:, 0]) - 15)
            max_x = int(np.max(eye_points[:, 0]) + 15)
            min_y = int(np.min(eye_points[:, 1]) - 10)
            max_y = int(np.max(eye_points[:, 1]) + 10)
            
            # ç¡®ä¿è¾¹ç•Œæ¡†åœ¨å›¾åƒèŒƒå›´å†…
            h, w = image.shape[:2]
            min_x = max(0, min_x)
            max_x = min(w, max_x)
            min_y = max(0, min_y)
            max_y = min(h, max_y)
            
            # æ£€æŸ¥è¾¹ç•Œæ¡†æ˜¯å¦æœ‰æ•ˆ
            roi_width = max_x - min_x
            roi_height = max_y - min_y
            
            if roi_width <= 0 or roi_height <= 0:
                print(f"âŒ {eye_name}è¾¹ç•Œæ¡†æ— æ•ˆ: {roi_width}x{roi_height}")
                continue
            
            print(f"ğŸ”„ å¤„ç†{eye_name}: åŒºåŸŸ({min_x},{min_y})-({max_x},{max_y}), å°ºå¯¸{roi_width}x{roi_height}")
            
            try:
                # æå–çœ¼éƒ¨åŒºåŸŸ
                eye_roi = image[min_y:max_y, min_x:max_x].copy()
                
                if eye_roi.size == 0:
                    print(f"âŒ {eye_name}ROIä¸ºç©º")
                    continue
                
                # è®¡ç®—ç¼©æ”¾åçš„å°ºå¯¸
                scale = 1 + intensity
                new_width = int(roi_width * scale)
                new_height = int(roi_height * scale)
                
                print(f"   ç¼©æ”¾ä» {roi_width}x{roi_height} åˆ° {new_width}x{new_height}")
                
                # ç¼©æ”¾çœ¼éƒ¨åŒºåŸŸ
                enlarged_roi = cv2.resize(eye_roi, (new_width, new_height), interpolation=cv2.INTER_CUBIC)
                
                # è®¡ç®—æ”¾ç½®ä½ç½®ï¼ˆå±…ä¸­ï¼‰
                offset_x = (new_width - roi_width) // 2
                offset_y = (new_height - roi_height) // 2
                
                start_x = min_x - offset_x
                start_y = min_y - offset_y
                end_x = start_x + new_width
                end_y = start_y + new_height
                
                # å¤„ç†è¾¹ç•Œè¶…å‡º
                crop_left = max(0, -start_x)
                crop_top = max(0, -start_y)
                crop_right = max(0, end_x - w)
                crop_bottom = max(0, end_y - h)
                
                start_x = max(0, start_x)
                start_y = max(0, start_y)
                end_x = min(w, end_x)
                end_y = min(h, end_y)
                
                # è£å‰ªenlarged_roi
                if crop_left > 0 or crop_top > 0 or crop_right > 0 or crop_bottom > 0:
                    enlarged_roi = enlarged_roi[crop_top:new_height-crop_bottom, 
                                              crop_left:new_width-crop_right]
                
                final_width = end_x - start_x
                final_height = end_y - start_y
                
                if final_width <= 0 or final_height <= 0 or enlarged_roi.size == 0:
                    print(f"âŒ {eye_name}æœ€ç»ˆåŒºåŸŸæ— æ•ˆ")
                    continue
                
                # ç¡®ä¿å°ºå¯¸åŒ¹é…
                if enlarged_roi.shape[:2] != (final_height, final_width):
                    enlarged_roi = cv2.resize(enlarged_roi, (final_width, final_height))
                
                print(f"   æœ€ç»ˆæ”¾ç½®: ({start_x},{start_y})-({end_x},{end_y})")
                
                # ä¿®æ”¹ï¼šå‡å°‘ç¾½åŒ–ç¨‹åº¦
                mask = np.ones((final_height, final_width), dtype=np.float32)
                
                # è¾¹ç¼˜ç¾½åŒ–
                feather_size = min(3, final_width//6, final_height//6)  # ä»5æ”¹ä¸º3ï¼Œä»//4æ”¹ä¸º//6
                if feather_size > 0:
                    for i in range(feather_size):
                        alpha = (i + 1) / feather_size
                        if i < final_height:
                            mask[i, :] *= alpha
                            mask[-(i+1), :] *= alpha
                        if i < final_width:
                            mask[:, i] *= alpha
                            mask[:, -(i+1)] *= alpha
                
                # åº”ç”¨åˆ°ç»“æœå›¾åƒ
                for c in range(3):
                    result[start_y:end_y, start_x:end_x, c] = (
                        result[start_y:end_y, start_x:end_x, c] * (1 - mask) +
                        enlarged_roi[:, :, c] * mask
                    )
                
                print(f"âœ… {eye_name}å¤„ç†å®Œæˆ")
                
            except Exception as e:
                print(f"âŒ {eye_name}å¤„ç†å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
                continue
        
        print("âœ… ç®€å•å˜æ¢å®Œæˆ")
        return result
    
    def debug_eye_detection(self, image: np.ndarray) -> np.ndarray:
        """è°ƒè¯•çœ¼éƒ¨æ£€æµ‹ï¼ˆä¿®å¤æ˜¾ç¤ºé—®é¢˜ï¼‰"""
        landmarks = self.detect_landmarks(image)
        if landmarks is None:
            print("âŒ æœªæ£€æµ‹åˆ°é¢éƒ¨å…³é”®ç‚¹")
            return image
        
        debug_img = image.copy()
        
        # ç»˜åˆ¶å¢å¼ºç‰ˆçœ¼éƒ¨å…³é”®ç‚¹ï¼ˆå·¦çœ¼ç»¿è‰²ï¼‰
        for i, idx in enumerate(self.LEFT_EYE_ENHANCED):
            if idx < len(landmarks):
                point = landmarks[idx]
                cv2.circle(debug_img, tuple(point), 6, (0, 255, 0), -1)
                cv2.circle(debug_img, tuple(point), 8, (0, 255, 0), 2)
                # ä½¿ç”¨ç®€å•çš„ASCIIå­—ç¬¦é¿å…ç¼–ç é—®é¢˜
                label = f"{i}"  # ç®€åŒ–æ ‡ç­¾
                cv2.putText(debug_img, label, tuple(point + 10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        
        # ç»˜åˆ¶å¢å¼ºç‰ˆçœ¼éƒ¨å…³é”®ç‚¹ï¼ˆå³çœ¼çº¢è‰²ï¼‰
        for i, idx in enumerate(self.RIGHT_EYE_ENHANCED):
            if idx < len(landmarks):
                point = landmarks[idx]
                cv2.circle(debug_img, tuple(point), 6, (0, 0, 255), -1)
                cv2.circle(debug_img, tuple(point), 8, (0, 0, 255), 2)
                # ä½¿ç”¨ç®€å•çš„ASCIIå­—ç¬¦
                label = f"{i}"  # ç®€åŒ–æ ‡ç­¾
                cv2.putText(debug_img, label, tuple(point + 10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
        
        # ç»˜åˆ¶çœ¼éƒ¨è½®å»“ï¼ˆå·¦çœ¼é’è‰²å°ç‚¹ï¼‰
        for idx in self.LEFT_EYE_CONTOUR:
            if idx < len(landmarks):
                cv2.circle(debug_img, tuple(landmarks[idx]), 3, (255, 255, 0), -1)
        
        # ç»˜åˆ¶çœ¼éƒ¨è½®å»“ï¼ˆå³çœ¼ç´«è‰²å°ç‚¹ï¼‰
        for idx in self.RIGHT_EYE_CONTOUR:
            if idx < len(landmarks):
                cv2.circle(debug_img, tuple(landmarks[idx]), 3, (255, 0, 255), -1)
        
        # æ˜¾ç¤ºéªŒè¯ç»“æœï¼ˆé¿å…ä½¿ç”¨ç‰¹æ®Šå­—ç¬¦ï¼‰
        is_valid = self.validate_eye_landmarks(landmarks)
        status_text = "VALID" if is_valid else "INVALID"
        cv2.putText(debug_img, f"Eye landmarks: {status_text}", (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0) if is_valid else (0, 0, 255), 2)
        
        # æ·»åŠ å›¾ä¾‹
        legend_y = 60
        cv2.putText(debug_img, "GREEN: Left Eye (0-7)", (10, legend_y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        cv2.putText(debug_img, "RED: Right Eye (0-7)", (10, legend_y + 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
        cv2.putText(debug_img, "CYAN: Left contour", (10, legend_y + 60), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
        cv2.putText(debug_img, "PURPLE: Right contour", (10, legend_y + 90), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 255), 2)
        
        # æ˜¾ç¤ºå…³é”®ç‚¹ç´¢å¼•ä¿¡æ¯
        cv2.putText(debug_img, f"Enhanced control points: 8 per eye", (10, legend_y + 120), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        return debug_img
    
    def process_image(self, image: np.ndarray, enlarge_intensity: float = 0.1) -> np.ndarray:
        """å¤„ç†å›¾ç‰‡"""
        landmarks = self.detect_landmarks(image)
        if landmarks is None:
            print("âŒ æœªæ£€æµ‹åˆ°é¢éƒ¨å…³é”®ç‚¹")
            return image
        
        print(f"âœ… æ£€æµ‹åˆ° {len(landmarks)} ä¸ªé¢éƒ¨å…³é”®ç‚¹")
        
        # åº”ç”¨çœ¼ç›æ”¾å¤§
        if enlarge_intensity > 0:
            result = self.simple_eye_enlarge(image, landmarks, enlarge_intensity)
        else:
            result = image
        
        return result

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='å®‰å…¨çœ¼éƒ¨è°ƒæ•´å·¥å…· - è§£å†³å¸¦å­é—®é¢˜')
    parser.add_argument('--input', '-i', required=True, help='è¾“å…¥å›¾ç‰‡è·¯å¾„')
    parser.add_argument('--output', '-o', required=True, help='è¾“å‡ºå›¾ç‰‡è·¯å¾„')
    parser.add_argument('--enlarge', type=float, default=0.2, help='çœ¼ç›æ”¾å¤§å¼ºåº¦ (ç®€å•æ¨¡å¼:0.01-0.15, TPSæ¨¡å¼:0.01-0.4)')  # ä¿®æ”¹ï¼šè¯´æ˜ä¸åŒæ¨¡å¼çš„èŒƒå›´
    parser.add_argument('--debug', action='store_true', help='è°ƒè¯•æ¨¡å¼ï¼šæ˜¾ç¤ºå…³é”®ç‚¹')
    parser.add_argument('--simple', action='store_true', help='ä½¿ç”¨ç®€å•å˜æ¢ï¼ˆç»•è¿‡TPSï¼‰')
    parser.add_argument('--comparison', action='store_true', help='ç”Ÿæˆå¯¹æ¯”å›¾')
    
    args = parser.parse_args()
    
    # åŠ è½½å›¾ç‰‡
    image = cv2.imread(args.input)
    if image is None:
        print(f"âŒ æ— æ³•åŠ è½½å›¾ç‰‡: {args.input}")
        return
    
    print(f"åŸå›¾å°ºå¯¸: {image.shape}")
    
    # åˆ›å»ºå¤„ç†å™¨
    processor = SafeEyeAdjustment()
    
    # è°ƒè¯•æ¨¡å¼
    if args.debug:
        debug_result = processor.debug_eye_detection(image)
        cv2.imwrite(args.output, debug_result)
        print(f"è°ƒè¯•å›¾ä¿å­˜åˆ°: {args.output}")
        return
    
    # ä¿®æ”¹ï¼šæ ¹æ®æ¨¡å¼è®¾ç½®ä¸åŒçš„å¼ºåº¦é™åˆ¶
    if args.simple:
        # ç®€å•æ¨¡å¼ï¼šé™åˆ¶åˆ°0.15é¿å…åƒç´ æ‰­æ›²
        max_allowed = 0.15
        enlarge_intensity = min(args.enlarge, max_allowed)
        if enlarge_intensity != args.enlarge:
            print(f"ç®€å•æ¨¡å¼å¼ºåº¦é™åˆ¶åˆ°: {enlarge_intensity} (å»ºè®®â‰¤0.15é¿å…åƒç´ æ‰­æ›²)")
    else:
        # TPSæ¨¡å¼ï¼šå…è®¸æ›´é«˜å¼ºåº¦0.4
        max_allowed = 0.4
        enlarge_intensity = min(args.enlarge, max_allowed)
        if enlarge_intensity != args.enlarge:
            print(f"TPSæ¨¡å¼å¼ºåº¦é™åˆ¶åˆ°: {enlarge_intensity} (å»ºè®®â‰¤0.4ä¿æŒç¨³å®šæ€§)")
    
    # å¤„ç†å›¾ç‰‡
    print("å¼€å§‹å®‰å…¨çœ¼éƒ¨è°ƒæ•´...")
    if args.simple:
        result = processor.test_simple_transform(image, enlarge_intensity)
    else:
        result = processor.process_image(image, enlarge_intensity)
    
    # ä¿®æ”¹ï¼šæ ¹æ®ç”¨æˆ·æŒ‡å®šæ ¼å¼ä¿å­˜ï¼Œä½†ç»™å‡ºPNGå»ºè®®
    output_path = args.output
    is_jpeg = output_path.lower().endswith(('.jpg', '.jpeg'))
    
    if is_jpeg:
        print("âš ï¸  æ³¨æ„ï¼šJPEGæ ¼å¼ä¼šå‹ç¼©ç»†å¾®å˜åŒ–ï¼Œå»ºè®®ä½¿ç”¨PNGæ ¼å¼è·å¾—æœ€ä½³æ•ˆæœ")
        png_suggestion = output_path.rsplit('.', 1)[0] + '.png'
        print(f"   å»ºè®®å‘½ä»¤ï¼špython eye_adjust.py -i {args.input} -o {png_suggestion} --enlarge {args.enlarge} {'--comparison' if args.comparison else ''}")
    
    cv2.imwrite(output_path, result)
    print(f"âœ… å¤„ç†å®Œæˆï¼ä¿å­˜åˆ°: {output_path}")
    
    # æ£€æŸ¥åƒç´ å·®å¼‚
    diff = cv2.absdiff(image, result)
    total_diff = np.sum(diff)
    max_diff = np.max(diff)
    changed_pixels = np.sum(diff > 0)
    print(f"ğŸ“Š åƒç´ å˜åŒ–ç»Ÿè®¡:")
    print(f"   æ€»å·®å¼‚: {total_diff}")
    print(f"   æœ€å¤§å·®å¼‚: {max_diff}")
    print(f"   å˜åŒ–åƒç´ æ•°: {changed_pixels}")
    
    if total_diff < 1000:
        print("âš ï¸  å˜åŒ–å¾ˆå°ï¼Œå¯èƒ½éœ€è¦ï¼š")
        print("   1. æé«˜ --enlarge å‚æ•° (å¦‚0.3)")
        print("   2. å°è¯• --simple æ¨¡å¼")
        print("   3. ä½¿ç”¨PNGæ ¼å¼é¿å…å‹ç¼©")
    
    # ç”Ÿæˆå¯¹æ¯”å›¾
    if args.comparison:
        # å¯¹æ¯”å›¾ä½¿ç”¨ç›¸åŒæ ¼å¼
        if is_jpeg:
            comparison_path = output_path.replace('.jpg', '_comparison.jpg').replace('.jpeg', '_comparison.jpeg')
            diff_path = output_path.rsplit('.', 1)[0] + '_diff.png'  # å·®å¼‚å›¾å»ºè®®ç”¨PNG
        else:
            comparison_path = output_path.replace('.png', '_comparison.png')
            diff_path = output_path.replace('.png', '_diff.png')
        
        comparison = np.hstack([image, result])
        cv2.line(comparison, (image.shape[1], 0), (image.shape[1], image.shape[0]), (0, 255, 0), 3)
        
        # æ·»åŠ æ ‡ç­¾
        cv2.putText(comparison, 'Original', (20, 50), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3)
        cv2.putText(comparison, f'Enlarge {enlarge_intensity:.2f}', (image.shape[1] + 20, 50), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3)
        
        cv2.imwrite(comparison_path, comparison)
        print(f"å¯¹æ¯”å›¾ä¿å­˜åˆ°: {comparison_path}")
        
        # å·®å¼‚å›¾ç”¨PNGä¿å­˜ï¼ˆæ— æŸï¼Œä¾¿äºè§‚å¯Ÿç»†å¾®å˜åŒ–ï¼‰
        if changed_pixels > 0:
            diff_colored = cv2.applyColorMap((diff * 10).astype(np.uint8), cv2.COLORMAP_HOT)
            cv2.imwrite(diff_path, diff_colored)
            print(f"å·®å¼‚å›¾ä¿å­˜åˆ°: {diff_path} (PNGæ ¼å¼ä¾¿äºè§‚å¯Ÿ)")
        else:
            print("æ— åƒç´ å˜åŒ–ï¼Œè·³è¿‡å·®å¼‚å›¾ç”Ÿæˆ")
    
    print("\nğŸ›¡ï¸  ä¿®å¤å†…å®¹:")
    print("âœ… åŒé‡å¼ºåº¦é™åˆ¶: ç®€å•æ¨¡å¼â‰¤0.15, TPSæ¨¡å¼â‰¤0.4")
    print("âœ… é»˜è®¤å¼ºåº¦: 0.1 â†’ 0.2") 
    print("âœ… è‡ªé€‚åº”å¼ºåº¦: ç®€åŒ–ç®—æ³•ï¼Œé¿å…è¿‡åº¦è¡°å‡")
    print("âœ… ç§»åŠ¨è·ç¦»é™åˆ¶: 100 â†’ 150åƒç´ ")
    print("âœ… maskç¾½åŒ–: (11,11) â†’ (5,5)")
    print("âœ… è¾¹ç¼˜ç¾½åŒ–: æ›´ä¿å®ˆçš„ç¾½åŒ–ç­–ç•¥")
    print("âœ… æ ¼å¼å¤„ç†: æ”¯æŒç”¨æˆ·æŒ‡å®šæ ¼å¼ï¼ŒJPEGæ—¶ç»™å‡ºPNGå»ºè®®")
    print("âœ… åƒç´ å·®å¼‚ç»Ÿè®¡: é‡åŒ–å˜åŒ–ç¨‹åº¦")
    print("\nğŸ“– ä½¿ç”¨ç¤ºä¾‹:")
    print("â€¢ TPSæ¨¡å¼(é«˜å¼ºåº¦): python eye_adjust.py -i input.jpg -o result.png --enlarge 0.3 --comparison")
    print("â€¢ ç®€å•æ¨¡å¼(ç¨³å®š):  python eye_adjust.py -i input.jpg -o result.png --enlarge 0.15 --simple --comparison") 
    print("â€¢ å¯¹æ¯”æµ‹è¯•:       python eye_adjust.py -i input.jpg -o result.png --enlarge 0.25 --comparison")
    print("â€¢ è°ƒè¯•å…³é”®ç‚¹:     python eye_adjust.py -i input.jpg -o debug.png --debug")
    print("\nâš ï¸  é‡è¦:")
    print("â€¢ ç®€å•æ¨¡å¼: å»ºè®®å¼ºåº¦0.05-0.15 (é¿å…åƒç´ æ‰­æ›²)")
    print("â€¢ TPSæ¨¡å¼: å¯ç”¨å¼ºåº¦0.1-0.4 (å¹³æ»‘æ’å€¼ï¼Œæ‰¿å—æ›´é«˜å¼ºåº¦)")
    print("â€¢ å·®å¼‚å›¾å§‹ç»ˆç”¨PNGä¿å­˜ä¾¿äºè§‚å¯Ÿç»†å¾®å˜åŒ–")

if __name__ == "__main__":
    main()
