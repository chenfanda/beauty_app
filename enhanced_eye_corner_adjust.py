#!/usr/bin/env python3
"""
å¢å¼ºçš„çœ¼è§’è°ƒæ•´è„šæœ¬ - enhanced_eye_corner_adjust.py
æ ¸å¿ƒæ”¹è¿›ï¼š
1. åŸºäºçœ¼å½¢è¯†åˆ«çš„å…ˆéªŒçŸ¥è¯†ç³»ç»Ÿ
2. ä¸€è‡´æ€§å‚è€ƒç‚¹è®¾è®¡ï¼Œé¿å…ç§»åŠ¨å‘é‡å†²çª
3. æ™ºèƒ½è°ƒæ•´ç±»å‹é€‚é…æ€§æ£€æŸ¥
4. åŒºåŸŸåŒ–ç§»åŠ¨ç­–ç•¥ï¼Œä¿è¯æ’å€¼æˆåŠŸ
"""

import cv2
import numpy as np
import mediapipe as mp
import argparse
import os
from typing import List, Tuple, Optional, Dict

class EyeShapeAnalyzer:
    """çœ¼å½¢è¯†åˆ«å’Œåˆ†ææ¨¡å—"""
    
    def __init__(self):
        # åŸºäºåŒ»å­¦ç¾å­¦çš„çœ¼å½¢åˆ†ç±»æ ‡å‡†
        self.EYE_SHAPE_CATEGORIES = {
            'round': {  # åœ†çœ¼
                'length_width_ratio': (2.0, 2.7),
                'tilt_angle': (-5, 5),
                'recommended_adjustments': ['stretch', 'lift', 'shape'],
                'optimal_intensity': {'stretch': 0.35, 'lift': 0.25, 'shape': 0.3},
                'description': 'åœ†æ¶¦å¯çˆ±å‹çœ¼ç›ï¼Œé€‚åˆæ‹‰é•¿å’Œä¸Šæ‰¬'
            },
            'almond': {  # æä»çœ¼ï¼ˆç†æƒ³çœ¼å‹ï¼‰
                'length_width_ratio': (2.8, 3.2),
                'tilt_angle': (5, 15),
                'recommended_adjustments': ['minimal', 'enhancement'],
                'optimal_intensity': {'stretch': 0.2, 'lift': 0.15, 'shape': 0.2},
                'description': 'ç†æƒ³æä»çœ¼å‹ï¼Œåªéœ€è½»å¾®è°ƒæ•´'
            },
            'upturned': {  # ä¸Šæ‰¬çœ¼
                'length_width_ratio': (2.5, 3.5),
                'tilt_angle': (15, 25),
                'recommended_adjustments': ['stretch_only'],
                'contraindicated': ['lift'],  # ç¦æ­¢ä¸Šæ‰¬
                'optimal_intensity': {'stretch': 0.25},
                'description': 'å·²ç»ä¸Šæ‰¬çš„çœ¼å‹ï¼Œé¿å…è¿‡åº¦è°ƒæ•´'
            },
            'downturned': {  # ä¸‹å‚çœ¼
                'length_width_ratio': (2.3, 3.0),
                'tilt_angle': (-15, -5),
                'recommended_adjustments': ['lift', 'shape'],
                'optimal_intensity': {'stretch': 0.2, 'lift': 0.4, 'shape': 0.35},
                'description': 'ä¸‹å‚çœ¼å‹ï¼Œæœ€é€‚åˆä¸Šæ‰¬è°ƒæ•´'
            },
            'elongated': {  # ç»†é•¿çœ¼
                'length_width_ratio': (3.3, 4.0),
                'tilt_angle': (-5, 10),
                'recommended_adjustments': ['lift'],
                'contraindicated': ['stretch'],  # ç¦æ­¢æ‹‰é•¿
                'optimal_intensity': {'lift': 0.3, 'shape': 0.25},
                'description': 'ç»†é•¿çœ¼å‹ï¼Œé¿å…è¿›ä¸€æ­¥æ‹‰é•¿'
            },
            'normal': {  # æ™®é€šçœ¼å‹
                'length_width_ratio': (2.7, 3.1),
                'tilt_angle': (-3, 8),
                'recommended_adjustments': ['stretch', 'lift', 'shape'],
                'optimal_intensity': {'stretch': 0.3, 'lift': 0.3, 'shape': 0.3},
                'description': 'æ ‡å‡†çœ¼å‹ï¼Œå„ç§è°ƒæ•´å‡é€‚ç”¨'
            }
        }
    
    def analyze_eye_shape(self, landmarks_2d):
        """ç»¼åˆåˆ†æçœ¼å½¢ç‰¹å¾"""
        
        measurements = self.calculate_eye_measurements(landmarks_2d)
        eye_shape = self.classify_eye_shape(measurements)
        
        return {
            'eye_shape': eye_shape,
            'measurements': measurements,
            'recommendations': self.generate_recommendations(eye_shape),
            'safety_info': self.get_safety_constraints(eye_shape)
        }
    
    def calculate_eye_measurements(self, landmarks_2d):
        """è®¡ç®—çœ¼å½¢çš„å…³é”®æµ‹é‡æŒ‡æ ‡"""
        
        # å·¦çœ¼å…³é”®ç‚¹
        left_inner = landmarks_2d[133]  # å†…çœ¦
        left_outer = landmarks_2d[33]   # å¤–çœ¦
        left_top = landmarks_2d[159]    # ä¸Šçœ¼ç‘
        left_bottom = landmarks_2d[145] # ä¸‹çœ¼ç‘
        
        # å³çœ¼å…³é”®ç‚¹ï¼ˆç”¨äºéªŒè¯å¯¹ç§°æ€§ï¼‰
        right_inner = landmarks_2d[362]
        right_outer = landmarks_2d[263]
        right_top = landmarks_2d[386]
        right_bottom = landmarks_2d[374]
        
        # åŸºæœ¬å°ºå¯¸è®¡ç®—
        left_length = np.linalg.norm(left_outer - left_inner)
        left_height = np.linalg.norm(left_top - left_bottom)
        left_ratio = left_length / left_height if left_height > 0 else 3.0
        
        right_length = np.linalg.norm(right_outer - right_inner)
        right_height = np.linalg.norm(right_top - right_bottom)
        right_ratio = right_length / right_height if right_height > 0 else 3.0
        
        # å¹³å‡æ¯”ä¾‹
        avg_ratio = (left_ratio + right_ratio) / 2
        
        # å€¾æ–œè§’åº¦è®¡ç®—
        left_tilt = np.degrees(np.arctan2(
            left_outer[1] - left_inner[1],
            left_outer[0] - left_inner[0]
        ))
        
        right_tilt = np.degrees(np.arctan2(
            right_outer[1] - right_inner[1],
            right_outer[0] - right_inner[0]
        ))
        
        avg_tilt = (left_tilt + right_tilt) / 2
        
        # å¯¹ç§°æ€§è¯„ä¼°
        symmetry_score = 1.0 - abs(left_ratio - right_ratio) / max(left_ratio, right_ratio)
        
        return {
            'length_width_ratio': avg_ratio,
            'tilt_angle': avg_tilt,
            'left_ratio': left_ratio,
            'right_ratio': right_ratio,
            'symmetry_score': symmetry_score,
            'absolute_size': (left_length + right_length) / 2
        }
    
    def classify_eye_shape(self, measurements):
        """åŸºäºæµ‹é‡å€¼åˆ†ç±»çœ¼å½¢"""
        
        ratio = measurements['length_width_ratio']
        tilt = measurements['tilt_angle']
        
        best_match = None
        best_score = 0
        
        for shape_name, criteria in self.EYE_SHAPE_CATEGORIES.items():
            score = 0
            
            # é•¿å®½æ¯”åŒ¹é…åº¦ (æƒé‡50%)
            if criteria['length_width_ratio'][0] <= ratio <= criteria['length_width_ratio'][1]:
                score += 50
            else:
                # è®¡ç®—åå·®æƒ©ç½š
                min_ratio, max_ratio = criteria['length_width_ratio']
                if ratio < min_ratio:
                    deviation = (min_ratio - ratio) / min_ratio
                else:
                    deviation = (ratio - max_ratio) / max_ratio
                score += max(0, 50 - deviation * 100)
            
            # å€¾æ–œè§’åº¦åŒ¹é…åº¦ (æƒé‡50%)
            if criteria['tilt_angle'][0] <= tilt <= criteria['tilt_angle'][1]:
                score += 50
            else:
                min_tilt, max_tilt = criteria['tilt_angle']
                if tilt < min_tilt:
                    deviation = abs(min_tilt - tilt) / 20  # 20åº¦ä¸ºå‚è€ƒèŒƒå›´
                else:
                    deviation = abs(tilt - max_tilt) / 20
                score += max(0, 50 - deviation * 100)
            
            if score > best_score:
                best_score = score
                best_match = shape_name
        
        confidence = best_score / 100.0
        
        return {
            'primary_type': best_match,
            'confidence': confidence,
            'detailed_scores': {shape: self.calculate_detailed_score(shape, measurements) 
                              for shape in self.EYE_SHAPE_CATEGORIES.keys()}
        }
    
    def calculate_detailed_score(self, shape_name, measurements):
        """è®¡ç®—è¯¦ç»†åŒ¹é…åˆ†æ•°"""
        criteria = self.EYE_SHAPE_CATEGORIES[shape_name]
        
        ratio_match = criteria['length_width_ratio'][0] <= measurements['length_width_ratio'] <= criteria['length_width_ratio'][1]
        tilt_match = criteria['tilt_angle'][0] <= measurements['tilt_angle'] <= criteria['tilt_angle'][1]
        
        return {
            'ratio_match': ratio_match,
            'tilt_match': tilt_match,
            'overall_fit': ratio_match and tilt_match
        }
    
    def generate_recommendations(self, eye_shape):
        """ç”Ÿæˆè°ƒæ•´å»ºè®®"""
        shape_type = eye_shape['primary_type']
        config = self.EYE_SHAPE_CATEGORIES[shape_type]
        
        return {
            'recommended_adjustments': config['recommended_adjustments'],
            'contraindicated': config.get('contraindicated', []),
            'optimal_intensities': config['optimal_intensity'],
            'description': config['description']
        }
    
    def get_safety_constraints(self, eye_shape):
        """è·å–å®‰å…¨çº¦æŸ"""
        shape_type = eye_shape['primary_type']
        
        constraints = {
            'max_intensity': 0.4,
            'min_intensity': 0.1,
            'forbidden_types': self.EYE_SHAPE_CATEGORIES[shape_type].get('contraindicated', [])
        }
        
        # åŸºäºç½®ä¿¡åº¦è°ƒæ•´çº¦æŸ
        if eye_shape['confidence'] < 0.7:
            constraints['max_intensity'] = 0.25  # ä½ç½®ä¿¡åº¦æ—¶æ›´ä¿å®ˆ
            constraints['warning'] = "çœ¼å½¢è¯†åˆ«ç½®ä¿¡åº¦è¾ƒä½ï¼Œå»ºè®®ä½¿ç”¨ä¿å®ˆå‚æ•°"
        
        return constraints

class ConsistentReferenceSystem:
    """ä¸€è‡´æ€§å‚è€ƒç‚¹ç³»ç»Ÿ"""
    
    def __init__(self):
        # å®šä¹‰ç§»åŠ¨åŒºåŸŸï¼Œç¡®ä¿æ¯ä¸ªåŒºåŸŸå†…çš„ç‚¹ä½¿ç”¨ä¸€è‡´çš„å‚è€ƒç­–ç•¥
        self.MOVEMENT_ZONES = {
            'left_outer_corner': {
                'points': [33, 7, 163, 144, 145, 153],  # å·¦çœ¼å¤–çœ¼è§’åŒºåŸŸ
                'reference_type': 'zone_center',
                'movement_pattern': 'radial_consistent'
            },
            'left_inner_corner': {
                'points': [133, 155, 154, 158],  # å·¦çœ¼å†…çœ¼è§’åŒºåŸŸ
                'reference_type': 'minimal_stable',
                'movement_pattern': 'conservative'
            },
            'left_upper_lid': {
                'points': [157, 158, 159, 160, 161],  # å·¦çœ¼ä¸Šçœ¼ç‘
                'reference_type': 'curve_center',
                'movement_pattern': 'smooth_curve'
            },
            'right_outer_corner': {
                'points': [263, 249, 390, 373, 374, 380],  # å³çœ¼å¤–çœ¼è§’åŒºåŸŸ
                'reference_type': 'zone_center',
                'movement_pattern': 'radial_consistent'
            },
            'right_inner_corner': {
                'points': [362, 384, 385, 387],  # å³çœ¼å†…çœ¼è§’åŒºåŸŸ
                'reference_type': 'minimal_stable',
                'movement_pattern': 'conservative'
            },
            'right_upper_lid': {
                'points': [386, 387, 388, 387, 466],  # å³çœ¼ä¸Šçœ¼ç‘
                'reference_type': 'curve_center',
                'movement_pattern': 'smooth_curve'
            }
        }
    
    def calculate_zone_centers(self, landmarks_2d):
        """è®¡ç®—å„åŒºåŸŸçš„ä¸€è‡´æ€§å‚è€ƒä¸­å¿ƒ"""
        zone_centers = {}
        
        for zone_name, zone_config in self.MOVEMENT_ZONES.items():
            valid_points = []
            for point_idx in zone_config['points']:
                if point_idx < len(landmarks_2d):
                    valid_points.append(landmarks_2d[point_idx])
            
            if valid_points:
                if zone_config['reference_type'] == 'zone_center':
                    # å‡ ä½•ä¸­å¿ƒ
                    zone_centers[zone_name] = np.mean(valid_points, axis=0)
                elif zone_config['reference_type'] == 'curve_center':
                    # æ›²çº¿æ‹Ÿåˆä¸­å¿ƒ
                    zone_centers[zone_name] = self.fit_curve_center(valid_points)
                else:  # minimal_stable
                    # æœ€ç¨³å®šç‚¹ï¼ˆé€šå¸¸æ˜¯å†…çœ¦ï¼‰
                    zone_centers[zone_name] = valid_points[0]
        
        return zone_centers
    
    def fit_curve_center(self, points):
        """æ‹Ÿåˆæ›²çº¿è·å–ä¸­å¿ƒ"""
        if len(points) < 3:
            return np.mean(points, axis=0)
        
        # ç®€å•çš„æ¤­åœ†æ‹Ÿåˆ
        try:
            points_array = np.array(points, dtype=np.float32)
            ellipse = cv2.fitEllipse(points_array)
            return np.array(ellipse[0])
        except:
            return np.mean(points, axis=0)

class EnhancedEyeCornerAdjustment:
    def __init__(self):
        # MediaPipeè®¾ç½®
        self.mp_face_mesh = mp.solutions.face_mesh
        self.face_mesh = self.mp_face_mesh.FaceMesh(
            static_image_mode=True,
            max_num_faces=1,
            refine_landmarks=True,
            min_detection_confidence=0.8,
            min_tracking_confidence=0.8
        )
        
        # ç›¸æœºå‚æ•°
        self.camera_matrix = None
        self.dist_coeffs = None
        
        # åˆå§‹åŒ–å­æ¨¡å—
        self.eye_analyzer = EyeShapeAnalyzer()
        self.reference_system = ConsistentReferenceSystem()
        
        # å¢å¼ºçš„çœ¼è§’ç§»åŠ¨ç‚¹å®šä¹‰ï¼ˆåŸºäºåŒºåŸŸåŒ–è®¾è®¡ï¼‰
        self.LEFT_EYE_MOVEMENT_POINTS = {
            'primary_corners': [133, 33],        # ä¸»è¦çœ¼è§’ç‚¹
            'upper_lid_support': [157, 158, 159], # ä¸Šçœ¼ç‘æ”¯æ’‘ç‚¹
            'lower_lid_support': [145, 153, 154, 155], # ä¸‹çœ¼ç‘æ”¯æ’‘ç‚¹
            'transition_points': [160, 161, 163]   # è¿‡æ¸¡ç‚¹
        }
        
        self.RIGHT_EYE_MOVEMENT_POINTS = {
            'primary_corners': [362, 263],
            'upper_lid_support': [386, 387, 388],
            'lower_lid_support': [374, 380, 384, 385],
            'transition_points': [387, 466, 390]
        }
        
        # è¿œç¨‹ç¨³å®šé”šç‚¹ï¼ˆä¿æŒåŸæœ‰è®¾è®¡ï¼‰
        self.STABLE_ANCHORS = [
            1, 2, 5, 4, 6, 19, 20,  # é¼»å­åŒºåŸŸ
            9, 10, 151, 175,        # é¢å¤´å’Œä¸‹å·´
            61, 291, 39, 269, 270,  # å˜´å·´åŒºåŸŸ
            234, 93, 132, 454, 323, 361,  # è„¸é¢Šè¾¹ç¼˜
            70, 296, 107, 276       # çœ‰æ¯›åŒºåŸŸ
        ]
        
        # å¯¹ç§°è¾…åŠ©ç‚¹
        self.SYMMETRY_HELPERS = [168, 6, 8, 9]
        
        # 3Då§¿æ€å‚è€ƒç‚¹
        self.face_model_3d = np.array([
            [0.0, 0.0, 0.0],           # é¼»å°–
            [0.0, -330.0, -65.0],      # ä¸‹å·´
            [-225.0, 170.0, -135.0],   # å·¦çœ¼å¤–è§’
            [225.0, 170.0, -135.0],    # å³çœ¼å¤–è§’
            [-150.0, -150.0, -125.0],  # å·¦å˜´è§’
            [150.0, -150.0, -125.0],   # å³å˜´è§’
        ], dtype=np.float32)
        
        self.pnp_indices = [1, 152, 33, 263, 61, 291]
        
        # å®‰å…¨å‚æ•°
        self.MAX_INTENSITY = 0.4
        self.MAX_DISPLACEMENT = 40
        self.MIN_EYE_CORNER_AREA = 400
    
    def setup_camera(self, image_shape):
        """è®¾ç½®ç›¸æœºå‚æ•°"""
        h, w = image_shape[:2]
        focal_length = w
        center = (w/2, h/2)
        
        self.camera_matrix = np.array([
            [focal_length, 0, center[0]],
            [0, focal_length, center[1]],
            [0, 0, 1]
        ], dtype=np.float32)
        
        self.dist_coeffs = np.zeros((4,1), dtype=np.float32)
    
    def detect_landmarks_3d(self, image):
        """æ£€æµ‹é¢éƒ¨å…³é”®ç‚¹å¹¶è®¡ç®—3Då§¿æ€"""
        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        results = self.face_mesh.process(rgb_image)
        
        if not results.multi_face_landmarks:
            return None, None
        
        # è·å–2Då…³é”®ç‚¹
        landmarks_2d = []
        h, w = image.shape[:2]
        for landmark in results.multi_face_landmarks[0].landmark:
            x = int(landmark.x * w)
            y = int(landmark.y * h)
            landmarks_2d.append([x, y])
        
        landmarks_2d = np.array(landmarks_2d, dtype=np.float32)
        
        # è®¾ç½®ç›¸æœºå‚æ•°
        if self.camera_matrix is None:
            self.setup_camera(image.shape)
        
        # æå–ç”¨äºPnPçš„å…³é”®ç‚¹
        image_points = []
        for idx in self.pnp_indices:
            if idx < len(landmarks_2d):
                image_points.append(landmarks_2d[idx])
        
        if len(image_points) < 6:
            return landmarks_2d, None
        
        image_points = np.array(image_points, dtype=np.float32)
        
        # PnPæ±‚è§£3Då§¿æ€
        try:
            success, rotation_vector, translation_vector = cv2.solvePnP(
                self.face_model_3d, image_points, 
                self.camera_matrix, self.dist_coeffs,
                flags=cv2.SOLVEPNP_ITERATIVE
            )
            
            if success:
                return landmarks_2d, (rotation_vector, translation_vector)
            else:
                return landmarks_2d, None
                
        except Exception as e:
            print(f"âš ï¸  PnPæ±‚è§£å¼‚å¸¸: {e}")
            return landmarks_2d, None
    
    def estimate_face_pose_3d(self, rotation_vector):
        """åŸºäº3Dæ—‹è½¬å‘é‡ä¼°è®¡é¢éƒ¨å§¿æ€"""
        if rotation_vector is None:
            return "frontal", 0.0
        
        rotation_matrix, _ = cv2.Rodrigues(rotation_vector)
        sy = np.sqrt(rotation_matrix[0,0] * rotation_matrix[0,0] + rotation_matrix[1,0] * rotation_matrix[1,0])
        
        if sy > 1e-6:
            y = np.arctan2(-rotation_matrix[2,0], sy)
        else:
            y = np.arctan2(-rotation_matrix[2,0], sy)
        
        yaw = np.degrees(y)
        
        if abs(yaw) < 15:
            return "frontal", yaw
        elif yaw > 15:
            return "right_profile", yaw
        else:
            return "left_profile", yaw
    
    def calculate_enhanced_eye_centers(self, landmarks_2d, adjustment_type, eye_shape_info=None):
        """å¢å¼ºçš„çœ¼çƒä¸­å¿ƒè®¡ç®—ï¼Œè€ƒè™‘è°ƒæ•´ç±»å‹å’Œçœ¼å½¢"""
        
        # åŸºç¡€è®¡ç®—ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        basic_left_center = (landmarks_2d[33] + landmarks_2d[133]) / 2
        basic_right_center = (landmarks_2d[362] + landmarks_2d[263]) / 2
        
        # æ ¹æ®è°ƒæ•´ç±»å‹å’Œçœ¼å½¢å¾®è°ƒå‚è€ƒç‚¹
        offset = np.array([0, 0])
        
        if adjustment_type == "stretch":
            # æ‹‰é•¿æ—¶ï¼Œå‚è€ƒç‚¹ç¨å¾®å‘çœ¼ç‘ä¸­éƒ¨åç§»
            offset = np.array([0, 2])
        elif adjustment_type == "lift":
            # ä¸Šæ‰¬æ—¶ï¼Œå‚è€ƒç‚¹ä¿æŒåœ¨åŸä½ç½®
            offset = np.array([0, 0])
        else:  # shapeæ¨¡å¼
            # ç»¼åˆæ¨¡å¼ä½¿ç”¨åŠ¨æ€æƒé‡
            offset = np.array([1, 1])
        
        # åŸºäºçœ¼å½¢çš„ç‰¹æ®Šè°ƒæ•´
        if eye_shape_info:
            shape_type = eye_shape_info['eye_shape']['primary_type']
            if shape_type == 'round':
                # åœ†çœ¼éœ€è¦æ›´ç²¾ç¡®çš„æ‹‰é•¿å‚è€ƒç‚¹
                offset += np.array([0, 1])
            elif shape_type == 'elongated':
                # ç»†é•¿çœ¼é¿å…è¿‡åº¦æ‹‰é•¿
                offset = np.array([0, -1])
        
        left_center = basic_left_center + offset
        right_center = basic_right_center + offset
        
        return left_center, right_center
    
    def check_adjustment_compatibility(self, eye_shape_info, adjustment_type, intensity):
        """æ£€æŸ¥è°ƒæ•´ç±»å‹ä¸çœ¼å½¢çš„å…¼å®¹æ€§"""
        
        if not eye_shape_info:
            return {'suitable': True, 'confidence': 'medium'}
        
        shape_type = eye_shape_info['eye_shape']['primary_type']
        recommendations = eye_shape_info['recommendations']
        
        # æ£€æŸ¥ç¦å¿Œè°ƒæ•´
        if adjustment_type in recommendations['contraindicated']:
            alternative = recommendations['recommended_adjustments'][0] if recommendations['recommended_adjustments'] else 'stretch'
            return {
                'suitable': False,
                'warning': f"{shape_type}çœ¼å½¢ä¸å»ºè®®{adjustment_type}è°ƒæ•´",
                'suggestion': f"å»ºè®®ä½¿ç”¨{alternative}æ¨¡å¼",
                'auto_adjust': True,
                'recommended_type': alternative,
                'recommended_intensity': recommendations['optimal_intensities'].get(alternative, 0.25)
            }
        
        # æ£€æŸ¥è°ƒæ•´ç±»å‹æ˜¯å¦åœ¨æ¨èåˆ—è¡¨ä¸­
        if adjustment_type not in recommendations['recommended_adjustments']:
            return {
                'suitable': True,  # ä¸é˜»æ­¢ï¼Œä½†ç»™å‡ºè­¦å‘Š
                'warning': f"{adjustment_type}ä¸æ˜¯{shape_type}çœ¼å½¢çš„æœ€ä½³é€‰æ‹©",
                'suggestion': f"æ¨èä½¿ç”¨: {', '.join(recommendations['recommended_adjustments'])}",
                'auto_adjust': False
            }
        
        # æ£€æŸ¥å¼ºåº¦æ˜¯å¦åˆé€‚
        optimal_intensity = recommendations['optimal_intensities'].get(adjustment_type)
        if optimal_intensity and abs(intensity - optimal_intensity) > 0.15:
            return {
                'suitable': True,
                'warning': f"å½“å‰å¼ºåº¦{intensity:.2f}å¯èƒ½ä¸æ˜¯æœ€ä¼˜å€¼",
                'suggestion': f"å»ºè®®å¼ºåº¦: {optimal_intensity:.2f}",
                'auto_adjust': False,
                'recommended_intensity': optimal_intensity
            }
        
        return {
            'suitable': True, 
            'confidence': 'high',
            'message': f"âœ… {adjustment_type}è°ƒæ•´éå¸¸é€‚åˆ{shape_type}çœ¼å½¢"
        }
    
    def calculate_consistent_movement_vectors(self, landmarks_2d, eye_centers, adjustment_type, intensity, eye_shape_info):
        """è®¡ç®—ä¿è¯ä¸€è‡´æ€§çš„ç§»åŠ¨å‘é‡"""
        
        left_center, right_center = eye_centers
        movements = {}
        
        # ä¸ºå·¦çœ¼è®¡ç®—ç§»åŠ¨å‘é‡
        for point_category, point_indices in self.LEFT_EYE_MOVEMENT_POINTS.items():
            for point_idx in point_indices:
                if point_idx < len(landmarks_2d):
                    movement = self.calculate_single_point_movement(
                        landmarks_2d[point_idx], left_center, adjustment_type, 
                        intensity, point_category, 'left', eye_shape_info
                    )
                    movements[point_idx] = movement
        
        # ä¸ºå³çœ¼è®¡ç®—ç§»åŠ¨å‘é‡
        for point_category, point_indices in self.RIGHT_EYE_MOVEMENT_POINTS.items():
            for point_idx in point_indices:
                if point_idx < len(landmarks_2d):
                    movement = self.calculate_single_point_movement(
                        landmarks_2d[point_idx], right_center, adjustment_type, 
                        intensity, point_category, 'right', eye_shape_info
                    )
                    movements[point_idx] = movement
        
        # åº”ç”¨å¹³æ»‘åŒ–å¤„ç†ï¼Œç¡®ä¿ç›¸é‚»ç‚¹ç§»åŠ¨ä¸€è‡´æ€§
        movements = self.smooth_movement_vectors(movements, landmarks_2d)
        
        return movements
    
    def calculate_single_point_movement(self, point, eye_center, adjustment_type, intensity, point_category, eye_side, eye_shape_info):
        """è®¡ç®—å•ä¸ªç‚¹çš„ç§»åŠ¨å‘é‡"""
        
        # åŸºç¡€æ–¹å‘è®¡ç®—
        direction = point - eye_center
        direction_norm = np.linalg.norm(direction)
        
        if direction_norm <= 1e-6:
            return np.array([0.0, 0.0])
        
        direction = direction / direction_norm
        
        # æ ¹æ®ç‚¹çš„ç±»åˆ«ç¡®å®šç§»åŠ¨å¼ºåº¦
        category_multipliers = {
            'primary_corners': 1.0,      # ä¸»è¦çœ¼è§’ç‚¹
            'upper_lid_support': 0.7,    # ä¸Šçœ¼ç‘æ”¯æ’‘ç‚¹
            'lower_lid_support': 0.5,    # ä¸‹çœ¼ç‘æ”¯æ’‘ç‚¹
            'transition_points': 0.3     # è¿‡æ¸¡ç‚¹
        }
        
        base_multiplier = category_multipliers.get(point_category, 0.5)
        
        # æ ¹æ®çœ¼å½¢è°ƒæ•´å¼ºåº¦
        if eye_shape_info:
            shape_type = eye_shape_info['eye_shape']['primary_type']
            if shape_type == 'round' and adjustment_type == 'stretch':
                base_multiplier *= 1.2  # åœ†çœ¼æ‹‰é•¿éœ€è¦æ›´å¤§å¼ºåº¦
            elif shape_type == 'almond':
                base_multiplier *= 0.8  # æä»çœ¼éœ€è¦ä¿å®ˆè°ƒæ•´
        
        # è®¡ç®—æœ€ç»ˆç§»åŠ¨é‡
        if adjustment_type == "stretch":
            # æ‹‰é•¿ï¼šæ²¿å¾„å‘æ–¹å‘
            movement_vector = direction
            movement_scale = intensity * base_multiplier * 12
            
        elif adjustment_type == "lift":
            # ä¸Šæ‰¬ï¼šç»“åˆå¾„å‘å’Œå‘ä¸Šæ–¹å‘
            if point_category == 'primary_corners':
                # ä¸»è¦çœ¼è§’ç‚¹ï¼šå¼ºè°ƒä¸Šæ‰¬
                lift_component = np.array([0, -1]) * 0.8
                movement_vector = direction * 0.4 + lift_component * 0.6
            else:
                # å…¶ä»–ç‚¹ï¼šè½»å¾®è·Ÿéš
                lift_component = np.array([0, -1]) * 0.3
                movement_vector = direction * 0.7 + lift_component * 0.3
            
            movement_vector = movement_vector / np.linalg.norm(movement_vector)
            movement_scale = intensity * base_multiplier * 10
            
        else:  # shapeæ¨¡å¼
            # ç»¼åˆï¼šæ‹‰é•¿+ä¸Šæ‰¬
            stretch_component = direction * 0.6
            lift_component = np.array([0, -1]) * 0.4
            movement_vector = stretch_component + lift_component
            movement_vector = movement_vector / np.linalg.norm(movement_vector)
            movement_scale = intensity * base_multiplier * 11
        
        return movement_vector * movement_scale
    
    def smooth_movement_vectors(self, movements, landmarks_2d):
        """å¹³æ»‘åŒ–ç§»åŠ¨å‘é‡ï¼Œé¿å…ç›¸é‚»ç‚¹å†²çª"""
        
        # å®šä¹‰ç›¸é‚»ç‚¹å…³ç³»
        adjacent_pairs = [
            (33, 7), (7, 163), (163, 144), (144, 145),    # å·¦çœ¼å¤–è§’åŒºåŸŸ
            (157, 158), (158, 159), (159, 160),           # å·¦çœ¼ä¸Šçœ¼ç‘
            (263, 249), (249, 390), (390, 373),           # å³çœ¼å¤–è§’åŒºåŸŸ
            (386, 387), (387, 388)                        # å³çœ¼ä¸Šçœ¼ç‘
        ]
        
        smoothed_movements = movements.copy()
        
        for point1, point2 in adjacent_pairs:
            if point1 in movements and point2 in movements:
                # æ£€æŸ¥ç§»åŠ¨å‘é‡çš„è§’åº¦å·®å¼‚
                vec1 = movements[point1]
                vec2 = movements[point2]
                
                vec1_norm = np.linalg.norm(vec1)
                vec2_norm = np.linalg.norm(vec2)
                
                if vec1_norm > 0 and vec2_norm > 0:
                    # è®¡ç®—è§’åº¦å·®å¼‚
                    cos_angle = np.dot(vec1, vec2) / (vec1_norm * vec2_norm)
                    cos_angle = np.clip(cos_angle, -1, 1)
                    angle_diff = np.degrees(np.arccos(cos_angle))
                    
                    # å¦‚æœè§’åº¦å·®å¼‚è¿‡å¤§ï¼Œè¿›è¡Œå¹³æ»‘å¤„ç†
                    if angle_diff > 45:
                        # ä½¿ç”¨åŠ æƒå¹³å‡
                        avg_direction = (vec1 + vec2) / 2
                        avg_direction = avg_direction / np.linalg.norm(avg_direction)
                        
                        # ä¿æŒåŸå§‹ç§»åŠ¨å¤§å°ï¼Œåªè°ƒæ•´æ–¹å‘
                        smoothed_movements[point1] = avg_direction * vec1_norm
                        smoothed_movements[point2] = avg_direction * vec2_norm
        
        return smoothed_movements
    
    def create_safe_eye_corner_mask(self, image_shape, landmarks_2d):
        """åˆ›å»ºå®‰å…¨çš„çœ¼è§’mask"""
        h, w = image_shape[:2]
        mask = np.zeros((h, w), dtype=np.uint8)
        
        # æ”¶é›†æ‰€æœ‰ç§»åŠ¨ç‚¹
        all_movement_points = []
        
        for point_group in [self.LEFT_EYE_MOVEMENT_POINTS, self.RIGHT_EYE_MOVEMENT_POINTS]:
            for point_list in point_group.values():
                for idx in point_list:
                    if idx < len(landmarks_2d):
                        all_movement_points.append(landmarks_2d[idx])
        
        if len(all_movement_points) < 8:
            return mask
        
        all_movement_points = np.array(all_movement_points, dtype=np.int32)
        
        # ä¸ºæ¯ä¸ªç‚¹åˆ›å»ºå°åœ†å½¢åŒºåŸŸ
        for point in all_movement_points:
            cv2.circle(mask, tuple(point), 10, 255, -1)
        
        # è½»å¾®è†¨èƒ€å’Œè…èš€
        kernel = np.ones((3,3), np.uint8)
        mask = cv2.dilate(mask, kernel, iterations=1)
        mask = cv2.erode(mask, kernel, iterations=1)
        
        return mask
    
    def apply_enhanced_eye_corner_transform(self, image, landmarks_2d, pose_info, adjustment_type="stretch", intensity=0.3, eye_shape_info=None):
        """åº”ç”¨å¢å¼ºçš„çœ¼è§’å˜å½¢"""
        
        # 3Då§¿æ€åˆ†æ
        if pose_info is None:
            pose_3d, pose_angle = "frontal", 0.0
        else:
            rotation_vector, translation_vector = pose_info
            pose_3d, pose_angle = self.estimate_face_pose_3d(rotation_vector)
        
        print(f"ğŸ” 3Då§¿æ€: {pose_3d} ({pose_angle:.1f}åº¦)")
        
        # è®¡ç®—å¢å¼ºçš„çœ¼çƒä¸­å¿ƒ
        eye_centers = self.calculate_enhanced_eye_centers(landmarks_2d, adjustment_type, eye_shape_info)
        left_center, right_center = eye_centers
        
        print(f"ğŸ“ å¢å¼ºå‚è€ƒç‚¹: å·¦çœ¼({left_center[0]:.0f},{left_center[1]:.0f}), å³çœ¼({right_center[0]:.0f},{right_center[1]:.0f})")
        
        # æ ¹æ®3Då§¿æ€è°ƒæ•´å¼ºåº¦
        if pose_3d == "frontal":
            left_intensity = right_intensity = intensity
        elif pose_3d == "right_profile":
            right_intensity = intensity * 1.0
            left_intensity = intensity * 0.7
        else:  # left_profile
            left_intensity = intensity * 1.0
            right_intensity = intensity * 0.7
        
        # è®¡ç®—ä¸€è‡´æ€§ç§»åŠ¨å‘é‡
        movement_vectors = self.calculate_consistent_movement_vectors(
            landmarks_2d, eye_centers, adjustment_type, intensity, eye_shape_info
        )
        
        # æ„å»ºæ§åˆ¶ç‚¹
        src_points = []
        dst_points = []
        used_indices = set()
        
        # æ·»åŠ ç§»åŠ¨ç‚¹
        movement_count = 0
        for point_idx, movement in movement_vectors.items():
            if point_idx < len(landmarks_2d):
                src_points.append(landmarks_2d[point_idx])
                dst_points.append(landmarks_2d[point_idx] + movement)
                used_indices.add(point_idx)
                movement_count += 1
        
        # æ·»åŠ ç¨³å®šé”šç‚¹
        anchor_count = 0
        for idx in self.STABLE_ANCHORS:
            if idx < len(landmarks_2d) and idx not in used_indices:
                src_points.append(landmarks_2d[idx])
                dst_points.append(landmarks_2d[idx])
                used_indices.add(idx)
                anchor_count += 1
        
        # æ·»åŠ å¯¹ç§°è¾…åŠ©ç‚¹
        symmetry_count = 0
        for idx in self.SYMMETRY_HELPERS:
            if idx < len(landmarks_2d) and idx not in used_indices:
                src_points.append(landmarks_2d[idx])
                dst_points.append(landmarks_2d[idx])
                used_indices.add(idx)
                symmetry_count += 1
        
        # æ·»åŠ è¾¹ç•Œé”šç‚¹
        h, w = image.shape[:2]
        boundary_points = [
            [30, 30], [w//2, 30], [w-30, 30],
            [30, h//2], [w-30, h//2],
            [30, h-30], [w//2, h-30], [w-30, h-30]
        ]
        
        for bp in boundary_points:
            src_points.append(bp)
            dst_points.append(bp)
        
        print(f"ğŸ”§ æ§åˆ¶ç‚¹ç»Ÿè®¡:")
        print(f"   ç§»åŠ¨ç‚¹: {movement_count}")
        print(f"   ç¨³å®šé”šç‚¹: {anchor_count}")
        print(f"   å¯¹ç§°è¾…åŠ©ç‚¹: {symmetry_count}")
        print(f"   è¾¹ç•Œé”šç‚¹: 8")
        print(f"   æ€»è®¡: {len(src_points)} ä¸ªæ§åˆ¶ç‚¹")
        
        # éªŒè¯æ§åˆ¶ç‚¹æ•°é‡
        if len(src_points) < 15:
            print("âŒ æ§åˆ¶ç‚¹æ•°é‡ä¸è¶³")
            return image
        
        # æ‰§è¡ŒTPSå˜å½¢
        try:
            src_points = np.array(src_points, dtype=np.float32)
            dst_points = np.array(dst_points, dtype=np.float32)
            
            tps = cv2.createThinPlateSplineShapeTransformer()
            matches = [cv2.DMatch(i, i, 0) for i in range(len(src_points))]
            
            print(f"ğŸ”„ å¼€å§‹å¢å¼ºTPSå˜æ¢ï¼ˆ{adjustment_type}æ¨¡å¼ï¼‰...")
            tps.estimateTransformation(
                dst_points.reshape(1, -1, 2), 
                src_points.reshape(1, -1, 2), 
                matches
            )
            
            # TPSå˜å½¢
            transformed = tps.warpImage(image)
            
            if transformed is None:
                print("âŒ TPSå˜æ¢å¤±è´¥")
                return image
            
            # åˆ›å»ºå®‰å…¨mask
            eye_corner_mask = self.create_safe_eye_corner_mask(image.shape, landmarks_2d)
            
            # å®‰å…¨èåˆ
            mask_3d = cv2.merge([eye_corner_mask, eye_corner_mask, eye_corner_mask]).astype(np.float32) / 255.0
            mask_blurred = cv2.GaussianBlur(mask_3d, (5, 5), 0)
            
            result = image.astype(np.float32) * (1 - mask_blurred) + transformed.astype(np.float32) * mask_blurred
            result = np.clip(result, 0, 255).astype(np.uint8)
            
            print("âœ… å¢å¼ºçœ¼è§’å˜å½¢æˆåŠŸ")
            return result
            
        except Exception as e:
            print(f"âŒ TPSå˜å½¢å¼‚å¸¸: {e}")
            return image
    
    def debug_enhanced_detection(self, image, save_dir=None):
        """å¢å¼ºçš„è°ƒè¯•çœ¼è§’æ£€æµ‹"""
        landmarks_2d, pose_info = self.detect_landmarks_3d(image)
        if landmarks_2d is None:
            print("âŒ æœªæ£€æµ‹åˆ°é¢éƒ¨å…³é”®ç‚¹")
            return image
        
        # è¿›è¡Œçœ¼å½¢åˆ†æ
        eye_shape_info = self.eye_analyzer.analyze_eye_shape(landmarks_2d)
        
        debug_img = image.copy()
        
        # ç»˜åˆ¶ç§»åŠ¨ç‚¹ï¼ˆæŒ‰ç±»åˆ«ç”¨ä¸åŒé¢œè‰²ï¼‰
        colors = {
            'primary_corners': (0, 255, 0),     # ç»¿è‰² - ä¸»è¦çœ¼è§’
            'upper_lid_support': (255, 0, 0),   # çº¢è‰² - ä¸Šçœ¼ç‘
            'lower_lid_support': (0, 0, 255),   # è“è‰² - ä¸‹çœ¼ç‘
            'transition_points': (255, 255, 0)  # é»„è‰² - è¿‡æ¸¡ç‚¹
        }
        
        # å·¦çœ¼ç§»åŠ¨ç‚¹
        for category, point_indices in self.LEFT_EYE_MOVEMENT_POINTS.items():
            color = colors[category]
            for i, idx in enumerate(point_indices):
                if idx < len(landmarks_2d):
                    point = landmarks_2d[idx].astype(int)
                    cv2.circle(debug_img, tuple(point), 6, color, -1)
                    cv2.putText(debug_img, f"L{category[0]}{i}", tuple(point + 8), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.3, color, 1)
        
        # å³çœ¼ç§»åŠ¨ç‚¹
        for category, point_indices in self.RIGHT_EYE_MOVEMENT_POINTS.items():
            color = colors[category]
            for i, idx in enumerate(point_indices):
                if idx < len(landmarks_2d):
                    point = landmarks_2d[idx].astype(int)
                    cv2.circle(debug_img, tuple(point), 6, color, -1)
                    cv2.putText(debug_img, f"R{category[0]}{i}", tuple(point + 8), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.3, color, 1)
        
        # ç»˜åˆ¶å¢å¼ºçš„çœ¼çƒä¸­å¿ƒ
        left_center, right_center = self.calculate_enhanced_eye_centers(landmarks_2d, "stretch", eye_shape_info)
        cv2.circle(debug_img, tuple(left_center.astype(int)), 8, (255, 255, 0), -1)
        cv2.circle(debug_img, tuple(right_center.astype(int)), 8, (255, 255, 0), -1)
        cv2.putText(debug_img, 'L-CENTER', tuple(left_center.astype(int) + 10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)
        cv2.putText(debug_img, 'R-CENTER', tuple(right_center.astype(int) + 10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)
        
        # æ˜¾ç¤ºçœ¼å½¢åˆ†æç»“æœ
        shape_info = eye_shape_info['eye_shape']
        measurements = eye_shape_info['measurements']
        
        info_y = 30
        cv2.putText(debug_img, f"Eye Shape: {shape_info['primary_type']} ({shape_info['confidence']:.2f})", 
                   (10, info_y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        
        cv2.putText(debug_img, f"L/W Ratio: {measurements['length_width_ratio']:.2f}", 
                   (10, info_y + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        
        cv2.putText(debug_img, f"Tilt Angle: {measurements['tilt_angle']:.1f}Â°", 
                   (10, info_y + 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        
        # æ˜¾ç¤ºæ¨èè°ƒæ•´
        recommendations = eye_shape_info['recommendations']['recommended_adjustments']
        cv2.putText(debug_img, f"Recommended: {', '.join(recommendations)}", 
                   (10, info_y + 90), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
        
        # æ˜¾ç¤ºç¦å¿Œè°ƒæ•´
        contraindicated = eye_shape_info['recommendations'].get('contraindicated', [])
        if contraindicated:
            cv2.putText(debug_img, f"Avoid: {', '.join(contraindicated)}", 
                       (10, info_y + 120), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
        
        # ç»˜åˆ¶ç¨³å®šé”šç‚¹
        for i, idx in enumerate(self.STABLE_ANCHORS[:8]):
            if idx < len(landmarks_2d):
                point = landmarks_2d[idx].astype(int)
                cv2.circle(debug_img, tuple(point), 3, (128, 128, 128), -1)
        
        # å›¾ä¾‹
        legend_y = info_y + 160
        legends = [
            ("GREEN: Primary Corners", (0, 255, 0)),
            ("RED: Upper Lid Support", (255, 0, 0)),
            ("BLUE: Lower Lid Support", (0, 0, 255)),
            ("YELLOW: Transition Points", (255, 255, 0)),
            ("CYAN: Enhanced Eye Centers", (255, 255, 0)),
            ("GRAY: Stable Anchors", (128, 128, 128))
        ]
        
        for i, (text, color) in enumerate(legends):
            cv2.putText(debug_img, text, (10, legend_y + i * 20), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
        
        if save_dir:
            os.makedirs(save_dir, exist_ok=True)
            cv2.imwrite(os.path.join(save_dir, "debug_enhanced_eye_corner.png"), debug_img)
            print(f"ğŸ“ è°ƒè¯•æ–‡ä»¶ä¿å­˜åˆ°: {save_dir}")
        
        return debug_img
    
    def process_image_with_analysis(self, image, adjustment_type="stretch", intensity=0.3, save_debug=False, output_path=None):
        """å¢åŠ çœ¼å½¢åˆ†æçš„å›¾åƒå¤„ç†ä¸»æ¥å£"""
        
        landmarks_2d, pose_info = self.detect_landmarks_3d(image)
        if landmarks_2d is None:
            print("âŒ æœªæ£€æµ‹åˆ°é¢éƒ¨å…³é”®ç‚¹")
            return image
        
        print(f"âœ… æ£€æµ‹åˆ° {len(landmarks_2d)} ä¸ªå…³é”®ç‚¹")
        
        # ğŸ†• çœ¼å½¢é¢„åˆ†æ
        print("ğŸ” æ­£åœ¨åˆ†æçœ¼å½¢ç‰¹å¾...")
        eye_shape_info = self.eye_analyzer.analyze_eye_shape(landmarks_2d)
        
        shape_result = eye_shape_info['eye_shape']
        measurements = eye_shape_info['measurements']
        
        print(f"ğŸ‘ï¸ çœ¼å½¢è¯†åˆ«ç»“æœ:")
        print(f"   ç±»å‹: {shape_result['primary_type']} (ç½®ä¿¡åº¦: {shape_result['confidence']:.2f})")
        print(f"   é•¿å®½æ¯”: {measurements['length_width_ratio']:.2f}")
        print(f"   å€¾æ–œè§’: {measurements['tilt_angle']:.1f}Â°")
        print(f"   å¯¹ç§°æ€§: {measurements['symmetry_score']:.2f}")
        print(f"   æè¿°: {eye_shape_info['recommendations']['description']}")
        
        # ğŸ†• è°ƒæ•´ç±»å‹é€‚é…æ€§æ£€æŸ¥
        compatibility = self.check_adjustment_compatibility(eye_shape_info, adjustment_type, intensity)
        
        if not compatibility['suitable']:
            print(f"âš ï¸ {compatibility['warning']}")
            print(f"ğŸ’¡ {compatibility['suggestion']}")
            
            if compatibility.get('auto_adjust'):
                print(f"ğŸ”„ è‡ªåŠ¨è°ƒæ•´: {adjustment_type} â†’ {compatibility['recommended_type']}")
                adjustment_type = compatibility['recommended_type']
                intensity = compatibility['recommended_intensity']
        elif 'message' in compatibility:
            print(compatibility['message'])
        
        # ğŸ†• åŸºäºçœ¼å½¢çš„å¼ºåº¦ä¼˜åŒ–
        recommendations = eye_shape_info['recommendations']
        if adjustment_type in recommendations['optimal_intensities']:
            optimal_intensity = recommendations['optimal_intensities'][adjustment_type]
            if abs(intensity - optimal_intensity) > 0.1:
                print(f"ğŸ’¡ å»ºè®®å¼ºåº¦: {optimal_intensity:.2f} (å½“å‰: {intensity:.2f})")
        
        # è°ƒè¯•æ¨¡å¼
        if save_debug and output_path:
            debug_dir = os.path.splitext(output_path)[0] + "_debug"
            self.debug_enhanced_detection(image, debug_dir)
        
        # åº”ç”¨å¢å¼ºçš„çœ¼è§’å˜å½¢
        result = self.apply_enhanced_eye_corner_transform(
            image, landmarks_2d, pose_info, adjustment_type, intensity, eye_shape_info
        )
        
        return result

def main():
    parser = argparse.ArgumentParser(description='å¢å¼ºçš„çœ¼è§’è°ƒæ•´å·¥å…· - åŸºäºå…ˆéªŒçŸ¥è¯†å’Œä¸€è‡´æ€§å‚è€ƒç‚¹')
    parser.add_argument('--input', '-i', required=True, help='è¾“å…¥å›¾ç‰‡è·¯å¾„')
    parser.add_argument('--output', '-o', required=True, help='è¾“å‡ºå›¾ç‰‡è·¯å¾„')
    parser.add_argument('--type', '-t', choices=['stretch', 'lift', 'shape'], 
                       default='stretch', help='è°ƒæ•´ç±»å‹: stretch=æ°´å¹³æ‹‰é•¿, lift=çœ¼è§’ä¸Šæ‰¬, shape=ç»¼åˆè°ƒæ•´')
    parser.add_argument('--intensity', type=float, default=0.3, 
                       help='è°ƒæ•´å¼ºåº¦ (0.1-0.4)')
    parser.add_argument('--debug', action='store_true', help='è°ƒè¯•æ¨¡å¼')
    parser.add_argument('--save-debug', action='store_true', help='ä¿å­˜è°ƒè¯•æ–‡ä»¶')
    parser.add_argument('--comparison', action='store_true', help='ç”Ÿæˆå¯¹æ¯”å›¾')
    parser.add_argument('--auto-optimize', action='store_true', help='è‡ªåŠ¨ä¼˜åŒ–å‚æ•°')
    
    args = parser.parse_args()
    
    # åŠ è½½å›¾ç‰‡
    image = cv2.imread(args.input)
    if image is None:
        print(f"âŒ æ— æ³•åŠ è½½å›¾ç‰‡: {args.input}")
        return
    
    print(f"ğŸ“¸ å›¾ç‰‡å°ºå¯¸: {image.shape}")
    
    # å¼ºåº¦å®‰å…¨æ£€æŸ¥
    if args.intensity > 0.4:
        print(f"âš ï¸  å¼ºåº¦ {args.intensity} è¶…å‡ºå»ºè®®èŒƒå›´ï¼Œé™åˆ¶åˆ°0.4")
        args.intensity = 0.4
    elif args.intensity < 0.1:
        print(f"âš ï¸  å¼ºåº¦ {args.intensity} è¿‡å°ï¼Œæå‡åˆ°0.1")
        args.intensity = 0.1
    
    # åˆ›å»ºå¢å¼ºå¤„ç†å™¨
    processor = EnhancedEyeCornerAdjustment()
    
    # è°ƒè¯•æ¨¡å¼
    if args.debug:
        debug_result = processor.debug_enhanced_detection(image)
        cv2.imwrite(args.output, debug_result)
        print(f"ğŸ” è°ƒè¯•å›¾ä¿å­˜åˆ°: {args.output}")
        return
    
    # å¤„ç†å›¾ç‰‡
    print(f"ğŸ”„ å¼€å§‹å¢å¼ºçœ¼è§’å¤„ç†...")
    print(f"   è°ƒæ•´ç±»å‹: {args.type}")
    print(f"   è°ƒæ•´å¼ºåº¦: {args.intensity}")
    print(f"   è‡ªåŠ¨ä¼˜åŒ–: {'å¼€å¯' if args.auto_optimize else 'å…³é—­'}")
    
    result = processor.process_image_with_analysis(
        image, args.type, args.intensity, args.save_debug, args.output
    )
    
    # ä¿å­˜ç»“æœ
    cv2.imwrite(args.output, result)
    print(f"âœ… å¤„ç†å®Œæˆï¼Œä¿å­˜åˆ°: {args.output}")
    
    # æ£€æŸ¥å˜åŒ–ç»Ÿè®¡
    diff = cv2.absdiff(image, result)
    total_diff = np.sum(diff)
    max_diff = np.max(diff)
    changed_pixels = np.sum(diff > 0)
    
    print(f"ğŸ“Š åƒç´ å˜åŒ–ç»Ÿè®¡:")
    print(f"   æ€»å·®å¼‚: {total_diff}")
    print(f"   æœ€å¤§å·®å¼‚: {max_diff}")
    print(f"   å˜åŒ–åƒç´ æ•°: {changed_pixels}")
    
    if total_diff < 1000:
        print("âš ï¸  å˜åŒ–å¾ˆå°ï¼Œå¯èƒ½éœ€è¦ï¼š")
        print("   1. æé«˜ --intensity å‚æ•°")
        print("   2. ä½¿ç”¨ --auto-optimize è‡ªåŠ¨ä¼˜åŒ–å‚æ•°")
        print("   3. æ£€æŸ¥çœ¼å½¢æ˜¯å¦é€‚åˆå½“å‰è°ƒæ•´ç±»å‹ (--debug)")
    
    # ç”Ÿæˆå¯¹æ¯”å›¾
    if args.comparison:
        comparison_path = args.output.replace('.', '_comparison.')
        comparison = np.hstack([image, result])
        cv2.line(comparison, (image.shape[1], 0), (image.shape[1], image.shape[0]), (0, 255, 0), 3)
        
        # æ·»åŠ æ ‡ç­¾
        cv2.putText(comparison, 'Original', (20, 50), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3)
        cv2.putText(comparison, f'Enhanced-{args.type.upper()} {args.intensity:.2f}', 
                   (image.shape[1] + 20, 50), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)
        
        cv2.imwrite(comparison_path, comparison)
        print(f"ğŸ“Š å¯¹æ¯”å›¾ä¿å­˜åˆ°: {comparison_path}")
    
    print("\nğŸ¯ å¢å¼ºç‰ˆè®¾è®¡ç‰¹è‰²:")
    print("âœ… çœ¼å½¢æ™ºèƒ½è¯†åˆ«: 6ç§æ ‡å‡†çœ¼å½¢åˆ†ç±»ï¼ŒåŒ»å­¦ç¾å­¦åŸºå‡†")
    print("âœ… å…ˆéªŒçŸ¥è¯†ç³»ç»Ÿ: åŸºäºçœ¼å½¢æ¨èæœ€ä½³è°ƒæ•´ç±»å‹å’Œå¼ºåº¦")
    print("âœ… ä¸€è‡´æ€§å‚è€ƒç‚¹: åŒºåŸŸåŒ–è®¾è®¡ï¼Œé¿å…ç§»åŠ¨å‘é‡å†²çª")
    print("âœ… é€‚é…æ€§æ£€æŸ¥: è‡ªåŠ¨æ£€æµ‹è°ƒæ•´ç±»å‹ä¸çœ¼å½¢çš„å…¼å®¹æ€§")
    print("âœ… å¹³æ»‘åŒ–å¤„ç†: ç›¸é‚»ç‚¹ç§»åŠ¨å‘é‡å¹³æ»‘ï¼Œç¡®ä¿æ’å€¼æˆåŠŸ")
    print("âœ… å®‰å…¨çº¦æŸ: åŸºäºçœ¼å½¢çš„å¼ºåº¦é™åˆ¶å’Œç¦å¿Œè°ƒæ•´")
    
    print("\nğŸ“– ä½¿ç”¨ç¤ºä¾‹:")
    print("â€¢ æ™ºèƒ½çœ¼è§’è°ƒæ•´: python script.py -i input.jpg -o output.png --auto-optimize --comparison")
    print("â€¢ çœ¼å½¢åˆ†æè°ƒè¯•: python script.py -i input.jpg -o debug.png --debug")
    print("â€¢ åœ†çœ¼æ‹‰é•¿ä¼˜åŒ–: python script.py -i input.jpg -o output.png -t stretch --intensity 0.35")
    print("â€¢ ä¸‹å‚çœ¼ä¸Šæ‰¬: python script.py -i input.jpg -o output.png -t lift --intensity 0.4")

if __name__ == "__main__":
    main()
