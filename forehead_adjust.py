#!/usr/bin/env python3
"""
é¢å¤´è°ƒæ•´è„šæœ¬ - forehead_adjust.py
ç²¾ç¡®ç‰ˆæœ¬ï¼šåªä½¿ç”¨ç¡®è®¤çš„é¢å¤´ç‚¹ï¼Œé‡‡ç”¨æ›´æœ‰æ•ˆçš„å˜å½¢ç­–ç•¥
å€Ÿé‰´ç˜¦è„¸æˆåŠŸç»éªŒï¼Œä¸“æ³¨å‘é™…çº¿å’Œé¢å¤´é«˜åº¦è°ƒæ•´
"""

import cv2
import numpy as np
import mediapipe as mp
import argparse
import os

class ForeheadAdjustment:
    def __init__(self):
        # MediaPipeè®¾ç½®
        self.mp_face_mesh = mp.solutions.face_mesh
        self.face_mesh = self.mp_face_mesh.FaceMesh(
            static_image_mode=True,
            max_num_faces=1,
            refine_landmarks=True,
            min_detection_confidence=0.8,
            min_tracking_confidence=0.8
        )
        
        # ç›¸æœºå‚æ•°
        self.camera_matrix = None
        self.dist_coeffs = None
        
        # ç²¾ç¡®çš„é¢å¤´æ§åˆ¶ç‚¹ï¼ˆåªä½¿ç”¨ç¡®è®¤çš„MediaPipeé¢å¤´ç‚¹ï¼‰
        self.FOREHEAD_CENTER = [10, 9, 151]                    # ä¸­å¤®è„Šæ¤ï¼ˆå›ºå®šï¼‰
        self.FOREHEAD_LEFT = [66, 107]                         # å·¦ä¾§é¢å¤´ä¸»ç‚¹
        self.FOREHEAD_RIGHT = [336, 296]                       # å³ä¾§é¢å¤´ä¸»ç‚¹
        
        # å‘é™…çº¿ç›¸å…³ç‚¹ï¼ˆé¢å¤´ä¸Šè¾¹ç¼˜ï¼‰
        self.HAIRLINE_POINTS = [
            67, 69, 70, 71,                # å·¦ä¾§å‘é™…çº¿
            299, 333, 298, 301              # å³ä¾§å‘é™…çº¿
        ]
        
        # çœ‰æ¯›ä¸Šæ–¹ç‚¹ï¼ˆé¢å¤´ä¸‹è¾¹ç¼˜ï¼‰
        self.EYEBROW_UPPER = [
            55, 65, 52, 53,                # å·¦çœ‰ä¸Šæ–¹
            285, 295, 282, 283              # å³çœ‰ä¸Šæ–¹
        ]
        
        # å¤ªé˜³ç©´åŒºåŸŸç‚¹
        self.TEMPLE_POINTS = [234, 454]    # å·¦å³å¤ªé˜³ç©´
        
        # ç¨³å®šé”šç‚¹ï¼ˆè¿œç¦»é¢å¤´çš„ç‚¹ï¼‰
        self.STABLE_ANCHORS = [
            # çœ¼éƒ¨
            33, 133, 362, 263, 7, 163, 144, 145, 153, 154, 155, 173,
            # é¼»å­
            1, 2, 5, 4, 6, 19, 20,
            # å˜´éƒ¨
            61, 291, 39, 269, 270, 0, 17, 18,
            # ä¸‹è„¸è½®å»“
            200, 199, 175, 164, 136, 150, 149, 176, 148, 152
        ]
        
        # 3Dé¢éƒ¨æ¨¡å‹
        self.face_model_3d = np.array([
            [0.0, 0.0, 0.0],
            [0.0, -330.0, -65.0],
            [-225.0, 170.0, -135.0],
            [225.0, 170.0, -135.0],
            [-150.0, -150.0, -125.0],
            [150.0, -150.0, -125.0],
        ], dtype=np.float32)
        
        self.pnp_indices = [1, 152, 33, 263, 61, 291]
    
    def setup_camera(self, image_shape):
        """è®¾ç½®ç›¸æœºå‚æ•°"""
        h, w = image_shape[:2]
        focal_length = w
        center = (w/2, h/2)
        
        self.camera_matrix = np.array([
            [focal_length, 0, center[0]],
            [0, focal_length, center[1]],
            [0, 0, 1]
        ], dtype=np.float32)
        
        self.dist_coeffs = np.zeros((4,1), dtype=np.float32)
    
    def detect_landmarks_3d(self, image):
        """æ£€æµ‹é¢éƒ¨å…³é”®ç‚¹å¹¶è®¡ç®—3Då§¿æ€"""
        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        results = self.face_mesh.process(rgb_image)
        
        if not results.multi_face_landmarks:
            return None, None
        
        # è·å–2Då…³é”®ç‚¹
        landmarks_2d = []
        h, w = image.shape[:2]
        for landmark in results.multi_face_landmarks[0].landmark:
            x = int(landmark.x * w)
            y = int(landmark.y * h)
            landmarks_2d.append([x, y])
        
        landmarks_2d = np.array(landmarks_2d, dtype=np.float32)
        
        # è®¾ç½®ç›¸æœºå‚æ•°
        if self.camera_matrix is None:
            self.setup_camera(image.shape)
        
        # æå–ç”¨äºPnPçš„å…³é”®ç‚¹
        image_points = []
        for idx in self.pnp_indices:
            if idx < len(landmarks_2d):
                image_points.append(landmarks_2d[idx])
        
        if len(image_points) < 6:
            print("âš ï¸  PnPå…³é”®ç‚¹ä¸è¶³")
            return landmarks_2d, None
        
        image_points = np.array(image_points, dtype=np.float32)
        
        # PnPæ±‚è§£3Då§¿æ€
        try:
            success, rotation_vector, translation_vector = cv2.solvePnP(
                self.face_model_3d, image_points, 
                self.camera_matrix, self.dist_coeffs,
                flags=cv2.SOLVEPNP_ITERATIVE
            )
            
            if not success:
                print("âš ï¸  PnPæ±‚è§£å¤±è´¥")
                return landmarks_2d, None
            
            return landmarks_2d, (rotation_vector, translation_vector)
            
        except Exception as e:
            print(f"âš ï¸  PnPæ±‚è§£å¼‚å¸¸: {e}")
            return landmarks_2d, None
    
    def estimate_face_pose_3d(self, rotation_vector):
        """ä¼°è®¡é¢éƒ¨å§¿æ€"""
        if rotation_vector is None:
            return "frontal"
        
        rotation_matrix, _ = cv2.Rodrigues(rotation_vector)
        sy = np.sqrt(rotation_matrix[0,0] * rotation_matrix[0,0] + rotation_matrix[1,0] * rotation_matrix[1,0])
        
        if sy > 1e-6:
            y = np.arctan2(-rotation_matrix[2,0], sy)
        else:
            y = np.arctan2(-rotation_matrix[2,0], sy)
        
        yaw = np.degrees(y)
        print(f"ğŸ” 3Då§¿æ€æ£€æµ‹: Yaw = {yaw:.1f}åº¦")
        
        if abs(yaw) < 15:
            return "frontal"
        elif yaw > 15:
            return "right_profile"
        else:
            return "left_profile"
    
    def create_forehead_mask(self, image_shape, landmarks_2d):
        """åˆ›å»ºç²¾ç¡®çš„é¢å¤´mask"""
        h, w = image_shape[:2]
        mask = np.zeros((h, w), dtype=np.uint8)
        
        # æ”¶é›†ç¡®è®¤çš„é¢å¤´ç‚¹
        forehead_points = []
        all_points = (self.FOREHEAD_CENTER + self.FOREHEAD_LEFT + self.FOREHEAD_RIGHT + 
                     self.HAIRLINE_POINTS + self.EYEBROW_UPPER + self.TEMPLE_POINTS)
        
        for idx in all_points:
            if idx < len(landmarks_2d):
                forehead_points.append(landmarks_2d[idx])
        
        if len(forehead_points) >= 4:
            forehead_points = np.array(forehead_points, dtype=np.int32)
            hull = cv2.convexHull(forehead_points)
            
            # ä¿å®ˆæ‰©å±•
            forehead_center = np.mean(hull.reshape(-1, 2), axis=0)
            expanded_hull = []
            
            for point in hull.reshape(-1, 2):
                dx = point[0] - forehead_center[0]
                dy = point[1] - forehead_center[1]
                
                new_x = forehead_center[0] + dx * 1.1
                new_y = forehead_center[1] + dy * 1.1
                
                expanded_hull.append([new_x, new_y])
            
            expanded_hull = np.array(expanded_hull, dtype=np.int32)
            
            # è¾¹ç•Œä¿æŠ¤
            if 33 < len(landmarks_2d) and 263 < len(landmarks_2d):
                eye_y = min(landmarks_2d[33][1], landmarks_2d[263][1])
                for i, point in enumerate(expanded_hull):
                    if point[1] > eye_y - 20:
                        expanded_hull[i][1] = eye_y - 20
                    expanded_hull[i][0] = np.clip(point[0], 5, w-5)
                    expanded_hull[i][1] = np.clip(point[1], 5, h-5)
            
            cv2.fillPoly(mask, [expanded_hull], 255)
        
        return mask

    def calculate_forehead_center(self, landmarks_2d):
        """è®¡ç®—é¢å¤´3Då˜å½¢ä¸­å¿ƒç‚¹"""
        # æ”¶é›†é¢å¤´å…³é”®ç‚¹
        forehead_points = []
        for idx in self.FOREHEAD_CENTER + self.FOREHEAD_LEFT + self.FOREHEAD_RIGHT:
            if idx < len(landmarks_2d):
                forehead_points.append(landmarks_2d[idx])
        
        if len(forehead_points) < 3:
            return None
        
        # è®¡ç®—å‡ ä½•ä¸­å¿ƒ
        forehead_points = np.array(forehead_points)
        center = np.mean(forehead_points, axis=0)
        return center

    def apply_radial_transform(self, point, center, intensity, mode="expand"):
        """å¾„å‘å˜å½¢ç®—æ³• - æ¨¡æ‹Ÿ3Dæ•ˆæœ"""
        if center is None:
            return point
        
        # è®¡ç®—ä»ä¸­å¿ƒåˆ°ç‚¹çš„å‘é‡
        direction = point - center
        distance = np.linalg.norm(direction)
        
        if distance < 0.1:  # é¿å…é™¤é›¶
            return point
        
        # å½’ä¸€åŒ–æ–¹å‘å‘é‡
        direction_normalized = direction / distance
        
        if mode == "expand":
            # å¾„å‘å‘å¤–æ‰©å±•ï¼ˆé¥±æ»¡æ•ˆæœï¼‰
            expansion = intensity * 8.0 * (1 - distance / 200.0)  # è·ç¦»è¶Šè¿‘æ‰©å±•è¶Šå¤§
            expansion = max(0, expansion)  # ç¡®ä¿ä¸ä¸ºè´Ÿ
            new_point = point + direction_normalized * expansion
        else:  # "shrink"
            # å¾„å‘å‘å†…æ”¶ç¼©ï¼ˆå¹³æ•´æ•ˆæœï¼‰
            contraction = intensity * 6.0 * (1 - distance / 100.0)
            contraction = max(0, contraction)
            new_point = point - direction_normalized * contraction
        
        return new_point

    def apply_vertical_lift(self, point, center, intensity, lift_type="up"):
        """å‚ç›´æå‡ç®—æ³• - æ¨¡æ‹Ÿ3Déš†èµ·"""
        if center is None:
            return point
        
        # è®¡ç®—è·ç¦»ä¸­å¿ƒçš„è·ç¦»
        distance_from_center = np.linalg.norm(point - center)
        max_distance = 300.0  # æœ€å¤§å½±å“è·ç¦»
        
        if distance_from_center > max_distance:
            return point
        
        # è·ç¦»è¶Šè¿‘ï¼Œæå‡è¶Šå¤§ï¼ˆé«˜æ–¯åˆ†å¸ƒæ•ˆæœï¼‰
        distance_ratio = distance_from_center / max_distance
        lift_factor = np.exp(-distance_ratio * distance_ratio * 0.5)  # é«˜æ–¯è¡°å‡
        
        if lift_type == "up":
            # å‘ä¸Šæå‡ï¼ˆé¥±æ»¡æ•ˆæœï¼‰
            lift_amount = intensity * 35.0 * lift_factor
            new_point = [point[0], point[1] - lift_amount]  # Yå‡å°æ˜¯å‘ä¸Š
        else:  # "down"
            # å‘ä¸‹å‹å¹³ï¼ˆå¹³æ•´æ•ˆæœï¼‰
            lift_amount = intensity * 20.0 * lift_factor
            new_point = [point[0], point[1] + lift_amount]  # Yå¢å¤§æ˜¯å‘ä¸‹
        
        return new_point
        
    def apply_effective_forehead_transform(self, image, landmarks_2d, pose_info, transform_type="shrink", intensity=0.3):
        """æœ‰æ•ˆçš„é¢å¤´3Då˜å½¢ - é¥±æ»¡vså¹³æ•´æ•ˆæœ"""
        if pose_info is None:
            pose_3d = "frontal"
        else:
            rotation_vector, translation_vector = pose_info
            pose_3d = self.estimate_face_pose_3d(rotation_vector)
        
        # 3Då§¿æ€è‡ªé€‚åº”
        if pose_3d != "frontal":
            intensity = intensity * 0.8
            print(f"ğŸ” 3Dä¾§è„¸æ£€æµ‹ï¼Œå¼ºåº¦è°ƒæ•´åˆ°: {intensity:.2f}")
        
        # æ„å»ºæ§åˆ¶ç‚¹
        src_points = []
        dst_points = []
        
        # æ£€æŸ¥å…³é”®ç‚¹
        core_points = self.FOREHEAD_CENTER + self.FOREHEAD_LEFT + self.FOREHEAD_RIGHT
        if any(idx >= len(landmarks_2d) for idx in core_points):
            print("âŒ æ‰¾ä¸åˆ°æ ¸å¿ƒé¢å¤´æ§åˆ¶ç‚¹")
            return image
        
        # å›ºå®šä¸­å¤®è„Šæ¤
        for idx in self.FOREHEAD_CENTER:
            point = landmarks_2d[idx]
            src_points.append(point)
            dst_points.append(point)
        
        # è®¡ç®—é¢å¤´3Då˜å½¢ä¸­å¿ƒ
        forehead_center = self.calculate_forehead_center(landmarks_2d)
        if forehead_center is None:
            print("âŒ æ— æ³•è®¡ç®—é¢å¤´ä¸­å¿ƒ")
            return image
        
        # 3Då§¿æ€è‡ªé€‚åº”ç³»æ•°
        if pose_3d == "left_profile":
            left_multiplier = 1.2
            right_multiplier = 0.8
        elif pose_3d == "right_profile":
            left_multiplier = 0.8
            right_multiplier = 1.2
        else:
            left_multiplier = right_multiplier = 1.0
        
        print(f"ğŸ¯ é¢å¤´3Då˜å½¢ - å€Ÿé‰´é¼»å­3DæˆåŠŸç»éªŒ")
        
        if transform_type == "shrink":
            print(f"ğŸ”µ é¢å¤´é¥±æ»¡æ•ˆæœ - ä¸­å¤®éš†èµ· + å¾„å‘æ‰©å±•")
            
            # å‘é™…çº¿ç‚¹ï¼šå‘ä¸Šæå‡ + å¾„å‘æ‰©å±•ï¼ˆåŒé‡3Dæ•ˆæœï¼‰
            for idx in self.HAIRLINE_POINTS:
                if idx < len(landmarks_2d):
                    point = landmarks_2d[idx]
                    src_points.append(point)
                    
                    # å…ˆå‚ç›´æå‡
                    lifted_point = self.apply_vertical_lift(point, forehead_center, intensity, "up")
                    # å†å¾„å‘æ‰©å±•
                    final_point = self.apply_radial_transform(lifted_point, forehead_center, intensity, "expand")
                    
                    dst_points.append(final_point)
            
            # å·¦ä¾§é¢å¤´ç‚¹ï¼šä¸»è¦å¾„å‘æ‰©å±•
            for idx in self.FOREHEAD_LEFT:
                if idx < len(landmarks_2d):
                    point = landmarks_2d[idx]
                    src_points.append(point)
                    
                    # å¾„å‘æ‰©å±• + 3Då§¿æ€è°ƒæ•´
                    radial_point = self.apply_radial_transform(point, forehead_center, intensity * left_multiplier, "expand")
                    # è½»å¾®ä¸Šæ
                    final_point = self.apply_vertical_lift(radial_point, forehead_center, intensity * 0.5, "up")
                    
                    dst_points.append(final_point)
            
            # å³ä¾§é¢å¤´ç‚¹ï¼šä¸»è¦å¾„å‘æ‰©å±•
            for idx in self.FOREHEAD_RIGHT:
                if idx < len(landmarks_2d):
                    point = landmarks_2d[idx]
                    src_points.append(point)
                    
                    # å¾„å‘æ‰©å±• + 3Då§¿æ€è°ƒæ•´
                    radial_point = self.apply_radial_transform(point, forehead_center, intensity * right_multiplier, "expand")
                    # è½»å¾®ä¸Šæ
                    final_point = self.apply_vertical_lift(radial_point, forehead_center, intensity * 0.5, "up")
                    
                    dst_points.append(final_point)
        
        elif transform_type == "expand":
            print(f"ğŸ”¶ é¢å¤´å¹³æ•´æ•ˆæœ - ä¸­å¤®å‹å¹³ + å¾„å‘æ”¶ç¼©")
            
            # å‘é™…çº¿ç‚¹ï¼šå‘ä¸‹å‹å¹³ + å¾„å‘æ”¶ç¼©
            for idx in self.HAIRLINE_POINTS:
                if idx < len(landmarks_2d):
                    point = landmarks_2d[idx]
                    src_points.append(point)
                    
                    # å…ˆå‚ç›´å‹å¹³
                    flattened_point = self.apply_vertical_lift(point, forehead_center, intensity, "down")
                    # å†å¾„å‘æ”¶ç¼©
                    final_point = self.apply_radial_transform(flattened_point, forehead_center, intensity, "shrink")
                    
                    dst_points.append(final_point)
            
            # å·¦ä¾§é¢å¤´ç‚¹ï¼šä¸»è¦å¾„å‘æ”¶ç¼©
            for idx in self.FOREHEAD_LEFT:
                if idx < len(landmarks_2d):
                    point = landmarks_2d[idx]
                    src_points.append(point)
                    
                    # å¾„å‘æ”¶ç¼© + 3Då§¿æ€è°ƒæ•´
                    radial_point = self.apply_radial_transform(point, forehead_center, intensity * left_multiplier, "shrink")
                    # è½»å¾®ä¸‹å‹
                    final_point = self.apply_vertical_lift(radial_point, forehead_center, intensity * 0.3, "down")
                    
                    dst_points.append(final_point)
            
            # å³ä¾§é¢å¤´ç‚¹ï¼šä¸»è¦å¾„å‘æ”¶ç¼©
            for idx in self.FOREHEAD_RIGHT:
                if idx < len(landmarks_2d):
                    point = landmarks_2d[idx]
                    src_points.append(point)
                    
                    # å¾„å‘æ”¶ç¼© + 3Då§¿æ€è°ƒæ•´
                    radial_point = self.apply_radial_transform(point, forehead_center, intensity * right_multiplier, "shrink")
                    # è½»å¾®ä¸‹å‹
                    final_point = self.apply_vertical_lift(radial_point, forehead_center, intensity * 0.3, "down")
                    
                    dst_points.append(final_point)
        
        # çœ‰æ¯›ä¸Šæ–¹ç‚¹è½»å¾®è·Ÿéšï¼ˆä¿æŒè‡ªç„¶è¿‡æ¸¡ï¼‰
        for idx in self.EYEBROW_UPPER:
            if idx < len(landmarks_2d):
                point = landmarks_2d[idx]
                src_points.append(point)
                
                if transform_type == "shrink":  # é¥±æ»¡æ—¶è½»å¾®ä¸Šæ
                    follow_point = self.apply_vertical_lift(point, forehead_center, intensity * 0.3, "up")
                else:  # å¹³æ•´æ—¶è½»å¾®ä¸‹å‹
                    follow_point = self.apply_vertical_lift(point, forehead_center, intensity * 0.2, "down")
                
                dst_points.append(follow_point)
        
        # å¤ªé˜³ç©´è½»å¾®è·Ÿéš
        for idx in self.TEMPLE_POINTS:
            if idx < len(landmarks_2d):
                point = landmarks_2d[idx]
                src_points.append(point)
                
                if transform_type == "shrink":  # é¥±æ»¡æ—¶è½»å¾®å¤–æ‰©
                    temple_point = self.apply_radial_transform(point, forehead_center, intensity * 0.3, "expand")
                else:  # å¹³æ•´æ—¶è½»å¾®å†…æ”¶
                    temple_point = self.apply_radial_transform(point, forehead_center, intensity * 0.2, "shrink")
                
                dst_points.append(temple_point)
        
        # æ·»åŠ ç¨³å®šé”šç‚¹
        anchor_count = 0
        for idx in self.STABLE_ANCHORS:
            if idx < len(landmarks_2d):
                src_points.append(landmarks_2d[idx])
                dst_points.append(landmarks_2d[idx])
                anchor_count += 1
        
        # è¾¹ç•Œé”šç‚¹
        h, w = image.shape[:2]
        boundary_points = [
            [20, 20], [w//2, 20], [w-20, 20],
            [20, h//2], [w-20, h//2],
            [20, h-20], [w//2, h-20], [w-20, h-20]
        ]
        
        for bp in boundary_points:
            src_points.append(bp)
            dst_points.append(bp)
        
        forehead_control_count = len(self.HAIRLINE_POINTS + self.FOREHEAD_LEFT + self.FOREHEAD_RIGHT + 
                                    self.EYEBROW_UPPER + self.TEMPLE_POINTS)
        
        print(f"ğŸ”§ 3Då˜å½¢æ§åˆ¶ç‚¹ç»Ÿè®¡:")
        print(f"   ä¸­å¤®è„Šæ¤: 3ä¸ª(å›ºå®š)")
        print(f"   é¢å¤´æ§åˆ¶ç‚¹: {forehead_control_count}ä¸ª(3Då˜å½¢)")
        print(f"   ç¨³å®šé”šç‚¹: {anchor_count}ä¸ª")
        print(f"   è¾¹ç•Œé”šç‚¹: 8ä¸ª")
        print(f"   æ€»è®¡: {len(src_points)}ä¸ª")
        
        if len(src_points) < 15:
            print("âŒ æ§åˆ¶ç‚¹ä¸è¶³")
            return image
        
        # æ‰§è¡ŒTPSå˜æ¢
        try:
            src_points = np.array(src_points, dtype=np.float32)
            dst_points = np.array(dst_points, dtype=np.float32)
            
            # æ£€æŸ¥ç§»åŠ¨è·ç¦»
            distances = np.linalg.norm(dst_points - src_points, axis=1)
            max_distance = np.max(distances)
            moving_count = np.sum(distances > 0.5)
            
            print(f"ğŸ“Š 3Då˜å½¢ç»Ÿè®¡:")
            print(f"   æœ€å¤§ç§»åŠ¨: {max_distance:.2f}åƒç´ ")
            print(f"   ç§»åŠ¨ç‚¹æ•°: {moving_count}")
            
            # TPSå˜æ¢
            tps = cv2.createThinPlateSplineShapeTransformer()
            matches = [cv2.DMatch(i, i, 0) for i in range(len(src_points))]
            
            print("ğŸ”„ å¼€å§‹3D TPSå˜æ¢...")
            
            # æ­£ç¡®çš„å‚æ•°é¡ºåº
            tps.estimateTransformation(
                dst_points.reshape(1, -1, 2),
                src_points.reshape(1, -1, 2),
                matches
            )
            
            transformed = tps.warpImage(image)
            
            if transformed is None:
                print("âŒ TPSå˜æ¢è¿”å›ç©ºç»“æœ")
                return image
            
            # å¼‚å¸¸åƒç´ ä¿®å¤
            green_mask = ((transformed[:, :, 0] == 0) & 
                        (transformed[:, :, 1] == 255) & 
                        (transformed[:, :, 2] == 0))
            if np.sum(green_mask) > 0:
                transformed[green_mask] = image[green_mask]
            
            gray_transformed = cv2.cvtColor(transformed, cv2.COLOR_BGR2GRAY)
            gray_original = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            dark_mask = (gray_transformed < 10) & (gray_original > 50)
            if np.sum(dark_mask) > 0:
                transformed[dark_mask] = image[dark_mask]
            
            # åˆ›å»ºmaskå¹¶èåˆ
            forehead_mask = self.create_forehead_mask(image.shape, landmarks_2d)
            mask_3d = cv2.merge([forehead_mask, forehead_mask, forehead_mask]).astype(np.float32) / 255.0
            mask_blurred = cv2.GaussianBlur(mask_3d, (15, 15), 0)
            
            result = image.astype(np.float32) * (1 - mask_blurred) + transformed.astype(np.float32) * mask_blurred
            result = np.clip(result, 0, 255).astype(np.uint8)
            
            print("âœ… 3Dé¢å¤´å˜å½¢æˆåŠŸ")
            return result
            
        except Exception as e:
            print(f"âŒ TPSå˜å½¢å¼‚å¸¸: {e}")
            return image
        
    def debug_forehead_detection(self, image):
        """è°ƒè¯•æ¨¡å¼ - æ˜¾ç¤ºç²¾ç¡®çš„é¢å¤´ç‚¹"""
        landmarks_2d, pose_info = self.detect_landmarks_3d(image)
        if landmarks_2d is None:
            print("âŒ æœªæ£€æµ‹åˆ°é¢éƒ¨å…³é”®ç‚¹")
            return image
        
        debug_img = image.copy()
        
        # ç»˜åˆ¶ä¸­å¤®è„Šæ¤ - çº¢è‰²
        for i, idx in enumerate(self.FOREHEAD_CENTER):
            if idx < len(landmarks_2d):
                point = landmarks_2d[idx].astype(int)
                cv2.circle(debug_img, tuple(point), 10, (0, 0, 255), -1)
                cv2.putText(debug_img, f"C{idx}", tuple(point + 15), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
        
        # ç»˜åˆ¶å‘é™…çº¿ç‚¹ - ç»¿è‰²
        for i, idx in enumerate(self.HAIRLINE_POINTS):
            if idx < len(landmarks_2d):
                point = landmarks_2d[idx].astype(int)
                cv2.circle(debug_img, tuple(point), 8, (0, 255, 0), -1)
                cv2.putText(debug_img, f"H{idx}", tuple(point + 10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
        
        # ç»˜åˆ¶å·¦å³é¢å¤´ä¸»ç‚¹ - è“è‰²
        for i, idx in enumerate(self.FOREHEAD_LEFT + self.FOREHEAD_RIGHT):
            if idx < len(landmarks_2d):
                point = landmarks_2d[idx].astype(int)
                cv2.circle(debug_img, tuple(point), 8, (255, 0, 0), -1)
                cv2.putText(debug_img, f"F{idx}", tuple(point + 10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)
        
        # ç»˜åˆ¶çœ‰æ¯›ä¸Šæ–¹ç‚¹ - é»„è‰²
        for i, idx in enumerate(self.EYEBROW_UPPER):
            if idx < len(landmarks_2d):
                point = landmarks_2d[idx].astype(int)
                cv2.circle(debug_img, tuple(point), 6, (0, 255, 255), -1)
                cv2.putText(debug_img, f"E{idx}", tuple(point + 8), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 255), 1)
        
        # ç»˜åˆ¶å¤ªé˜³ç©´ç‚¹ - ç´«è‰²
        for i, idx in enumerate(self.TEMPLE_POINTS):
            if idx < len(landmarks_2d):
                point = landmarks_2d[idx].astype(int)
                cv2.circle(debug_img, tuple(point), 8, (255, 0, 255), -1)
                cv2.putText(debug_img, f"T{idx}", tuple(point + 10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 2)
        
        # æ˜¾ç¤º3Då§¿æ€
        if pose_info is not None:
            rotation_vector, translation_vector = pose_info
            pose_3d = self.estimate_face_pose_3d(rotation_vector)
            cv2.putText(debug_img, f"3D Pose: {pose_3d}", (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
        
        # æ˜¾ç¤ºmask
        mask = self.create_forehead_mask(image.shape, landmarks_2d)
        mask_overlay = debug_img.copy()
        mask_overlay[mask > 0] = [255, 255, 255]
        debug_img = cv2.addWeighted(debug_img, 0.7, mask_overlay, 0.3, 0)
        
        # å›¾ä¾‹
        legend_y = 70
        cv2.putText(debug_img, "RED: Center Spine (Fixed)", (10, legend_y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)
        cv2.putText(debug_img, "GREEN: Hairline (Main Effect)", (10, legend_y + 20), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
        cv2.putText(debug_img, "BLUE: Forehead Main Points", (10, legend_y + 40), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)
        cv2.putText(debug_img, "YELLOW: Eyebrow Upper", (10, legend_y + 60), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
        cv2.putText(debug_img, "PURPLE: Temple Points", (10, legend_y + 80), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 1)
        
        return debug_img
    
    def process_image(self, image, transform_type="shrink", intensity=0.3):
        """å¤„ç†å›¾åƒ"""
        landmarks_2d, pose_info = self.detect_landmarks_3d(image)
        if landmarks_2d is None:
            print("âŒ æœªæ£€æµ‹åˆ°é¢éƒ¨å…³é”®ç‚¹")
            return image
        
        print(f"âœ… æ£€æµ‹åˆ° {len(landmarks_2d)} ä¸ª2Då…³é”®ç‚¹")
        
        return self.apply_effective_forehead_transform(image, landmarks_2d, pose_info, transform_type, intensity)
def main():
   parser = argparse.ArgumentParser(description='é¢å¤´è°ƒæ•´å·¥å…· - ç²¾ç¡®æœ‰æ•ˆç‰ˆæœ¬')
   parser.add_argument('--input', '-i', required=True, help='è¾“å…¥å›¾ç‰‡è·¯å¾„')
   parser.add_argument('--output', '-o', required=True, help='è¾“å‡ºå›¾ç‰‡è·¯å¾„')
   parser.add_argument('--type', '-t', choices=['shrink', 'expand'], 
                   default='shrink', help='è°ƒæ•´ç±»å‹ï¼šshrink=é¥±æ»¡æ•ˆæœ, expand=å¹³æ•´æ•ˆæœ')
   parser.add_argument('--intensity', type=float, default=0.3, 
                      help='è°ƒæ•´å¼ºåº¦ (0.1-0.8)')
   parser.add_argument('--debug', action='store_true', help='è°ƒè¯•æ¨¡å¼')
   parser.add_argument('--comparison', action='store_true', help='ç”Ÿæˆå¯¹æ¯”å›¾')
   
   args = parser.parse_args()
   
   # åŠ è½½å›¾ç‰‡
   image = cv2.imread(args.input)
   if image is None:
       print(f"âŒ æ— æ³•åŠ è½½å›¾ç‰‡: {args.input}")
       return
   
   print(f"ğŸ“¸ å›¾ç‰‡å°ºå¯¸: {image.shape}")
   
   # å¼ºåº¦æ£€æŸ¥
   if args.intensity > 0.8:
       print(f"âš ï¸  å¼ºåº¦è¿‡å¤§ï¼Œé™åˆ¶åˆ°0.8")
       args.intensity = 0.8
   elif args.intensity < 0.1:
       print(f"âš ï¸  å¼ºåº¦è¿‡å°ï¼Œæå‡åˆ°0.1")
       args.intensity = 0.1
   
   # åˆ›å»ºå¤„ç†å™¨
   processor = ForeheadAdjustment()
   
   # è°ƒè¯•æ¨¡å¼
   if args.debug:
       debug_result = processor.debug_forehead_detection(image)
       cv2.imwrite(args.output, debug_result)
       print(f"ğŸ” è°ƒè¯•å›¾ä¿å­˜åˆ°: {args.output}")
       return
   
   # å¤„ç†å›¾ç‰‡
   print(f"ğŸ”„ å¼€å§‹ç²¾ç¡®é¢å¤´å¤„ç† - ç±»å‹: {args.type}, å¼ºåº¦: {args.intensity}")
   result = processor.process_image(image, args.type, args.intensity)
   
   # ä¿å­˜ç»“æœ
   cv2.imwrite(args.output, result)
   print(f"âœ… å¤„ç†å®Œæˆï¼Œä¿å­˜åˆ°: {args.output}")
   
   # ç»Ÿè®¡å˜åŒ–
   diff = cv2.absdiff(image, result)
   total_diff = np.sum(diff)
   changed_pixels = np.sum(diff > 0)
   print(f"ğŸ“Š å˜åŒ–ç»Ÿè®¡: æ€»å·®å¼‚={total_diff}, å˜åŒ–åƒç´ ={changed_pixels}")
   
   # ç”Ÿæˆå¯¹æ¯”å›¾
   if args.comparison:
       comparison_path = args.output.replace('.', '_comparison.')
       comparison = np.hstack([image, result])
       cv2.line(comparison, (image.shape[1], 0), (image.shape[1], image.shape[0]), (0, 255, 0), 2)
       
       cv2.putText(comparison, 'Original', (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
       cv2.putText(comparison, f'Hairline-{args.type}-{args.intensity}', (image.shape[1] + 20, 40), 
                  cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
       
       cv2.imwrite(comparison_path, comparison)
       print(f"ğŸ“Š å¯¹æ¯”å›¾ä¿å­˜åˆ°: {comparison_path}")
   
print("\nğŸ¯ 3Då˜å½¢ç­–ç•¥:")
print("â€¢ é¥±æ»¡(shrink)ï¼šä¸­å¤®éš†èµ· + å¾„å‘æ‰©å±• (æ¨¡æ‹Ÿ3Då‡¸å‡º)")
print("â€¢ å¹³æ•´(expand)ï¼šä¸­å¤®å‹å¹³ + å¾„å‘æ”¶ç¼© (æ¨¡æ‹Ÿ3Dæ‰å¹³)")
print("â€¢ å€Ÿé‰´é¼»å­3Dè„šæœ¬çš„ç«‹ä½“å˜å½¢æŠ€æœ¯")
print("â€¢ å‚ç›´æå‡ + å¾„å‘å˜å½¢ = åŒé‡3Dæ•ˆæœ")

print("\nğŸ“– ä½¿ç”¨ç¤ºä¾‹:")
print("â€¢ é¢å¤´é¥±æ»¡: python forehead_adjust.py -i input.jpg -o output.png -t shrink --intensity 0.4 --comparison")
print("â€¢ é¢å¤´å¹³æ•´: python forehead_adjust.py -i input.jpg -o output.png -t expand --intensity 0.3 --comparison")
print("â€¢ 3Dè°ƒè¯•: python forehead_adjust.py -i input.jpg -o debug.png --debug")

if __name__ == "__main__":
   main()
