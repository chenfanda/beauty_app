#!/usr/bin/env python3
"""
åŸºäºMediaPipe + 3Då‡ ä½•çš„é¼»å­è°ƒæ•´è„šæœ¬
ä½¿ç”¨PnPç®—æ³•å’Œ3Dé¢éƒ¨æ¨¡å‹è¿›è¡Œæ›´è‡ªç„¶çš„å˜å½¢
"""

import cv2
import numpy as np
import mediapipe as mp
import argparse
from typing import List, Tuple, Optional

class Nose3DGeometry:
    def __init__(self):
        # MediaPipeè®¾ç½®
        self.mp_face_mesh = mp.solutions.face_mesh
        self.face_mesh = self.mp_face_mesh.FaceMesh(
            static_image_mode=True,
            max_num_faces=1,
            refine_landmarks=True,
            min_detection_confidence=0.8,
            min_tracking_confidence=0.8
        )
        
        # ç›¸æœºå‚æ•°
        self.camera_matrix = None
        self.dist_coeffs = None
        
        # é¼»å­å…³é”®ç‚¹
        self.NOSE_TIP_3D = [1, 2]
        self.LEFT_NOSTRIL_3D = [49, 131, 134]
        self.RIGHT_NOSTRIL_3D = [278, 360, 363]
        self.NOSE_BRIDGE_3D = [6, 19, 20, 8, 9, 10]
        
        # æ ‡å‡†3Dé¢éƒ¨æ¨¡å‹å…³é”®ç‚¹ï¼ˆæ¯«ç±³å•ä½ï¼‰
        self.face_model_3d = np.array([
            # ä¸»è¦é¢éƒ¨ç‰¹å¾ç‚¹ç”¨äºPnPæ±‚è§£
            [0.0, 0.0, 0.0],           # é¼»å°– (1)
            [0.0, -330.0, -65.0],      # ä¸‹å·´ (152)  
            [-225.0, 170.0, -135.0],   # å·¦çœ¼å¤–è§’ (33)
            [225.0, 170.0, -135.0],    # å³çœ¼å¤–è§’ (263)
            [-150.0, -150.0, -125.0],  # å·¦å˜´è§’ (61)
            [150.0, -150.0, -125.0],   # å³å˜´è§’ (291)
        ], dtype=np.float32)
        
        # å¯¹åº”çš„MediaPipeç´¢å¼•
        self.pnp_indices = [1, 152, 33, 263, 61, 291]
    
    def setup_camera(self, image_shape):
        """è®¾ç½®ç›¸æœºå‚æ•°"""
        h, w = image_shape[:2]
        
        # ä¼°ç®—ç›¸æœºå†…å‚çŸ©é˜µ
        focal_length = w
        center = (w/2, h/2)
        
        self.camera_matrix = np.array([
            [focal_length, 0, center[0]],
            [0, focal_length, center[1]],
            [0, 0, 1]
        ], dtype=np.float32)
        
        # å‡è®¾æ— é•œå¤´ç•¸å˜
        self.dist_coeffs = np.zeros((4,1), dtype=np.float32)
    
    def detect_landmarks_3d(self, image):
        """æ£€æµ‹é¢éƒ¨å…³é”®ç‚¹å¹¶è®¡ç®—3Då§¿æ€"""
        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        results = self.face_mesh.process(rgb_image)
        
        if not results.multi_face_landmarks:
            return None, None
        
        # è·å–2Då…³é”®ç‚¹
        landmarks_2d = []
        h, w = image.shape[:2]
        for landmark in results.multi_face_landmarks[0].landmark:
            x = int(landmark.x * w)
            y = int(landmark.y * h)
            landmarks_2d.append([x, y])
        
        landmarks_2d = np.array(landmarks_2d, dtype=np.float32)
        
        # è®¾ç½®ç›¸æœºå‚æ•°
        if self.camera_matrix is None:
            self.setup_camera(image.shape)
        
        # æå–ç”¨äºPnPçš„å…³é”®ç‚¹
        image_points = []
        for idx in self.pnp_indices:
            if idx < len(landmarks_2d):
                image_points.append(landmarks_2d[idx])
        
        if len(image_points) < 6:
            print("PnPå…³é”®ç‚¹ä¸è¶³")
            return landmarks_2d, None
        
        image_points = np.array(image_points, dtype=np.float32)
        
        # PnPæ±‚è§£3Då§¿æ€
        try:
            success, rotation_vector, translation_vector = cv2.solvePnP(
                self.face_model_3d, image_points, 
                self.camera_matrix, self.dist_coeffs,
                flags=cv2.SOLVEPNP_ITERATIVE
            )
            
            if not success:
                print("PnPæ±‚è§£å¤±è´¥")
                return landmarks_2d, None
            
            return landmarks_2d, (rotation_vector, translation_vector)
            
        except Exception as e:
            print(f"PnPæ±‚è§£å¼‚å¸¸: {e}")
            return landmarks_2d, None
    
    def estimate_face_pose_3d(self, rotation_vector):
        """åŸºäº3Dæ—‹è½¬å‘é‡ä¼°è®¡é¢éƒ¨å§¿æ€"""
        if rotation_vector is None:
            return "frontal"
        
        # å°†æ—‹è½¬å‘é‡è½¬æ¢ä¸ºæ—‹è½¬çŸ©é˜µ
        rotation_matrix, _ = cv2.Rodrigues(rotation_vector)
        
        # æå–æ¬§æ‹‰è§’
        sy = np.sqrt(rotation_matrix[0,0] * rotation_matrix[0,0] + rotation_matrix[1,0] * rotation_matrix[1,0])
        
        singular = sy < 1e-6
        
        if not singular:
            x = np.arctan2(rotation_matrix[2,1], rotation_matrix[2,2])
            y = np.arctan2(-rotation_matrix[2,0], sy)
            z = np.arctan2(rotation_matrix[1,0], rotation_matrix[0,0])
        else:
            x = np.arctan2(-rotation_matrix[1,2], rotation_matrix[1,1])
            y = np.arctan2(-rotation_matrix[2,0], sy)
            z = 0
        
        # è½¬æ¢ä¸ºåº¦æ•°
        yaw = np.degrees(y)
        
        print(f"3Då§¿æ€æ£€æµ‹: Yaw = {yaw:.1f}åº¦")
        
        # æ ¹æ®yawè§’åˆ¤æ–­å§¿æ€
        if abs(yaw) < 15:
            return "frontal"
        elif yaw > 15:
            return "right_profile"
        else:
            return "left_profile"
    
    def create_3d_nose_mask(self, image_shape, landmarks_2d, pose_3d):
        """åŸºäº3Då§¿æ€åˆ›å»ºæ›´ç²¾ç¡®çš„é¼»å­mask - ä¿®å¤ä¸Šä¸‹æ‰©å±•è¿‡åº¦"""
        h, w = image_shape[:2]
        mask = np.zeros((h, w), dtype=np.uint8)
        
        # æ”¶é›†é¼»å­å…³é”®ç‚¹
        nose_indices = self.NOSE_TIP_3D + self.LEFT_NOSTRIL_3D + self.RIGHT_NOSTRIL_3D + self.NOSE_BRIDGE_3D[:3]
        nose_points = []
        
        for idx in nose_indices:
            if idx < len(landmarks_2d):
                nose_points.append(landmarks_2d[idx])
        
        if len(nose_points) >= 3:
            nose_points = np.array(nose_points, dtype=np.int32)
            hull = cv2.convexHull(nose_points)
            
            # è®¡ç®—é¼»å­çš„å®é™…å°ºå¯¸
            nose_center = np.mean(hull.reshape(-1, 2), axis=0)
            nose_width = np.max(hull[:, :, 0]) - np.min(hull[:, :, 0])
            nose_height = np.max(hull[:, :, 1]) - np.min(hull[:, :, 1])
            
            print(f"é¼»å­å°ºå¯¸: {nose_width:.0f}x{nose_height:.0f}åƒç´ ")
            
            # 3Då§¿æ€è‡ªé€‚åº”æ‰©å±• - æ”¹å›æ•ˆæœæœ€å¥½çš„å‚æ•°
            if pose_3d == "frontal":
                horizontal_expand = 1.6  # ä¿æŒè¾ƒå¤§çš„æ‰©å±•
                vertical_expand = 1.6    # æ”¹å›å’Œæ°´å¹³ä¸€æ ·å¤§
            else:  # ä¾§è„¸
                horizontal_expand = 1.3  # æ”¹å›æ›´å¤§çš„æ‰©å±•
                vertical_expand = 1.3    # æ”¹å›å’Œæ°´å¹³ä¸€æ ·å¤§
            
            # æ ¹æ®å›¾ç‰‡å°ºå¯¸è°ƒæ•´
            total_pixels = h * w
            if total_pixels > 1000000:  # å¤§å›¾
                horizontal_expand *= 1.1
                vertical_expand *= 1.05
            elif total_pixels < 100000:  # å°å›¾
                horizontal_expand *= 0.9
                vertical_expand *= 0.95
            
            # åˆ†åˆ«å¤„ç†æ°´å¹³å’Œå‚ç›´æ–¹å‘çš„æ‰©å±•
            expanded_hull = []
            for point in hull.reshape(-1, 2):
                # è®¡ç®—ç›¸å¯¹äºä¸­å¿ƒçš„åç§»
                dx = point[0] - nose_center[0]
                dy = point[1] - nose_center[1]
                
                # åˆ†åˆ«æ‰©å±•xå’Œyæ–¹å‘
                new_x = nose_center[0] + dx * horizontal_expand
                new_y = nose_center[1] + dy * vertical_expand
                
                expanded_hull.append([new_x, new_y])
            
            expanded_hull = np.array(expanded_hull, dtype=np.int32)
            
            # è¿›ä¸€æ­¥é™åˆ¶å‚ç›´æ‰©å±•ï¼Œç¡®ä¿ä¸è¶…è¿‡åˆç†èŒƒå›´
            min_y = np.min(expanded_hull[:, 1])
            max_y = np.max(expanded_hull[:, 1])
            
            # åŸºäºé¼»å­é«˜åº¦é™åˆ¶å‚ç›´æ‰©å±• - æ”¹å›å…è®¸æ›´å¤§æ‰©å±•
            max_vertical_expansion = nose_height * 1.2  # æ”¹å›1.2ï¼Œå…è®¸æ›´å¤§çš„å‚ç›´æ‰©å±•
            
            if (max_y - min_y) > nose_height + max_vertical_expansion:
                # å¦‚æœæ‰©å±•è¿‡åº¦ï¼Œé‡æ–°è®¡ç®—
                center_y = (min_y + max_y) / 2
                target_height = nose_height + max_vertical_expansion
                
                for i, point in enumerate(expanded_hull):
                    if point[1] < center_y:  # ä¸ŠåŠéƒ¨åˆ†
                        expanded_hull[i][1] = max(point[1], center_y - target_height/2)
                    else:  # ä¸‹åŠéƒ¨åˆ†
                        expanded_hull[i][1] = min(point[1], center_y + target_height/2)
            
            cv2.fillPoly(mask, [expanded_hull], 255)
            
            # éªŒè¯maskä¸ä¼šå½±å“åˆ°çœ¼ç›å’Œå˜´å·´
            eye_y = min(landmarks_2d[33][1], landmarks_2d[263][1])  # çœ¼è§’é«˜åº¦
            mouth_y = max(landmarks_2d[61][1], landmarks_2d[291][1])  # å˜´è§’é«˜åº¦
            
            mask_top = np.min(expanded_hull[:, 1])
            mask_bottom = np.max(expanded_hull[:, 1])
            
            # è¾¹ç•Œä¿æŠ¤ - æ”¹å›æ›´å®½æ¾çš„è¾¹ç•Œï¼Œå…è®¸æ›´å¤§mask
            if mask_top < eye_y + 10:  # æ”¹å›æ›´å°çš„è¾¹ç•Œä¿æŠ¤
                mask[:int(eye_y + 10), :] = 0
                print("âš ï¸  Maskä¸Šè¾¹ç•Œè£å‰ªï¼Œé¿å…å½±å“çœ¼éƒ¨")
            
            if mask_bottom > mouth_y - 5:  # æ”¹å›æ›´å°çš„è¾¹ç•Œä¿æŠ¤
                mask[int(mouth_y - 5):, :] = 0
                print("âš ï¸  Maskä¸‹è¾¹ç•Œè£å‰ªï¼Œé¿å…å½±å“å˜´éƒ¨")
            
            print(f"3D Mask: å§¿æ€={pose_3d}, æ°´å¹³æ‰©å±•={horizontal_expand:.1f}x, å‚ç›´æ‰©å±•={vertical_expand:.1f}x")
        
        return mask
    
    def apply_3d_nose_transform(self, image, landmarks_2d, pose_info, transform_type="wings", intensity=0.3):
        """åº”ç”¨3Dæ„ŸçŸ¥çš„é¼»å­å˜å½¢"""
        if pose_info is None:
            print("3Då§¿æ€ä¿¡æ¯æ— æ•ˆï¼Œä½¿ç”¨2Dæ¨¡å¼")
            return self.apply_2d_fallback(image, landmarks_2d, transform_type, intensity)
        
        rotation_vector, translation_vector = pose_info
        pose_3d = self.estimate_face_pose_3d(rotation_vector)
        
        # 3Då§¿æ€è‡ªé€‚åº”å¼ºåº¦è°ƒæ•´
        if pose_3d != "frontal":
            intensity = intensity * 0.7  # ä¾§è„¸æ—¶é™ä½å¼ºåº¦
            print(f"3Dä¾§è„¸æ£€æµ‹ï¼Œå¼ºåº¦è°ƒæ•´åˆ°: {intensity:.2f}")
        
        # æ„å»ºå˜å½¢æ§åˆ¶ç‚¹
        src_points = []
        dst_points = []
        
        if transform_type == "wings":
            # 3Dæ„ŸçŸ¥çš„é¼»ç¿¼æ”¶ç¼©
            nose_center_x = landmarks_2d[1][0]  # ä½¿ç”¨é¼»å°–xåæ ‡ä½œä¸ºä¸­å¿ƒ
            
            # 3Då§¿æ€è‡ªé€‚åº”æ”¶ç¼©
            left_multiplier = 1.0
            right_multiplier = 1.0
            
            if pose_3d == "left_profile":
                left_multiplier = 1.1
                right_multiplier = 0.9
            elif pose_3d == "right_profile":
                left_multiplier = 0.9
                right_multiplier = 1.1
            
            # å·¦é¼»ç¿¼æ”¶ç¼©
            for idx in self.LEFT_NOSTRIL_3D:
                if idx < len(landmarks_2d):
                    point = landmarks_2d[idx]
                    src_points.append(point)
                    shrink_amount = (point[0] - nose_center_x) * intensity * 0.4 * left_multiplier
                    new_x = point[0] - shrink_amount
                    dst_points.append([new_x, point[1]])
            
            # å³é¼»ç¿¼æ”¶ç¼©
            for idx in self.RIGHT_NOSTRIL_3D:
                if idx < len(landmarks_2d):
                    point = landmarks_2d[idx]
                    src_points.append(point)
                    shrink_amount = (point[0] - nose_center_x) * intensity * 0.4 * right_multiplier
                    new_x = point[0] - shrink_amount
                    dst_points.append([new_x, point[1]])
        
        elif transform_type == "tip":
            # 3Dæ„ŸçŸ¥çš„é¼»å°–æŠ¬é«˜ - å®Œå–„å®ç°
            print(f"3Dé¼»å°–æŠ¬é«˜: {pose_3d}")
            
            # é¼»å°–å‘ä¸Šç§»åŠ¨
            for idx in self.NOSE_TIP_3D:
                if idx < len(landmarks_2d):
                    point = landmarks_2d[idx]
                    src_points.append(point)
                    lift_amount = intensity * 12
                    new_point = [point[0], point[1] - lift_amount]
                    dst_points.append(new_point)
            
            # é¼»æ¢é€‚åº¦æŠ¬é«˜
            for idx in self.NOSE_BRIDGE_3D[:4]:  # ä½¿ç”¨å‰4ä¸ªé¼»æ¢ç‚¹
                if idx < len(landmarks_2d):
                    point = landmarks_2d[idx]
                    src_points.append(point)
                    # æ¸å˜æŠ¬é«˜ï¼šè¶Šé è¿‘é¼»å°–æŠ¬å¾—è¶Šå¤š
                    bridge_lift = intensity * (8 - idx * 1.5)  # ä»8é€’å‡åˆ°2
                    new_point = [point[0], point[1] - max(bridge_lift, 2)]
                    dst_points.append(new_point)
        
        elif transform_type == "resize":
            # 3Dæ„ŸçŸ¥çš„æ•´ä½“é¼»å­ç¼©å°
            print(f"3Dé¼»å­æ•´ä½“ç¼©å°: {pose_3d}")
            
            # è®¡ç®—3Dæ„ŸçŸ¥çš„é¼»å­ä¸­å¿ƒ
            all_nose_indices = self.NOSE_TIP_3D + self.LEFT_NOSTRIL_3D + self.RIGHT_NOSTRIL_3D + self.NOSE_BRIDGE_3D[:3]
            nose_points_for_center = []
            for idx in all_nose_indices:
                if idx < len(landmarks_2d):
                    nose_points_for_center.append(landmarks_2d[idx])
            
            if len(nose_points_for_center) < 3:
                print("âŒ é¼»å­å…³é”®ç‚¹ä¸è¶³ï¼Œæ— æ³•æ•´ä½“ç¼©å°")
                return self.apply_2d_fallback(image, landmarks_2d, transform_type, intensity)
            
            nose_center = np.mean(nose_points_for_center, axis=0)
            
            # 3Då§¿æ€è‡ªé€‚åº”ç¼©å°
            if pose_3d != "frontal":
                shrink_intensity = intensity * 0.8  # ä¾§è„¸æ—¶æ›´ä¿å®ˆ
            else:
                shrink_intensity = intensity
            
            # æ‰€æœ‰é¼»å­å…³é”®ç‚¹å‘ä¸­å¿ƒæ”¶ç¼©
            for idx in all_nose_indices:
                if idx < len(landmarks_2d):
                    point = landmarks_2d[idx]
                    src_points.append(point)
                    
                    # å‘ä¸­å¿ƒæ”¶ç¼©
                    vec = point - nose_center
                    shrink_factor = 1 - shrink_intensity * 0.4
                    new_point = nose_center + vec * shrink_factor
                    dst_points.append(new_point)
        
        elif transform_type == "bridge":
            # æ–°å¢ï¼šé¼»æ¢å˜æŒºåŠŸèƒ½
            print(f"3Dé¼»æ¢å˜æŒº: {pose_3d}")
            
            # é¼»æ¢å‘å‰çªå‡ºï¼ˆåœ¨å›¾åƒä¸­è¡¨ç°ä¸ºè½»å¾®å‘ä¸Šå’Œç¼©å°ï¼‰
            for i, idx in enumerate(self.NOSE_BRIDGE_3D):
                if idx < len(landmarks_2d):
                    point = landmarks_2d[idx]
                    src_points.append(point)
                    
                    # æ¸å˜æ•ˆæœï¼šä¸­é—´çš„é¼»æ¢ç‚¹å˜åŒ–æœ€å¤§
                    position_ratio = 1.0 - abs(i - len(self.NOSE_BRIDGE_3D)/2) / (len(self.NOSE_BRIDGE_3D)/2)
                    
                    # å‘ä¸Šç§»åŠ¨æ¨¡æ‹Ÿå˜æŒº
                    lift_amount = intensity * 6 * position_ratio
                    # è½»å¾®å‘ä¸­å¿ƒæ”¶ç¼©æ¨¡æ‹Ÿå˜çª„
                    center_x = landmarks_2d[1][0]  # é¼»å°–xåæ ‡
                    shrink_amount = (point[0] - center_x) * intensity * 0.2 * position_ratio
                    
                    new_x = point[0] - shrink_amount
                    new_y = point[1] - lift_amount
                    dst_points.append([new_x, new_y])
        
        else:
            print(f"âŒ æœªçŸ¥çš„3Då˜å½¢ç±»å‹: {transform_type}")
            return self.apply_2d_fallback(image, landmarks_2d, transform_type, intensity)
        
        # æ·»åŠ å¤§é‡ç¨³å®šé”šç‚¹ - å‚è€ƒ2Dç‰ˆæœ¬çš„æˆåŠŸç»éªŒ
        stable_indices = [
            # çœ¼éƒ¨
            33, 133, 362, 263, 7, 163, 144, 145, 153, 154, 155, 173, 157, 158, 159, 160, 161, 246,
            382, 381, 380, 374, 373, 390, 249, 466, 388, 387, 386, 385, 384, 398,
            # å˜´éƒ¨
            61, 291, 39, 269, 270, 267, 271, 272, 0, 17, 18, 200, 199, 175, 164,
            # è„¸éƒ¨è½®å»“
            234, 93, 132, 58, 172, 136, 150, 149, 176, 148, 152, 377, 400, 378, 379, 365, 397, 288, 361, 323, 454
        ]
        
        anchor_count = 0
        for idx in stable_indices:
            if idx < len(landmarks_2d):
                src_points.append(landmarks_2d[idx])
                dst_points.append(landmarks_2d[idx])
                anchor_count += 1
        
        # æ·»åŠ è¾¹ç•Œé”šç‚¹
        h, w = image.shape[:2]
        boundary_margin = 50
        boundary_points = [
            [boundary_margin, boundary_margin], 
            [w//2, boundary_margin], 
            [w-boundary_margin, boundary_margin],
            [boundary_margin, h//2], 
            [w-boundary_margin, h//2],
            [boundary_margin, h-boundary_margin], 
            [w//2, h-boundary_margin], 
            [w-boundary_margin, h-boundary_margin]
        ]
        
        for bp in boundary_points:
            src_points.append(bp)
            dst_points.append(bp)
        
        print(f"3Dæ§åˆ¶ç‚¹: é¼»å­={len(src_points)-anchor_count-8}, é”šç‚¹={anchor_count}, è¾¹ç•Œ=8")
        
        if len(src_points) < 10:
            print("3Dæ§åˆ¶ç‚¹ä¸è¶³ï¼Œä½¿ç”¨2Dæ¨¡å¼")
            return self.apply_2d_fallback(image, landmarks_2d, transform_type, intensity)
        
        # æ‰§è¡ŒTPSå˜æ¢
        try:
            src_points = np.array(src_points, dtype=np.float32)
            dst_points = np.array(dst_points, dtype=np.float32)
            
            tps = cv2.createThinPlateSplineShapeTransformer()
            matches = [cv2.DMatch(i, i, 0) for i in range(len(src_points))]
            
            tps.estimateTransformation(
                dst_points.reshape(1, -1, 2), 
                src_points.reshape(1, -1, 2), 
                matches
            )
            
            # TPSå˜å½¢
            transformed = tps.warpImage(image)
            
            if transformed is None:
                print("3D TPSå˜æ¢å¤±è´¥")
                return image
            
            # åˆ›å»º3Dæ„ŸçŸ¥çš„mask
            nose_mask = self.create_3d_nose_mask(image.shape, landmarks_2d, pose_3d)
            
            # èåˆ
            mask_3d = cv2.merge([nose_mask, nose_mask, nose_mask]).astype(np.float32) / 255.0
            mask_blurred = cv2.GaussianBlur(mask_3d, (5, 5), 0)
            
            result = image.astype(np.float32) * (1 - mask_blurred) + transformed.astype(np.float32) * mask_blurred
            result = np.clip(result, 0, 255).astype(np.uint8)
            
            print("âœ… 3Då˜å½¢æˆåŠŸ")
            return result
            
        except Exception as e:
            print(f"3Då˜å½¢å¼‚å¸¸: {e}")
            return self.apply_2d_fallback(image, landmarks_2d, transform_type, intensity)
    
    def apply_2d_fallback(self, image, landmarks_2d, transform_type, intensity):
        """2Dæ¨¡å¼å›é€€"""
        print("ä½¿ç”¨2Då›é€€æ¨¡å¼")
        # è¿™é‡Œå¯ä»¥è°ƒç”¨ä¹‹å‰çš„2D TPSæ–¹æ³•
        return image
    
    def debug_3d_detection(self, image):
        """è°ƒè¯•3Dæ£€æµ‹ - ä¿®å¤å…³é”®ç‚¹æ˜¾ç¤º"""
        landmarks_2d, pose_info = self.detect_landmarks_3d(image)
        if landmarks_2d is None:
            print("æœªæ£€æµ‹åˆ°é¢éƒ¨å…³é”®ç‚¹")
            return image
        
        debug_img = image.copy()
        
        # ç»˜åˆ¶å®é™…çš„é¼»å­å…³é”®ç‚¹ï¼ˆä½¿ç”¨æ­£ç¡®çš„MediaPipeç´¢å¼•ï¼‰
        nose_parts = [
            (self.NOSE_TIP_3D, (0, 0, 255), "T"),        # é¼»å°–-çº¢è‰²
            (self.LEFT_NOSTRIL_3D, (0, 255, 0), "L"),    # å·¦é¼»ç¿¼-ç»¿è‰²  
            (self.RIGHT_NOSTRIL_3D, (255, 0, 0), "R"),   # å³é¼»ç¿¼-è“è‰²
            (self.NOSE_BRIDGE_3D[:3], (0, 255, 255), "B") # é¼»æ¢-é»„è‰²ï¼ˆåªæ˜¾ç¤ºå‰3ä¸ªï¼‰
        ]
        
        for indices, color, prefix in nose_parts:
            for i, idx in enumerate(indices):
                if idx < len(landmarks_2d):
                    point = landmarks_2d[idx].astype(int)
                    cv2.circle(debug_img, tuple(point), 5, color, -1)
                    # æ˜¾ç¤ºMediaPipeçœŸå®ç´¢å¼•è€Œä¸æ˜¯æˆ‘çš„é”™è¯¯ç¼–å·
                    cv2.putText(debug_img, f"{prefix}{idx}", tuple(point + 8), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
        
        # æ˜¾ç¤ºPnPå…³é”®ç‚¹ï¼ˆç”¨äº3Då§¿æ€æ±‚è§£çš„6ä¸ªç‚¹ï¼‰
        pnp_colors = [(255, 255, 255), (255, 255, 0), (0, 255, 255), (255, 0, 255), (128, 255, 128), (255, 128, 128)]
        for i, idx in enumerate(self.pnp_indices):
            if idx < len(landmarks_2d):
                point = landmarks_2d[idx].astype(int)
                cv2.circle(debug_img, tuple(point), 8, pnp_colors[i], 2)
                cv2.putText(debug_img, f"PnP{idx}", tuple(point + 12), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, pnp_colors[i], 2)
        
        # æ˜¾ç¤º3Då§¿æ€ä¿¡æ¯
        if pose_info is not None:
            rotation_vector, translation_vector = pose_info
            pose_3d = self.estimate_face_pose_3d(rotation_vector)
            cv2.putText(debug_img, f"3D Pose: {pose_3d}", (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
            
            # ç»˜åˆ¶3Dåæ ‡è½´ï¼ˆåœ¨é¼»å°–ä½ç½®ï¼‰
            nose_tip_3d = np.array([[0, 0, 0]], dtype=np.float32)
            axis_3d = np.array([
                [0, 0, 0],      # åŸç‚¹
                [30, 0, 0],     # Xè½´
                [0, 30, 0],     # Yè½´  
                [0, 0, -30]     # Zè½´
            ], dtype=np.float32)
            
            try:
                projected_axis, _ = cv2.projectPoints(
                    axis_3d, rotation_vector, translation_vector,
                    self.camera_matrix, self.dist_coeffs
                )
                projected_axis = projected_axis.reshape(-1, 2).astype(int)
                
                # ç»˜åˆ¶åæ ‡è½´
                origin = tuple(projected_axis[0])
                cv2.arrowedLine(debug_img, origin, tuple(projected_axis[1]), (0, 0, 255), 3)  # X-çº¢
                cv2.arrowedLine(debug_img, origin, tuple(projected_axis[2]), (0, 255, 0), 3)  # Y-ç»¿
                cv2.arrowedLine(debug_img, origin, tuple(projected_axis[3]), (255, 0, 0), 3)  # Z-è“
                
                # æ ‡è®°åæ ‡è½´
                cv2.putText(debug_img, "X", tuple(projected_axis[1] + 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
                cv2.putText(debug_img, "Y", tuple(projected_axis[2] + 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                cv2.putText(debug_img, "Z", tuple(projected_axis[3] + 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)
            except:
                print("3Dåæ ‡è½´æŠ•å½±å¤±è´¥")
        
        # æ˜¾ç¤º3D mask
        if pose_info is not None:
            pose_3d = self.estimate_face_pose_3d(pose_info[0])
            nose_mask = self.create_3d_nose_mask(image.shape, landmarks_2d, pose_3d)
            mask_overlay = debug_img.copy()
            mask_overlay[nose_mask > 0] = [255, 0, 255]  # ç´«è‰²mask
            debug_img = cv2.addWeighted(debug_img, 0.7, mask_overlay, 0.3, 0)
        
        # æ·»åŠ å›¾ä¾‹è¯´æ˜
        legend_y = 60
        cv2.putText(debug_img, "RED: Nose Tip", (10, legend_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)
        cv2.putText(debug_img, "GREEN: Left Nostril", (10, legend_y + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
        cv2.putText(debug_img, "BLUE: Right Nostril", (10, legend_y + 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)
        cv2.putText(debug_img, "YELLOW: Nose Bridge", (10, legend_y + 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
        cv2.putText(debug_img, "WHITE: PnP Points", (10, legend_y + 80), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        return debug_img
    
    def process_image(self, image, transform_type="wings", intensity=0.3):
        """å¤„ç†å›¾åƒ"""
        landmarks_2d, pose_info = self.detect_landmarks_3d(image)
        if landmarks_2d is None:
            print("æœªæ£€æµ‹åˆ°é¢éƒ¨å…³é”®ç‚¹")
            return image
        
        print(f"âœ… æ£€æµ‹åˆ° {len(landmarks_2d)} ä¸ª2Då…³é”®ç‚¹")
        
        return self.apply_3d_nose_transform(image, landmarks_2d, pose_info, transform_type, intensity)

def main():
    parser = argparse.ArgumentParser(description='3D Face Geometryé¼»å­è°ƒæ•´å·¥å…·')
    parser.add_argument('--input', '-i', required=True, help='è¾“å…¥å›¾ç‰‡è·¯å¾„')
    parser.add_argument('--output', '-o', required=True, help='è¾“å‡ºå›¾ç‰‡è·¯å¾„')
    parser.add_argument('--type', '-t', choices=['wings', 'tip', 'resize', 'bridge'], 
                       default='wings', help='è°ƒæ•´ç±»å‹ï¼šwings=é¼»ç¿¼æ”¶ç¼©, tip=é¼»å°–æŠ¬é«˜, resize=æ•´ä½“ç¼©å°, bridge=é¼»æ¢å˜æŒº')
    parser.add_argument('--intensity', type=float, default=0.3, 
                       help='è°ƒæ•´å¼ºåº¦ (0.1-0.5)')
    parser.add_argument('--debug', action='store_true', help='3Dè°ƒè¯•æ¨¡å¼')
    parser.add_argument('--comparison', action='store_true', help='ç”Ÿæˆå¯¹æ¯”å›¾')
    
    args = parser.parse_args()
    
    # åŠ è½½å›¾ç‰‡
    image = cv2.imread(args.input)
    if image is None:
        print(f"æ— æ³•åŠ è½½å›¾ç‰‡: {args.input}")
        return
    
    print(f"å›¾ç‰‡å°ºå¯¸: {image.shape}")
    
    # åˆ›å»º3Då¤„ç†å™¨
    processor = Nose3DGeometry()
    
    # è°ƒè¯•æ¨¡å¼
    if args.debug:
        debug_result = processor.debug_3d_detection(image)
        cv2.imwrite(args.output, debug_result)
        print(f"3Dè°ƒè¯•å›¾ä¿å­˜åˆ°: {args.output}")
        return
    
    # å¤„ç†å›¾ç‰‡
    print(f"å¼€å§‹3Då¤„ç† - ç±»å‹: {args.type}, å¼ºåº¦: {args.intensity}")
    result = processor.process_image(image, args.type, args.intensity)
    
    # ä¿å­˜ç»“æœ
    cv2.imwrite(args.output, result)
    print(f"å¤„ç†å®Œæˆï¼Œä¿å­˜åˆ°: {args.output}")
    
    # æ£€æŸ¥å˜åŒ–
    diff = cv2.absdiff(image, result)
    total_diff = np.sum(diff)
    changed_pixels = np.sum(diff > 0)
    print(f"å˜åŒ–ç»Ÿè®¡: æ€»å·®å¼‚={total_diff}, å˜åŒ–åƒç´ ={changed_pixels}")
    
    # ç”Ÿæˆå¯¹æ¯”å›¾
    if args.comparison:
        comparison_path = args.output.replace('.', '_3d_comparison.')
        comparison = np.hstack([image, result])
        cv2.line(comparison, (image.shape[1], 0), (image.shape[1], image.shape[0]), (0, 255, 0), 2)
        
        cv2.putText(comparison, 'Original', (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        cv2.putText(comparison, f'3D-{args.type} {args.intensity}', (image.shape[1] + 20, 40), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        
        cv2.imwrite(comparison_path, comparison)
        print(f"3Då¯¹æ¯”å›¾ä¿å­˜åˆ°: {comparison_path}")
    
    print("\nğŸŒŸ 3D Face Geometryç‰¹æ€§:")
    print("â€¢ åŸºäºçœŸå®3Dé¢éƒ¨å‡ ä½•æ¨¡å‹")
    print("â€¢ PnPç®—æ³•æ±‚è§£ç²¾ç¡®å¤´éƒ¨å§¿æ€")
    print("â€¢ 3Dæ„ŸçŸ¥çš„è‡ªé€‚åº”å˜å½¢å¼ºåº¦")
    print("â€¢ æ›´ç²¾ç¡®çš„ä¾§è„¸å¤„ç†")
    print("â€¢ 3Dåæ ‡è½´å¯è§†åŒ–è°ƒè¯•")
    print("\nä½¿ç”¨ç¤ºä¾‹:")
    print("â€¢ 3Dé¼»ç¿¼æ”¶ç¼©: python nose_3d.py -i input.jpg -o output.png -t wings --intensity 0.3 --comparison")
    print("â€¢ 3Dé¼»å°–æŠ¬é«˜: python nose_3d.py -i input.jpg -o output.png -t tip --intensity 0.25 --comparison")
    print("â€¢ 3Dæ•´ä½“ç¼©å°: python nose_3d.py -i input.jpg -o output.png -t resize --intensity 0.3 --comparison")
    print("â€¢ 3Dé¼»æ¢å˜æŒº: python nose_3d.py -i input.jpg -o output.png -t bridge --intensity 0.2 --comparison")
    print("â€¢ 3Dè°ƒè¯•æ¨¡å¼: python nose_3d.py -i input.jpg -o debug.png --debug")

if __name__ == "__main__":
    main()
