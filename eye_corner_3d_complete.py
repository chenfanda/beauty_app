#!/usr/bin/env python3
"""
ç²¾ç®€é«˜æ•ˆçœ¼è§’è°ƒæ•´å™¨ - streamlined_eye_corner_adjuster.py
æ ¸å¿ƒç†å¿µï¼šåŸºäºç¾å­¦åŸç†çš„æ™ºèƒ½è°ƒæ•´ï¼Œåˆ é™¤è¿‡åº¦å·¥ç¨‹åŒ–çš„åŠŸèƒ½

ä¿ç•™çš„æ ¸å¿ƒåŠŸèƒ½ï¼š
1. 3Då§¿æ€æ„ŸçŸ¥ - PnPç®—æ³•çš„çœŸå®å¤´éƒ¨å§¿æ€ä¼°è®¡
2. ç¾å­¦å¯¼å‘çš„ç§»åŠ¨ç­–ç•¥ - è¯†åˆ«çœ¼å½¢ç‰¹å¾ï¼Œåˆ¶å®šé’ˆå¯¹æ€§ç§»åŠ¨ç­–ç•¥
3. ç»“æ„å®Œæ•´æ€§ä¿æŠ¤ - ç¡®ä¿çœ¼å‘¨ç»„ç»‡åè°ƒæ€§
4. æ™ºèƒ½å¼ºåº¦æ§åˆ¶ - ä¿è¯å¯è§æ•ˆæœçš„åŒæ—¶ç¡®ä¿è‡ªç„¶

åˆ é™¤çš„å†—ä½™åŠŸèƒ½ï¼š
- è¿‡äºå¤æ‚çš„å¹´é¾„ä¼°è®¡
- è¿‡åº¦ç»†åˆ†çš„çœ¼å½¢åˆ†ç±»
- å¤šå±‚æ¬¡å› å­ç›¸ä¹˜å¯¼è‡´çš„å¼ºåº¦ç¨€é‡Š
- è¿‡äºä¿å®ˆçš„å®‰å…¨æœºåˆ¶
"""

import cv2
import numpy as np
import mediapipe as mp
import argparse
import os
from typing import Tuple, Dict, List, Optional

class EyeCornerAdjuster:
    """ç²¾ç®€é«˜æ•ˆçš„çœ¼è§’è°ƒæ•´å™¨"""
    
    def __init__(self,face_mesh=None):
        # MediaPipeåˆå§‹åŒ–
        self.mp_face_mesh = mp.solutions.face_mesh
        if not face_mesh:
            self.face_mesh = self.mp_face_mesh.FaceMesh(
                static_image_mode=True,
                max_num_faces=1,
                refine_landmarks=True,
                min_detection_confidence=0.8,
                min_tracking_confidence=0.8
            )
        else:
            self.face_mesh = face_mesh
        
        # ç›¸æœºå‚æ•°
        self.camera_matrix = None
        self.dist_coeffs = None
        
        # 3Dé¢éƒ¨æ¨¡å‹ (ç®€åŒ–ç‰ˆï¼Œåªä¿ç•™å…³é”®ç‚¹)
        self.face_model_3d = np.array([
            [0.0, 0.0, 0.0],           # é¼»å°–
            [0.0, -330.0, -65.0],      # ä¸‹å·´
            [-225.0, 170.0, -135.0],   # å·¦çœ¼å¤–è§’
            [225.0, 170.0, -135.0],    # å³çœ¼å¤–è§’
            [-150.0, -150.0, -125.0],  # å·¦å˜´è§’
            [150.0, -150.0, -125.0],   # å³å˜´è§’
        ], dtype=np.float32)
        
        self.pnp_indices = [1, 152, 33, 263, 61, 291]
        
        # çœ¼éƒ¨ç§»åŠ¨åŒºåŸŸå®šä¹‰ (ç²¾ç®€ç‰ˆ)
        self.EYE_REGIONS = {
            'left_eye': {
                'outer_corner': [33],                    # ä¸»è¦å¤–çœ¦ç‚¹
                'outer_support': [7, 163],               # å¤–çœ¦æ”¯æ’‘ç‚¹
                'inner_corner': [133],                   # å†…çœ¦ç‚¹
                'upper_lid': [157, 158, 159, 160, 161],  # ä¸Šçœ¼ç‘
                'lower_lid': [144, 145, 153],            # ä¸‹çœ¼ç‘
            },
            'right_eye': {
                'outer_corner': [263],                   # ä¸»è¦å¤–çœ¦ç‚¹
                'outer_support': [249, 390],             # å¤–çœ¦æ”¯æ’‘ç‚¹
                'inner_corner': [362],                   # å†…çœ¦ç‚¹
                'upper_lid': [386, 387, 388, 466],       # ä¸Šçœ¼ç‘
                'lower_lid': [373, 374, 380],            # ä¸‹çœ¼ç‘
            }
        }
        
        # ç¨³å®šé”šç‚¹ (ç®€åŒ–ç‰ˆ)
        self.STABLE_ANCHORS = [
            1, 2, 5, 4, 6,              # é¼»éƒ¨æ ¸å¿ƒ
            9, 10, 151, 175,            # é¢éƒ¨ä¸­è½´
            61, 291, 39, 269, 270,      # å˜´éƒ¨åŒºåŸŸ
            70, 296, 107, 276,          # çœ‰æ¯›åŒºåŸŸ
            168, 6, 8                   # å¯¹ç§°è½´
        ]
    
    def setup_camera(self, image_shape):
        """è®¾ç½®ç›¸æœºå‚æ•°"""
        h, w = image_shape[:2]
        focal_length = w
        center = (w/2, h/2)
        
        self.camera_matrix = np.array([
            [focal_length, 0, center[0]],
            [0, focal_length, center[1]],
            [0, 0, 1]
        ], dtype=np.float32)
        
        self.dist_coeffs = np.zeros((4,1), dtype=np.float32)
    
    def detect_landmarks_with_pose(self, image):
        """æ£€æµ‹å…³é”®ç‚¹å¹¶ä¼°è®¡3Då§¿æ€"""
        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        results = self.face_mesh.process(rgb_image)
        
        if not results.multi_face_landmarks:
            return None, None
        
        # è·å–2Då…³é”®ç‚¹
        landmarks_2d = []
        h, w = image.shape[:2]
        for landmark in results.multi_face_landmarks[0].landmark:
            x = int(landmark.x * w)
            y = int(landmark.y * h)
            landmarks_2d.append([x, y])
        
        landmarks_2d = np.array(landmarks_2d, dtype=np.float32)
        
        # è®¾ç½®ç›¸æœºå‚æ•°
        if self.camera_matrix is None:
            self.setup_camera(image.shape)
        
        # PnPæ±‚è§£3Då§¿æ€
        pose_info = None
        try:
            image_points = []
            for idx in self.pnp_indices:
                if idx < len(landmarks_2d):
                    image_points.append(landmarks_2d[idx])
            
            if len(image_points) >= 6:
                image_points = np.array(image_points, dtype=np.float32)
                
                success, rotation_vector, translation_vector = cv2.solvePnP(
                    self.face_model_3d, image_points, 
                    self.camera_matrix, self.dist_coeffs,
                    flags=cv2.SOLVEPNP_ITERATIVE
                )
                
                if success:
                    pose_info = (rotation_vector, translation_vector)
        
        except Exception as e:
            print(f"âš ï¸ 3Då§¿æ€ä¼°è®¡å¤±è´¥: {e}")
        
        return landmarks_2d, pose_info
    
    def analyze_eye_characteristics(self, landmarks_2d):
        """ç®€åŒ–çš„çœ¼å½¢ç‰¹å¾åˆ†æ - åªè¯†åˆ«å…³é”®ç‰¹å¾"""
        
        try:
            # å…³é”®ç‚¹è·å–
            left_inner, left_outer = landmarks_2d[133], landmarks_2d[33]
            left_top, left_bottom = landmarks_2d[159], landmarks_2d[145]
            right_inner, right_outer = landmarks_2d[362], landmarks_2d[263]
            right_top, right_bottom = landmarks_2d[386], landmarks_2d[374]
            
            # è®¡ç®—å…³é”®ç‰¹å¾
            left_tilt = np.degrees(np.arctan2(left_outer[1] - left_inner[1], left_outer[0] - left_inner[0]))
            right_tilt = np.degrees(np.arctan2(right_outer[1] - right_inner[1], right_outer[0] - right_inner[0]))
            avg_tilt = (left_tilt + right_tilt) / 2
            
            left_length = np.linalg.norm(left_outer - left_inner)
            left_height = np.linalg.norm(left_top - left_bottom)
            right_length = np.linalg.norm(right_outer - right_inner)
            right_height = np.linalg.norm(right_top - right_bottom)
            
            left_ratio = left_length / max(left_height, 1)
            right_ratio = right_length / max(right_height, 1)
            avg_ratio = (left_ratio + right_ratio) / 2
            
            # è¯†åˆ«å…³é”®ç‰¹å¾ (ç®€åŒ–ä¸ºæœ€é‡è¦çš„å‡ ä¸ª)
            features = {
                'upward_tilt': avg_tilt > 10,           # æ˜æ˜¾ä¸Šæ‰¬
                'downward_tilt': avg_tilt < -8,         # æ˜æ˜¾ä¸‹å‚
                'very_round': avg_ratio < 2.4,          # å¾ˆåœ†
                'very_elongated': avg_ratio > 3.4,      # å¾ˆé•¿
                'asymmetric': abs(left_tilt - right_tilt) > 8  # ä¸å¯¹ç§°
            }
            
            return features, {
                'avg_tilt': avg_tilt,
                'avg_ratio': avg_ratio,
                'left_tilt': left_tilt,
                'right_tilt': right_tilt
            }
            
        except Exception as e:
            print(f"âš ï¸ çœ¼å½¢åˆ†æå¤±è´¥: {e}")
            return {}, {}
    
    def get_pose_analysis(self, pose_info):
        """ç®€åŒ–çš„3Då§¿æ€åˆ†æ"""
        if pose_info is None:
            return {'type': 'frontal', 'yaw': 0, 'difficulty': 'easy', 'intensity_factor': 1.0}
        
        try:
            rotation_vector, translation_vector = pose_info
            rotation_matrix, _ = cv2.Rodrigues(rotation_vector)
            
            sy = np.sqrt(rotation_matrix[0,0] * rotation_matrix[0,0] + rotation_matrix[1,0] * rotation_matrix[1,0])
            yaw = np.degrees(np.arctan2(-rotation_matrix[2,0], sy))
            
            # ç®€åŒ–çš„å§¿æ€åˆ†ç±»
            if abs(yaw) < 20:
                pose_type, difficulty = 'frontal', 'easy'
                intensity_factor = 1.0
            elif abs(yaw) < 35:
                pose_type, difficulty = 'slight_profile', 'medium'
                intensity_factor = 0.8
            else:
                pose_type, difficulty = 'profile', 'hard'
                intensity_factor = 0.6
            
            return {
                'type': pose_type,
                'yaw': yaw,
                'difficulty': difficulty,
                'intensity_factor': intensity_factor
            }
            
        except Exception as e:
            print(f"âš ï¸ å§¿æ€åˆ†æå¤±è´¥: {e}")
            return {'type': 'frontal', 'yaw': 0, 'difficulty': 'easy', 'intensity_factor': 1.0}
    
    def calculate_adaptive_parameters(self, landmarks_2d, image_shape):
        """è®¡ç®—è‡ªé€‚åº”å‚æ•° - åŸºäºå›¾åƒå°ºå¯¸å’Œçœ¼éƒ¨å®é™…å¤§å°"""
        
        try:
            # è®¡ç®—çœ¼éƒ¨ç‰¹å¾å°ºå¯¸
            left_eye_width = np.linalg.norm(landmarks_2d[33] - landmarks_2d[133])
            right_eye_width = np.linalg.norm(landmarks_2d[263] - landmarks_2d[362])
            avg_eye_width = (left_eye_width + right_eye_width) / 2
            
            # è®¡ç®—çœ¼éƒ¨é«˜åº¦
            left_eye_height = np.linalg.norm(landmarks_2d[159] - landmarks_2d[145])
            right_eye_height = np.linalg.norm(landmarks_2d[386] - landmarks_2d[374])
            avg_eye_height = (left_eye_height + right_eye_height) / 2
            
            # è®¡ç®—é¢éƒ¨ç‰¹å¾å°ºå¯¸ä½œä¸ºå‚è€ƒ
            face_width = np.linalg.norm(landmarks_2d[234] - landmarks_2d[454])  # è„¸å®½
            inter_eye_distance = np.linalg.norm(landmarks_2d[33] - landmarks_2d[263])  # åŒçœ¼é—´è·
            
            # å›¾åƒåˆ†è¾¨ç‡ä¿¡æ¯
            h, w = image_shape[:2]
            image_area = h * w
            image_diagonal = np.sqrt(h*h + w*w)
            
            # è®¡ç®—çœ¼éƒ¨åœ¨å›¾åƒä¸­çš„ç›¸å¯¹å¤§å°
            eye_to_face_ratio = avg_eye_width / face_width if face_width > 0 else 0.3
            eye_to_image_ratio = avg_eye_width / w if w > 0 else 0.1
            
            # è‡ªé€‚åº”å‚æ•°è®¡ç®—
            adaptive_params = {}
            
            # 1. åŸºç¡€ç§»åŠ¨scale - ç›¸å¯¹äºçœ¼éƒ¨å¤§å°
            # ç›®æ ‡ï¼šç§»åŠ¨è·ç¦»åº”è¯¥æ˜¯çœ¼å®½çš„8-15%æ‰æœ‰æ˜æ˜¾æ•ˆæœ
            base_movement_ratio = 0.12  # çœ¼å®½çš„12%
            adaptive_params['base_scale'] = avg_eye_width * base_movement_ratio
            
            # 2. åˆ†è¾¨ç‡è¡¥å¿å› å­
            # é«˜åˆ†è¾¨ç‡å›¾åƒéœ€è¦æ›´å¤§çš„ç§»åŠ¨è·ç¦»
            base_resolution = 1920 * 1080  # åŸºå‡†åˆ†è¾¨ç‡
            resolution_factor = np.sqrt(image_area / base_resolution)
            resolution_factor = max(0.8, min(3.0, resolution_factor))  # é™åˆ¶åœ¨0.8-3.0ä¹‹é—´
            adaptive_params['resolution_factor'] = resolution_factor
            
            # 3. çœ¼éƒ¨å°ºå¯¸è¡¥å¿
            # å°çœ¼ç›éœ€è¦ç›¸å¯¹æ›´å¤§çš„è°ƒæ•´ï¼Œå¤§çœ¼ç›å¯ä»¥ç›¸å¯¹ä¿å®ˆ
            base_eye_width = 120  # åŸºå‡†çœ¼å®½(åƒç´ )
            eye_size_factor = base_eye_width / avg_eye_width if avg_eye_width > 0 else 1.0
            eye_size_factor = max(0.7, min(1.5, eye_size_factor))  # é™åˆ¶èŒƒå›´
            adaptive_params['eye_size_factor'] = eye_size_factor
            
            # 4. ç»¼åˆè‡ªé€‚åº”scale
            final_scale = (adaptive_params['base_scale'] * 
                          adaptive_params['resolution_factor'] * 
                          adaptive_params['eye_size_factor'])
            
            # ç¡®ä¿æœ€å°æœ‰æ•ˆscale
            min_effective_scale = max(15, avg_eye_width * 0.08)  # è‡³å°‘çœ¼å®½çš„8%
            final_scale = max(final_scale, min_effective_scale)
            
            adaptive_params['final_scale'] = final_scale
            
            # 5. è‡ªé€‚åº”å®‰å…¨é™åˆ¶
            # æœ€å¤§ç§»åŠ¨è·ç¦»ç›¸å¯¹äºçœ¼éƒ¨å°ºå¯¸
            max_safe_ratio = 0.25  # çœ¼å®½çš„25%ä¸ºå®‰å…¨ä¸Šé™
            adaptive_params['max_displacement'] = avg_eye_width * max_safe_ratio
            
            # 6. maskå°ºå¯¸è°ƒæ•´
            # maskåŠå¾„ç›¸å¯¹äºçœ¼éƒ¨å°ºå¯¸
            base_mask_ratio = 0.15  # çœ¼å®½çš„15%
            adaptive_params['mask_radius'] = max(8, avg_eye_width * base_mask_ratio)
            
            # è°ƒè¯•ä¿¡æ¯
            print(f"ğŸ“ è‡ªé€‚åº”å‚æ•°è®¡ç®—:")
            print(f"   å›¾åƒå°ºå¯¸: {w}Ã—{h} ({image_area/1000000:.1f}Måƒç´ )")
            print(f"   å¹³å‡çœ¼å®½: {avg_eye_width:.1f}px, çœ¼é«˜: {avg_eye_height:.1f}px")
            print(f"   çœ¼éƒ¨ç›¸å¯¹å°ºå¯¸: {eye_to_image_ratio:.3f} (å å›¾åƒå®½åº¦æ¯”ä¾‹)")
            print(f"   åˆ†è¾¨ç‡å› å­: {resolution_factor:.2f}")
            print(f"   çœ¼éƒ¨å°ºå¯¸å› å­: {eye_size_factor:.2f}")
            print(f"   æœ€ç»ˆscale: {final_scale:.1f} (ç›®æ ‡ç§»åŠ¨è·ç¦»)")
            print(f"   å®‰å…¨ä¸Šé™: {adaptive_params['max_displacement']:.1f}px")
            
            return adaptive_params
            
        except Exception as e:
            print(f"âš ï¸ è‡ªé€‚åº”å‚æ•°è®¡ç®—å¤±è´¥: {e}")
            # è¿”å›é»˜è®¤å‚æ•°
            return {
                'base_scale': 20,
                'resolution_factor': 1.0,
                'eye_size_factor': 1.0,
                'final_scale': 20,
                'max_displacement': 35,
                'mask_radius': 12
            }
    
    def calculate_movement_strategy(self, features, pose_analysis, adjustment_type, adaptive_params):
        """åŸºäºç¾å­¦åŸç†çš„ç§»åŠ¨ç­–ç•¥ (å¢å¼ºè‡ªé€‚åº”ç‰ˆæœ¬)"""
        
        # ä½¿ç”¨è‡ªé€‚åº”scaleæ›¿ä»£å›ºå®šscale
        base_scale = adaptive_params['final_scale']
        max_displacement = adaptive_params['max_displacement']
        
        # åŸºç¡€ç­–ç•¥ - ä½¿ç”¨è‡ªé€‚åº”scale
        strategy = {
            'outer_corner': {'intensity': 1.0, 'direction': 'radial', 'scale': base_scale},
            'outer_support': {'intensity': 0.8, 'direction': 'radial', 'scale': base_scale * 0.8},
            'inner_corner': {'intensity': 0.2, 'direction': 'minimal', 'scale': base_scale * 0.4},
            'upper_lid': {'intensity': 0.6, 'direction': 'arch', 'scale': base_scale * 0.7},
            'lower_lid': {'intensity': 0.4, 'direction': 'gentle', 'scale': base_scale * 0.6},
        }
        
        # ç¾å­¦ç¦å¿Œå’Œå¢å¼ºè§„åˆ™
        warnings = []
        
        if features.get('upward_tilt') and adjustment_type in ['lift', 'shape']:
            # ä¸Šæ‰¬çœ¼ç¦æ­¢è¿›ä¸€æ­¥ä¸Šæ‰¬
            strategy['outer_corner']['direction'] = 'horizontal_only'
            strategy['outer_support']['direction'] = 'horizontal_only'
            warnings.append("ğŸš« ä¸Šæ‰¬çœ¼ç‰¹å¾ï¼šç¦æ­¢è¿›ä¸€æ­¥ä¸Šæ‰¬")
        
        if features.get('very_elongated') and adjustment_type in ['stretch', 'shape']:
            # ç»†é•¿çœ¼ç¦æ­¢è¿›ä¸€æ­¥æ‹‰é•¿
            for region in strategy:
                strategy[region]['direction'] = 'vertical_priority'
                strategy[region]['scale'] *= 0.7
            warnings.append("ğŸš« ç»†é•¿çœ¼ç‰¹å¾ï¼šé™åˆ¶æ°´å¹³æ‹‰é•¿")
        
        if features.get('downward_tilt'):
            # ä¸‹å‚çœ¼å¢å¼ºä¸Šæ‰¬ - ä½¿ç”¨æ›´å¤§çš„scale
            strategy['outer_corner']['direction'] = 'upward_priority'
            strategy['outer_corner']['intensity'] = 1.4
            strategy['outer_corner']['scale'] = base_scale * 1.2  # å¢å¼ºscale
            strategy['upper_lid']['intensity'] = 0.8
            warnings.append("âœ¨ ä¸‹å‚çœ¼ç‰¹å¾ï¼šå¯ç”¨ä¸Šæ‰¬å¢å¼º")
        
        if features.get('very_round'):
            # åœ†çœ¼å¢å¼ºæ‹‰é•¿ - ä½¿ç”¨æ›´å¤§çš„scale
            strategy['outer_corner']['direction'] = 'horizontal_priority'
            strategy['outer_corner']['intensity'] = 1.3
            strategy['outer_corner']['scale'] = base_scale * 1.15  # å¢å¼ºscale
            strategy['outer_support']['intensity'] = 1.0
            warnings.append("âœ¨ åœ†çœ¼ç‰¹å¾ï¼šå¯ç”¨æ‹‰é•¿å¢å¼º")
        
        # 3Då§¿æ€è°ƒæ•´
        pose_factor = pose_analysis['intensity_factor']
        for region in strategy:
            strategy[region]['intensity'] *= pose_factor
        
        if pose_analysis['difficulty'] != 'easy':
            warnings.append(f"ğŸ“ {pose_analysis['type']}å§¿æ€ï¼šå¼ºåº¦è°ƒæ•´ä¸º{pose_factor:.1f}x")
        
        # ä¸å¯¹ç§°å¤„ç†
        asymmetry_adjust = {'left': 1.0, 'right': 1.0}
        if features.get('asymmetric'):
            # ç®€åŒ–çš„ä¸å¯¹ç§°å¤„ç†
            asymmetry_adjust = {'left': 1.1, 'right': 0.9}
            warnings.append("âš–ï¸ ä¸å¯¹ç§°ç‰¹å¾ï¼šå¯ç”¨å·®å¼‚åŒ–è°ƒæ•´")
        
        # æ›´æ–°æœ€å¤§ä½ç§»é™åˆ¶
        for region in strategy:
            strategy[region]['max_displacement'] = max_displacement
        
        for warning in warnings:
            print(warning)
        
        return strategy, asymmetry_adjust
    
    def calculate_movement_vectors(self, landmarks_2d, adjustment_type, intensity, image_shape):
        """è®¡ç®—ç§»åŠ¨å‘é‡ - å¢å¼ºè‡ªé€‚åº”ç‰ˆæœ¬"""
        
        # 1. è®¡ç®—è‡ªé€‚åº”å‚æ•°
        adaptive_params = self.calculate_adaptive_parameters(landmarks_2d, image_shape)
        
        # 2. åˆ†æçœ¼å½¢ç‰¹å¾
        features, measurements = self.analyze_eye_characteristics(landmarks_2d)
        
        # 3. è®¡ç®—çœ¼çƒä¸­å¿ƒ
        left_center = (landmarks_2d[33] + landmarks_2d[133]) / 2
        right_center = (landmarks_2d[263] + landmarks_2d[362]) / 2
        
        # 4. è·å–å§¿æ€åˆ†æ
        pose_analysis = getattr(self, '_current_pose_analysis', 
                               {'type': 'frontal', 'yaw': 0, 'difficulty': 'easy', 'intensity_factor': 1.0})
        
        # 5. åˆ¶å®šç§»åŠ¨ç­–ç•¥ (ä¼ å…¥è‡ªé€‚åº”å‚æ•°)
        strategy, asymmetry_adjust = self.calculate_movement_strategy(features, pose_analysis, adjustment_type, adaptive_params)
        
        # 6. è®¡ç®—å…·ä½“ç§»åŠ¨å‘é‡
        movements = {}
        
        for eye_side in ['left_eye', 'right_eye']:
            eye_center = left_center if eye_side == 'left_eye' else right_center
            side_multiplier = asymmetry_adjust['left'] if eye_side == 'left_eye' else asymmetry_adjust['right']
            
            for region_name, point_indices in self.EYE_REGIONS[eye_side].items():
                if region_name in strategy:
                    region_strategy = strategy[region_name]
                    
                    for point_idx in point_indices:
                        if point_idx < len(landmarks_2d):
                            movement = self.calculate_point_movement(
                                landmarks_2d[point_idx], eye_center, region_strategy,
                                adjustment_type, intensity * side_multiplier, adaptive_params
                            )
                            movements[point_idx] = movement
        
        # 7. ç»“æ„ä¿æŠ¤ (ä¼ å…¥è‡ªé€‚åº”å‚æ•°)
        movements = self.apply_structure_protection(movements, landmarks_2d, adaptive_params)
        
        return movements, adaptive_params
    
    def calculate_point_movement(self, point, eye_center, strategy, adjustment_type, intensity, adaptive_params):
        """è®¡ç®—å•ç‚¹ç§»åŠ¨å‘é‡ - è‡ªé€‚åº”ç‰ˆæœ¬"""
        
        direction_type = strategy['direction']
        region_intensity = strategy['intensity']
        scale = strategy['scale']  # ç°åœ¨æ˜¯è‡ªé€‚åº”çš„scale
        max_displacement = strategy.get('max_displacement', adaptive_params['max_displacement'])
        
        # åŸºç¡€æ–¹å‘å‘é‡
        to_point = point - eye_center
        to_point_norm = np.linalg.norm(to_point)
        if to_point_norm <= 1e-6:
            return np.array([0.0, 0.0])
        
        to_point_unit = to_point / to_point_norm
        
        # æ ¹æ®æ–¹å‘ç±»å‹è®¡ç®—ç§»åŠ¨å‘é‡
        if direction_type == 'minimal':
            movement_vector = to_point_unit * 0.2
        elif direction_type == 'horizontal_only':
            movement_vector = np.array([to_point_unit[0], 0])
        elif direction_type == 'vertical_priority':
            movement_vector = np.array([to_point_unit[0] * 0.3, to_point_unit[1]])
        elif direction_type == 'horizontal_priority':
            horizontal = np.array([to_point_unit[0], 0])
            vertical = np.array([0, to_point_unit[1]])
            movement_vector = horizontal * 0.8 + vertical * 0.2
        elif direction_type == 'upward_priority':
            upward = np.array([0, -1])
            movement_vector = to_point_unit * 0.4 + upward * 0.6
        else:  # 'radial', 'arch', 'gentle'
            movement_vector = to_point_unit
        
        # å½’ä¸€åŒ–
        movement_norm = np.linalg.norm(movement_vector)
        if movement_norm > 1e-6:
            movement_vector = movement_vector / movement_norm
        
        # åº”ç”¨è°ƒæ•´ç±»å‹çš„ä¿®æ­£
        type_scales = {'stretch': 1.2, 'lift': 1.0, 'shape': 1.1}
        type_scale = type_scales.get(adjustment_type, 1.0)
        
        # è®¡ç®—æœ€ç»ˆç§»åŠ¨ - ç°åœ¨scaleæ˜¯è‡ªé€‚åº”çš„
        final_movement = movement_vector * intensity * region_intensity * scale * type_scale
        
        # è‡ªé€‚åº”å®‰å…¨é™åˆ¶
        movement_magnitude = np.linalg.norm(final_movement)
        if movement_magnitude > max_displacement:
            final_movement = final_movement * (max_displacement / movement_magnitude)
        
        return final_movement
    
    def apply_structure_protection(self, movements, landmarks_2d, adaptive_params):
        """ç®€åŒ–çš„ç»“æ„ä¿æŠ¤ - è‡ªé€‚åº”ç‰ˆæœ¬"""
        
        if not movements:
            return movements
        
        protected_movements = movements.copy()
        
        # ä½¿ç”¨è‡ªé€‚åº”çš„å·®å¼‚é˜ˆå€¼
        base_scale = adaptive_params['final_scale']
        difference_threshold = base_scale * 2.0  # ç›¸å¯¹äºé¢„æœŸç§»åŠ¨è·ç¦»çš„é˜ˆå€¼
        
        # å®šä¹‰ç›¸é‚»ç‚¹ç»„ (ç®€åŒ–ç‰ˆ)
        adjacent_groups = [
            [33, 7, 163],               # å·¦çœ¼å¤–è§’
            [157, 158, 159, 160],       # å·¦çœ¼ä¸Šçœ¼ç‘
            [263, 249, 390],            # å³çœ¼å¤–è§’
            [386, 387, 388, 466]        # å³çœ¼ä¸Šçœ¼ç‘
        ]
        
        for group in adjacent_groups:
            valid_movements = []
            valid_indices = []
            
            for idx in group:
                if idx in movements:
                    valid_movements.append(movements[idx])
                    valid_indices.append(idx)
            
            if len(valid_movements) >= 2:
                # è‡ªé€‚åº”å¹³æ»‘ï¼šå¦‚æœç›¸é‚»ç‚¹ç§»åŠ¨å·®å¼‚è¿‡å¤§ï¼Œè¿›è¡Œå¹³æ»‘
                for i in range(len(valid_movements) - 1):
                    curr_movement = valid_movements[i]
                    next_movement = valid_movements[i + 1]
                    
                    curr_mag = np.linalg.norm(curr_movement)
                    next_mag = np.linalg.norm(next_movement)
                    
                    # ä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼åˆ¤æ–­æ˜¯å¦éœ€è¦å¹³æ»‘
                    mag_diff = abs(curr_mag - next_mag)
                    if mag_diff > difference_threshold:
                        avg_mag = (curr_mag + next_mag) / 2
                        curr_dir = curr_movement / max(curr_mag, 1e-6)
                        next_dir = next_movement / max(next_mag, 1e-6)
                        avg_dir = (curr_dir + next_dir) / 2
                        avg_dir = avg_dir / max(np.linalg.norm(avg_dir), 1e-6)
                        
                        protected_movements[valid_indices[i]] = avg_dir * avg_mag * 0.9
                        protected_movements[valid_indices[i + 1]] = avg_dir * avg_mag * 0.9
        
        return protected_movements
    
    def create_eye_mask(self, image_shape, landmarks_2d, adaptive_params):
        """åˆ›å»ºçœ¼éƒ¨mask - è‡ªé€‚åº”ç‰ˆæœ¬"""
        h, w = image_shape[:2]
        mask = np.zeros((h, w), dtype=np.uint8)
        
        # æ”¶é›†æ‰€æœ‰çœ¼éƒ¨ç‚¹
        eye_points = []
        for eye_regions in self.EYE_REGIONS.values():
            for point_list in eye_regions.values():
                for idx in point_list:
                    if idx < len(landmarks_2d):
                        eye_points.append(landmarks_2d[idx])
        
        if len(eye_points) < 8:
            return mask
        
        # ä½¿ç”¨è‡ªé€‚åº”çš„maskåŠå¾„
        mask_radius = int(adaptive_params['mask_radius'])
        
        # ä¸ºæ¯ä¸ªç‚¹åˆ›å»ºåœ†å½¢åŒºåŸŸ
        eye_points = np.array(eye_points, dtype=np.int32)
        for point in eye_points:
            cv2.circle(mask, tuple(point), mask_radius, 255, -1)
        
        # è‡ªé€‚åº”çš„å½¢æ€å­¦å¤„ç†
        kernel_size = max(3, int(mask_radius / 4))
        kernel = np.ones((kernel_size, kernel_size), np.uint8)
        mask = cv2.dilate(mask, kernel, iterations=1)
        
        return mask
    
    def apply_eye_corner_adjustment(self, image, landmarks_2d, pose_info, adjustment_type="stretch", intensity=0.3):
        """åº”ç”¨çœ¼è§’è°ƒæ•´ - ä¸»å¤„ç†å‡½æ•° (è‡ªé€‚åº”ç‰ˆæœ¬)"""
        
        print(f"ğŸ¯ å¼€å§‹çœ¼è§’è°ƒæ•´:")
        print(f"   è°ƒæ•´ç±»å‹: {adjustment_type}")
        print(f"   è°ƒæ•´å¼ºåº¦: {intensity}")
        
        # ç¼“å­˜å§¿æ€åˆ†æç»“æœ
        self._current_pose_analysis = self.get_pose_analysis(pose_info)
        pose_analysis = self._current_pose_analysis
        
        print(f"   3Då§¿æ€: {pose_analysis['type']} (yaw={pose_analysis['yaw']:.1f}Â°)")
        
        # è®¡ç®—ç§»åŠ¨å‘é‡ (ç°åœ¨è¿”å›è‡ªé€‚åº”å‚æ•°)
        movement_vectors, adaptive_params = self.calculate_movement_vectors(landmarks_2d, adjustment_type, intensity, image.shape)
        
        if not movement_vectors:
            print("âŒ æœªç”Ÿæˆæœ‰æ•ˆç§»åŠ¨å‘é‡")
            return image
        
        # æ„å»ºæ§åˆ¶ç‚¹
        src_points = []
        dst_points = []
        used_indices = set()
        
        # æ·»åŠ ç§»åŠ¨ç‚¹
        movement_count = 0
        total_movement = 0
        for point_idx, movement in movement_vectors.items():
            src_points.append(landmarks_2d[point_idx])
            dst_points.append(landmarks_2d[point_idx] + movement)
            used_indices.add(point_idx)
            movement_count += 1
            total_movement += np.linalg.norm(movement)
        
        avg_movement = total_movement / movement_count if movement_count > 0 else 0
        
        # æ·»åŠ ç¨³å®šé”šç‚¹
        anchor_count = 0
        for idx in self.STABLE_ANCHORS:
            if idx < len(landmarks_2d) and idx not in used_indices:
                src_points.append(landmarks_2d[idx])
                dst_points.append(landmarks_2d[idx])
                used_indices.add(idx)
                anchor_count += 1
        
        # æ·»åŠ è¾¹ç•Œé”šç‚¹
        h, w = image.shape[:2]
        boundary_points = [
            [30, 30], [w//2, 30], [w-30, 30],
            [30, h//2], [w-30, h//2],
            [30, h-30], [w//2, h-30], [w-30, h-30]
        ]
        
        for bp in boundary_points:
            src_points.append(bp)
            dst_points.append(bp)
        
        print(f"ğŸ”§ æ§åˆ¶ç‚¹: ç§»åŠ¨={movement_count}, é”šç‚¹={anchor_count}, è¾¹ç•Œ=8, æ€»è®¡={len(src_points)}")
        print(f"   å¹³å‡ç§»åŠ¨è·ç¦»: {avg_movement:.1f}åƒç´  (é¢„æœŸ: {adaptive_params['final_scale']:.1f})")
        
        # æ•ˆæœé¢„æœŸè¯„ä¼°
        expected_range = adaptive_params['final_scale']
        if avg_movement < expected_range * 0.5:
            print("âš ï¸ å®é™…ç§»åŠ¨è·ç¦»ä½äºé¢„æœŸï¼Œæ•ˆæœå¯èƒ½ä¸æ˜æ˜¾")
        elif avg_movement > expected_range * 1.5:
            print("âš ï¸ å®é™…ç§»åŠ¨è·ç¦»è¶…å‡ºé¢„æœŸï¼Œè¯·æ£€æŸ¥å‚æ•°")
        else:
            print("âœ… ç§»åŠ¨è·ç¦»åœ¨é¢„æœŸèŒƒå›´å†…")
        
        # éªŒè¯æ§åˆ¶ç‚¹æ•°é‡
        if len(src_points) < 15:
            print("âŒ æ§åˆ¶ç‚¹æ•°é‡ä¸è¶³")
            return image
        
        # TPSå˜å½¢
        try:
            src_points = np.array(src_points, dtype=np.float32)
            dst_points = np.array(dst_points, dtype=np.float32)
            
            tps = cv2.createThinPlateSplineShapeTransformer()
            matches = [cv2.DMatch(i, i, 0) for i in range(len(src_points))]
            
            tps.estimateTransformation(
                dst_points.reshape(1, -1, 2), 
                src_points.reshape(1, -1, 2), 
                matches
            )
            
            transformed = tps.warpImage(image)
            
            if transformed is None:
                print("âŒ TPSå˜æ¢å¤±è´¥")
                return image
            
            # åˆ›å»ºè‡ªé€‚åº”maskå¹¶èåˆ
            eye_mask = self.create_eye_mask(image.shape, landmarks_2d, adaptive_params)
            mask_3d = cv2.merge([eye_mask, eye_mask, eye_mask]).astype(np.float32) / 255.0
            mask_blurred = cv2.GaussianBlur(mask_3d, (5, 5), 0)
            
            result = image.astype(np.float32) * (1 - mask_blurred) + transformed.astype(np.float32) * mask_blurred
            result = np.clip(result, 0, 255).astype(np.uint8)
            
            print("âœ… çœ¼è§’è°ƒæ•´å®Œæˆ")
            
            # æ•ˆæœè¯„ä¼°
            diff = cv2.absdiff(image, result)
            total_diff = np.sum(diff)
            relative_change = total_diff / (image.shape[0] * image.shape[1] * 255 * 3)
            
            print(f"ğŸ“Š å˜åŒ–è¯„ä¼°:")
            print(f"   æ€»å·®å¼‚: {total_diff:,}")
            print(f"   å¹³å‡ç§»åŠ¨: {avg_movement:.1f}px")
            print(f"   ç›¸å¯¹å˜åŒ–: {relative_change:.4f}")
            print(f"   è‡ªé€‚åº”scale: {adaptive_params['final_scale']:.1f}px")
            
            # æ™ºèƒ½å»ºè®®
            if relative_change < 0.001:
                print("ğŸ’¡ æ•ˆæœè¾ƒå°å»ºè®®:")
                print("   â€¢ å½“å‰å›¾åƒåˆ†è¾¨ç‡è¾ƒé«˜ï¼Œéœ€è¦æ›´å¤§çš„è°ƒæ•´å¼ºåº¦")
                print("   â€¢ å»ºè®®å¼ºåº¦èŒƒå›´: 0.4-0.6")
            elif relative_change > 0.01:
                print("ğŸ’¡ æ•ˆæœè¾ƒå¤§æé†’:")
                print("   â€¢ è°ƒæ•´æ•ˆæœæ¯”è¾ƒæ˜æ˜¾ï¼Œå¦‚éœ€æ›´è‡ªç„¶å¯é™ä½å¼ºåº¦")
                print("   â€¢ å»ºè®®å¼ºåº¦èŒƒå›´: 0.2-0.3")
            else:
                print("âœ… è°ƒæ•´æ•ˆæœé€‚ä¸­ï¼Œåœ¨ç†æƒ³èŒƒå›´å†…")
            
            return result
            
        except Exception as e:
            print(f"âŒ TPSå˜å½¢å¼‚å¸¸: {e}")
            return image
    
    def debug_eye_analysis(self, image, save_path=None):
        """è°ƒè¯•çœ¼å½¢åˆ†æ - å¢å¼ºè‡ªé€‚åº”ç‰ˆæœ¬"""
        
        landmarks_2d, pose_info = self.detect_landmarks_with_pose(image)
        if landmarks_2d is None:
            print("âŒ æœªæ£€æµ‹åˆ°é¢éƒ¨å…³é”®ç‚¹")
            return image
        
        features, measurements = self.analyze_eye_characteristics(landmarks_2d)
        pose_analysis = self.get_pose_analysis(pose_info)
        
        # è®¡ç®—è‡ªé€‚åº”å‚æ•°ç”¨äºè°ƒè¯•æ˜¾ç¤º
        adaptive_params = self.calculate_adaptive_parameters(landmarks_2d, image.shape)
        
        debug_img = image.copy()
        
        # ç»˜åˆ¶çœ¼éƒ¨åŒºåŸŸ
        colors = {
            'outer_corner': (0, 255, 0),    # ç»¿è‰²
            'outer_support': (0, 200, 0),   # æ·±ç»¿
            'inner_corner': (255, 0, 0),    # çº¢è‰²
            'upper_lid': (0, 0, 255),       # è“è‰²
            'lower_lid': (255, 255, 0),     # é»„è‰²
        }
        
        for eye_side, regions in self.EYE_REGIONS.items():
            for region_name, point_indices in regions.items():
                color = colors.get(region_name, (128, 128, 128))
                for i, idx in enumerate(point_indices):
                    if idx < len(landmarks_2d):
                        point = landmarks_2d[idx].astype(int)
                        cv2.circle(debug_img, tuple(point), 4, color, -1)
                        cv2.putText(debug_img, f"{eye_side[0].upper()}{region_name[:3].upper()}{i}", 
                                   tuple(point + 6), cv2.FONT_HERSHEY_SIMPLEX, 0.25, color, 1)
        
        # æ˜¾ç¤ºåˆ†æç»“æœ
        info_y = 30
        cv2.putText(debug_img, f"3D Pose: {pose_analysis['type']} (yaw={pose_analysis['yaw']:.1f}Â°)", 
                   (10, info_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
        
        cv2.putText(debug_img, f"Eye Features:", (10, info_y + 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        
        feature_y = info_y + 60
        for feature, value in features.items():
            if value:
                cv2.putText(debug_img, f"âœ“ {feature}", (10, feature_y), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
                feature_y += 20
        
        cv2.putText(debug_img, f"Tilt: {measurements.get('avg_tilt', 0):.1f}Â°, Ratio: {measurements.get('avg_ratio', 0):.2f}", 
                   (10, feature_y + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 1)
        
        # æ˜¾ç¤ºè‡ªé€‚åº”å‚æ•°
        cv2.putText(debug_img, f"Adaptive Scale: {adaptive_params['final_scale']:.1f}px", 
                   (10, feature_y + 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 128, 0), 1)
        
        cv2.putText(debug_img, f"Resolution Factor: {adaptive_params['resolution_factor']:.2f}", 
                   (10, feature_y + 80), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 128, 0), 1)
        
        cv2.putText(debug_img, f"Max Displacement: {adaptive_params['max_displacement']:.1f}px", 
                   (10, feature_y + 100), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 128, 0), 1)
        
        # æ˜¾ç¤ºçœ¼çƒä¸­å¿ƒ
        if len(landmarks_2d) > 362:
            left_center = (landmarks_2d[33] + landmarks_2d[133]) / 2
            right_center = (landmarks_2d[263] + landmarks_2d[362]) / 2
            cv2.circle(debug_img, tuple(left_center.astype(int)), 6, (255, 255, 0), -1)
            cv2.circle(debug_img, tuple(right_center.astype(int)), 6, (255, 255, 0), -1)
        
        # æ˜¾ç¤ºè‡ªé€‚åº”maské¢„è§ˆ
        mask_preview = self.create_eye_mask(image.shape, landmarks_2d, adaptive_params)
        mask_overlay = debug_img.copy()
        mask_overlay[mask_preview > 0] = [255, 0, 255]
        debug_img = cv2.addWeighted(debug_img, 0.8, mask_overlay, 0.2, 0)
        
        if save_path:
            cv2.imwrite(save_path, debug_img)
            print(f"ğŸ“ è°ƒè¯•å›¾ä¿å­˜åˆ°: {save_path}")
            
            # è¾“å‡ºè¯¦ç»†çš„è‡ªé€‚åº”å‚æ•°ä¿¡æ¯åˆ°æ§åˆ¶å°
            print(f"\nğŸ“Š è¯¦ç»†è‡ªé€‚åº”å‚æ•°:")
            for key, value in adaptive_params.items():
                print(f"   {key}: {value}")
        
        return debug_img
    
    def process_image(self, image, adjustment_type="stretch", intensity=0.3, auto_optimize=True):
        """å¤„ç†å›¾åƒçš„ä¸»æ¥å£"""
        
        # æ£€æµ‹å…³é”®ç‚¹å’Œå§¿æ€
        landmarks_2d, pose_info = self.detect_landmarks_with_pose(image)
        if landmarks_2d is None:
            print("âŒ æœªæ£€æµ‹åˆ°é¢éƒ¨å…³é”®ç‚¹")
            return image
        
        print(f"âœ… æ£€æµ‹åˆ° {len(landmarks_2d)} ä¸ªå…³é”®ç‚¹")
        
        # Auto-Optimize: æ ¹æ®çœ¼å½¢ç‰¹å¾ä¼˜åŒ–å‚æ•°
        if auto_optimize:
            features, measurements = self.analyze_eye_characteristics(landmarks_2d)
            pose_analysis = self.get_pose_analysis(pose_info)
            
            print("ğŸ§  Auto-Optimizeåˆ†æ:")
            
            # æ˜¾ç¤ºæ£€æµ‹åˆ°çš„ç‰¹å¾
            active_features = [f for f, v in features.items() if v]
            if active_features:
                print(f"   æ£€æµ‹ç‰¹å¾: {', '.join(active_features)}")
            else:
                print("   æ£€æµ‹ç‰¹å¾: æ ‡å‡†çœ¼å½¢")
            
            # æ™ºèƒ½è°ƒæ•´å»ºè®®
            original_intensity = intensity
            
            # åŸºäºçœ¼å½¢ç‰¹å¾è°ƒæ•´å¼ºåº¦
            if features.get('very_round') and adjustment_type in ['stretch', 'shape']:
                intensity = max(intensity, 0.35)  # åœ†çœ¼éœ€è¦æ›´å¤§å¼ºåº¦
                print(f"   åœ†çœ¼ä¼˜åŒ–: å¼ºåº¦æå‡è‡³ {intensity}")
            
            if features.get('downward_tilt') and adjustment_type in ['lift', 'shape']:
                intensity = max(intensity, 0.4)   # ä¸‹å‚çœ¼éœ€è¦æ›´å¤§å¼ºåº¦
                print(f"   ä¸‹å‚çœ¼ä¼˜åŒ–: å¼ºåº¦æå‡è‡³ {intensity}")
            
            if features.get('upward_tilt') and adjustment_type == 'lift':
                adjustment_type = 'stretch'  # è‡ªåŠ¨åˆ‡æ¢è°ƒæ•´ç±»å‹
                print(f"   ä¸Šæ‰¬çœ¼ä¼˜åŒ–: è°ƒæ•´ç±»å‹åˆ‡æ¢ä¸º {adjustment_type}")
            
            if features.get('very_elongated') and adjustment_type == 'stretch':
                adjustment_type = 'lift'     # è‡ªåŠ¨åˆ‡æ¢è°ƒæ•´ç±»å‹
                print(f"   ç»†é•¿çœ¼ä¼˜åŒ–: è°ƒæ•´ç±»å‹åˆ‡æ¢ä¸º {adjustment_type}")
            
            # åŸºäºå§¿æ€è°ƒæ•´å¼ºåº¦
            if pose_analysis['difficulty'] != 'easy':
                intensity *= pose_analysis['intensity_factor']
                print(f"   å§¿æ€ä¼˜åŒ–: å¼ºåº¦è°ƒæ•´ä¸º {intensity:.3f} (å› å­: {pose_analysis['intensity_factor']:.2f})")
            
            # ç¡®ä¿æœ€å°æœ‰æ•ˆå¼ºåº¦
            intensity = max(intensity, 0.2)
            
            if abs(intensity - original_intensity) > 0.05:
                print(f"   æœ€ç»ˆä¼˜åŒ–: {original_intensity:.2f} â†’ {intensity:.2f}")
        
        # åº”ç”¨è°ƒæ•´
        result = self.apply_eye_corner_adjustment(image, landmarks_2d, pose_info, adjustment_type, intensity)
        
        return result

def main():
    parser = argparse.ArgumentParser(description='ç²¾ç®€é«˜æ•ˆçœ¼è§’è°ƒæ•´å™¨ - åŸºäºç¾å­¦åŸç†çš„æ™ºèƒ½è°ƒæ•´')
    parser.add_argument('--input', '-i', required=True, help='è¾“å…¥å›¾ç‰‡è·¯å¾„')
    parser.add_argument('--output', '-o', required=True, help='è¾“å‡ºå›¾ç‰‡è·¯å¾„')
    parser.add_argument('--type', '-t', choices=['stretch', 'lift', 'shape'], 
                       default='stretch', help='è°ƒæ•´ç±»å‹: stretch=æ‹‰é•¿, lift=ä¸Šæ‰¬, shape=ç»¼åˆ')
    parser.add_argument('--intensity', type=float, default=0.3, 
                       help='è°ƒæ•´å¼ºåº¦ (0.1-0.5)')
    parser.add_argument('--auto-optimize', action='store_true', default=True,
                       help='å¯ç”¨æ™ºèƒ½ä¼˜åŒ– (é»˜è®¤å¼€å¯)')
    parser.add_argument('--no-auto-optimize', dest='auto_optimize', action='store_false',
                       help='ç¦ç”¨æ™ºèƒ½ä¼˜åŒ–')
    parser.add_argument('--debug', action='store_true', help='è°ƒè¯•æ¨¡å¼')
    parser.add_argument('--comparison', action='store_true', help='ç”Ÿæˆå¯¹æ¯”å›¾')
    
    args = parser.parse_args()
    
    # åŠ è½½å›¾ç‰‡
    image = cv2.imread(args.input)
    if image is None:
        print(f"âŒ æ— æ³•åŠ è½½å›¾ç‰‡: {args.input}")
        return
    
    print(f"ğŸ“¸ å›¾ç‰‡ä¿¡æ¯: {image.shape[1]}Ã—{image.shape[0]} åƒç´ ")
    
    # å¼ºåº¦å®‰å…¨æ£€æŸ¥
    if args.intensity > 0.5:
        print(f"âš ï¸ å¼ºåº¦ {args.intensity} è¿‡å¤§ï¼Œé™åˆ¶åˆ°0.5")
        args.intensity = 0.5
    elif args.intensity < 0.1:
        print(f"âš ï¸ å¼ºåº¦ {args.intensity} è¿‡å°ï¼Œæå‡åˆ°0.1")
        args.intensity = 0.1
    
    # åˆ›å»ºè°ƒæ•´å™¨
    adjuster = EyeCornerAdjuster()
    
    # è°ƒè¯•æ¨¡å¼
    if args.debug:
        debug_result = adjuster.debug_eye_analysis(image, args.output)
        print(f"ğŸ” è°ƒè¯•å›¾ä¿å­˜åˆ°: {args.output}")
        return
    
    # å¤„ç†å›¾ç‰‡
    print(f"ğŸš€ å¯åŠ¨çœ¼è§’è°ƒæ•´...")
    print(f"   Auto-Optimize: {'å¼€å¯' if args.auto_optimize else 'å…³é—­'}")
    
    result = adjuster.process_image(image, args.type, args.intensity, args.auto_optimize)
    
    # ä¿å­˜ç»“æœ
    cv2.imwrite(args.output, result)
    print(f"âœ… å¤„ç†å®Œæˆï¼Œä¿å­˜åˆ°: {args.output}")
    
    # ç”Ÿæˆå¯¹æ¯”å›¾
    if args.comparison:
        comparison_path = args.output.replace('.', '_comparison.')
        comparison = np.hstack([image, result])
        cv2.line(comparison, (image.shape[1], 0), (image.shape[1], image.shape[0]), (0, 255, 0), 3)
        
        # æ·»åŠ æ ‡ç­¾
        cv2.putText(comparison, 'Original', (20, 50), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3)
        cv2.putText(comparison, f'{args.type.upper()}-{args.intensity:.2f}', 
                   (image.shape[1] + 20, 50), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)
        
        cv2.imwrite(comparison_path, comparison)
        print(f"ğŸ“Š å¯¹æ¯”å›¾ä¿å­˜åˆ°: {comparison_path}")
    
    # æœ€ç»ˆç»Ÿè®¡
    diff = cv2.absdiff(image, result)
    total_diff = np.sum(diff)
    changed_pixels = np.sum(diff > 0)
    
    print(f"\nğŸ“Š å¤„ç†ç»Ÿè®¡:")
    print(f"   æ€»åƒç´ å˜åŒ–: {total_diff:,}")
    print(f"   å˜åŒ–åƒç´ æ•°: {changed_pixels:,}")
    print(f"   å˜åŒ–å¼ºåº¦: {total_diff/(image.shape[0]*image.shape[1]*255*3):.4f}")
    
    if total_diff < 50000:
        print("ğŸ’¡ å˜åŒ–è¾ƒå°å»ºè®®:")
        print("   â€¢ å°è¯•å¢åŠ  --intensity å‚æ•°")
        print("   â€¢ ä½¿ç”¨ --debug æŸ¥çœ‹çœ¼å½¢ç‰¹å¾æ£€æµ‹")
        print("   â€¢ ç¡®ä¿å›¾ç‰‡ä¸­äººè„¸æ¸…æ™°ä¸”è§’åº¦åˆé€‚")
    
    print(f"\nğŸŒŸ ç²¾ç®€çœ¼è§’è°ƒæ•´å™¨ç‰¹è‰²:")
    print("âœ… 3Då§¿æ€æ„ŸçŸ¥ - çœŸå®å¤´éƒ¨å§¿æ€ä¼°è®¡")
    print("âœ… ç¾å­¦å¯¼å‘ç­–ç•¥ - åŸºäºçœ¼å½¢ç‰¹å¾çš„æ™ºèƒ½è°ƒæ•´")
    print("âœ… ç»“æ„å®Œæ•´æ€§ä¿æŠ¤ - ç¡®ä¿è‡ªç„¶åè°ƒçš„æ•ˆæœ")
    print("âœ… Auto-Optimize - æ™ºèƒ½å‚æ•°ä¼˜åŒ–")
    print("âœ… ç²¾ç®€é«˜æ•ˆ - åˆ é™¤å†—ä½™åŠŸèƒ½ï¼Œä¸“æ³¨æ ¸å¿ƒæ•ˆæœ")
    
    print(f"\nğŸ“– ä½¿ç”¨ç¤ºä¾‹:")
    print("â€¢ æ™ºèƒ½è‡ªåŠ¨è°ƒæ•´: python script.py -i input.jpg -o output.png --comparison")
    print("â€¢ æ‰‹åŠ¨è°ƒæ•´å‚æ•°: python script.py -i input.jpg -o output.png -t lift --intensity 0.4")
    print("â€¢ è°ƒè¯•çœ¼å½¢åˆ†æ: python script.py -i input.jpg -o debug.png --debug")
    print("â€¢ ç¦ç”¨æ™ºèƒ½ä¼˜åŒ–: python script.py -i input.jpg -o output.png --no-auto-optimize")

if __name__ == "__main__":
    main()