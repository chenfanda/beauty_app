#!/usr/bin/env python3
"""
3Då§¿æ€æ„ŸçŸ¥çš„çœ¼è§’è°ƒæ•´è„šæœ¬ - eye_corner_3d_complete.py
æ ¸å¿ƒç‰¹è‰²ï¼š
1. åŸºäºPnPç®—æ³•çš„çœŸå®3Då¤´éƒ¨å§¿æ€ä¼°è®¡
2. 3Dæ„ŸçŸ¥çš„è‡ªé€‚åº”çœ¼è§’å˜å½¢ç­–ç•¥
3. çœ¼å½¢è¯†åˆ« + 3Då§¿æ€çš„åŒé‡æ™ºèƒ½æ§åˆ¶
4. é€è§†æ ¡æ­£çš„å‚è€ƒç‚¹è®¡ç®—
5. å§¿æ€è‡ªé€‚åº”çš„ç§»åŠ¨å‘é‡å’Œå¼ºåº¦
"""

import cv2
import numpy as np
import mediapipe as mp
import argparse
import os
from typing import List, Tuple, Optional, Dict

class EyeShape3DAnalyzer:
    """3Dæ„ŸçŸ¥çš„çœ¼å½¢è¯†åˆ«å’Œåˆ†ææ¨¡å—"""
    
    def __init__(self):
        # åŸºäºåŒ»å­¦ç¾å­¦çš„çœ¼å½¢åˆ†ç±»æ ‡å‡†
        self.EYE_SHAPE_CATEGORIES = {
            'round': {
                'length_width_ratio': (2.0, 2.7),
                'tilt_angle': (-5, 5),
                'recommended_adjustments': ['stretch', 'lift', 'shape'],
                'pose_sensitivity': {'frontal': 1.0, 'profile': 0.8},
                'description': 'åœ†æ¶¦å¯çˆ±å‹çœ¼ç›ï¼Œé€‚åˆæ‹‰é•¿å’Œä¸Šæ‰¬'
            },
            'almond': {
                'length_width_ratio': (2.8, 3.2),
                'tilt_angle': (5, 15),
                'recommended_adjustments': ['minimal', 'enhancement'],
                'pose_sensitivity': {'frontal': 0.7, 'profile': 0.5},
                'description': 'ç†æƒ³æä»çœ¼å‹ï¼Œåªéœ€è½»å¾®è°ƒæ•´'
            },
            'upturned': {
                'length_width_ratio': (2.5, 3.5),
                'tilt_angle': (15, 25),
                'recommended_adjustments': ['stretch_only'],
                'contraindicated': ['lift'],
                'pose_sensitivity': {'frontal': 0.8, 'profile': 0.6},
                'description': 'å·²ç»ä¸Šæ‰¬çš„çœ¼å‹ï¼Œé¿å…è¿‡åº¦è°ƒæ•´'
            },
            'downturned': {
                'length_width_ratio': (2.3, 3.0),
                'tilt_angle': (-15, -5),
                'recommended_adjustments': ['lift', 'shape'],
                'pose_sensitivity': {'frontal': 1.2, 'profile': 1.0},
                'description': 'ä¸‹å‚çœ¼å‹ï¼Œæœ€é€‚åˆä¸Šæ‰¬è°ƒæ•´'
            },
            'elongated': {
                'length_width_ratio': (3.3, 4.0),
                'tilt_angle': (-5, 10),
                'recommended_adjustments': ['lift'],
                'contraindicated': ['stretch'],
                'pose_sensitivity': {'frontal': 0.6, 'profile': 0.8},
                'description': 'ç»†é•¿çœ¼å‹ï¼Œé¿å…è¿›ä¸€æ­¥æ‹‰é•¿'
            },
            'normal': {
                'length_width_ratio': (2.7, 3.1),
                'tilt_angle': (-3, 8),
                'recommended_adjustments': ['stretch', 'lift', 'shape'],
                'pose_sensitivity': {'frontal': 1.0, 'profile': 0.9},
                'description': 'æ ‡å‡†çœ¼å‹ï¼Œå„ç§è°ƒæ•´å‡é€‚ç”¨'
            }
        }
    
    def analyze_eye_shape_3d(self, landmarks_2d, pose_info):
        """åŸºäº3Då§¿æ€çš„çœ¼å½¢åˆ†æ"""
        measurements = self.calculate_eye_measurements(landmarks_2d)
        
        # 3Då§¿æ€ä¿®æ­£
        if pose_info is not None:
            measurements = self.correct_measurements_for_3d_pose(measurements, pose_info)
        
        eye_shape = self.classify_eye_shape(measurements)
        
        # 3Då§¿æ€ä¿®æ­£åˆ†ç±»ç½®ä¿¡åº¦
        if pose_info is not None:
            eye_shape = self.adjust_classification_for_pose(eye_shape, pose_info)
        
        return {
            'eye_shape': eye_shape,
            'measurements': measurements,
            'recommendations': self.generate_3d_recommendations(eye_shape, pose_info)
        }
    
    def calculate_eye_measurements(self, landmarks_2d):
        """è®¡ç®—çœ¼å½¢çš„å…³é”®æµ‹é‡æŒ‡æ ‡"""
        # å·¦çœ¼å…³é”®ç‚¹
        left_inner = landmarks_2d[133]
        left_outer = landmarks_2d[33]
        left_top = landmarks_2d[159]
        left_bottom = landmarks_2d[145]
        
        # å³çœ¼å…³é”®ç‚¹
        right_inner = landmarks_2d[362]
        right_outer = landmarks_2d[263]
        right_top = landmarks_2d[386]
        right_bottom = landmarks_2d[374]
        
        # åŸºæœ¬å°ºå¯¸è®¡ç®—
        left_length = np.linalg.norm(left_outer - left_inner)
        left_height = np.linalg.norm(left_top - left_bottom)
        left_ratio = left_length / left_height if left_height > 0 else 3.0
        
        right_length = np.linalg.norm(right_outer - right_inner)
        right_height = np.linalg.norm(right_top - right_bottom)
        right_ratio = right_length / right_height if right_height > 0 else 3.0
        
        # å¹³å‡æ¯”ä¾‹
        avg_ratio = (left_ratio + right_ratio) / 2
        
        # å€¾æ–œè§’åº¦è®¡ç®—
        left_tilt = np.degrees(np.arctan2(
            left_outer[1] - left_inner[1],
            left_outer[0] - left_inner[0]
        ))
        
        right_tilt = np.degrees(np.arctan2(
            right_outer[1] - right_inner[1],
            right_outer[0] - right_inner[0]
        ))
        
        avg_tilt = (left_tilt + right_tilt) / 2
        
        return {
            'length_width_ratio': avg_ratio,
            'tilt_angle': avg_tilt,
            'left_ratio': left_ratio,
            'right_ratio': right_ratio,
            'symmetry_score': 1.0 - abs(left_ratio - right_ratio) / max(left_ratio, right_ratio),
            'absolute_size': (left_length + right_length) / 2
        }
    
    def correct_measurements_for_3d_pose(self, measurements, pose_info):
        """3Då§¿æ€é€è§†æ ¡æ­£"""
        rotation_vector, translation_vector = pose_info
        rotation_matrix, _ = cv2.Rodrigues(rotation_vector)
        
        # è®¡ç®—yawè§’åº¦
        sy = np.sqrt(rotation_matrix[0,0] * rotation_matrix[0,0] + rotation_matrix[1,0] * rotation_matrix[1,0])
        yaw = np.degrees(np.arctan2(-rotation_matrix[2,0], sy))
        
        # é€è§†æ ¡æ­£å› å­
        perspective_factor = np.cos(np.radians(abs(yaw)))
        
        # æ ¡æ­£é•¿å®½æ¯”ï¼ˆä¾§è„¸æ—¶çœ¼ç›è¢«å‹ç¼©ï¼‰
        corrected_ratio = measurements['length_width_ratio'] / max(perspective_factor, 0.7)
        
        # æ ¡æ­£å€¾æ–œè§’ï¼ˆä¾§è„¸æ—¶è§’åº¦è¢«æ‰­æ›²ï¼‰
        if abs(yaw) > 20:
            angle_correction = yaw * 0.3
            corrected_tilt = measurements['tilt_angle'] - angle_correction
        else:
            corrected_tilt = measurements['tilt_angle']
        
        measurements_corrected = measurements.copy()
        measurements_corrected['length_width_ratio'] = corrected_ratio
        measurements_corrected['tilt_angle'] = corrected_tilt
        measurements_corrected['pose_corrected'] = True
        measurements_corrected['yaw_angle'] = yaw
        
        print(f"ğŸ”„ 3Dé€è§†æ ¡æ­£: yaw={yaw:.1f}Â°, æ¯”ä¾‹{measurements['length_width_ratio']:.2f}â†’{corrected_ratio:.2f}")
        
        return measurements_corrected
    
    def adjust_classification_for_pose(self, eye_shape, pose_info):
        """åŸºäº3Då§¿æ€è°ƒæ•´åˆ†ç±»ç½®ä¿¡åº¦"""
        rotation_vector, _ = pose_info
        rotation_matrix, _ = cv2.Rodrigues(rotation_vector)
        sy = np.sqrt(rotation_matrix[0,0] * rotation_matrix[0,0] + rotation_matrix[1,0] * rotation_matrix[1,0])
        yaw = np.degrees(np.arctan2(-rotation_matrix[2,0], sy))
        
        # ä¾§è„¸æ—¶é™ä½åˆ†ç±»ç½®ä¿¡åº¦
        if abs(yaw) > 30:
            eye_shape['confidence'] *= 0.8
            eye_shape['pose_warning'] = f"å¤§è§’åº¦ä¾§è„¸(yaw={yaw:.1f}Â°)ï¼Œåˆ†ç±»ç²¾åº¦é™ä½"
        elif abs(yaw) > 15:
            eye_shape['confidence'] *= 0.9
        
        return eye_shape
    
    def classify_eye_shape(self, measurements):
        """åŸºäºæµ‹é‡å€¼åˆ†ç±»çœ¼å½¢"""
        ratio = measurements['length_width_ratio']
        tilt = measurements['tilt_angle']
        
        best_match = None
        best_score = 0
        
        for shape_name, criteria in self.EYE_SHAPE_CATEGORIES.items():
            score = 0
            
            # é•¿å®½æ¯”åŒ¹é…åº¦ (æƒé‡50%)
            if criteria['length_width_ratio'][0] <= ratio <= criteria['length_width_ratio'][1]:
                score += 50
            else:
                min_ratio, max_ratio = criteria['length_width_ratio']
                if ratio < min_ratio:
                    deviation = (min_ratio - ratio) / min_ratio
                else:
                    deviation = (ratio - max_ratio) / max_ratio
                score += max(0, 50 - deviation * 100)
            
            # å€¾æ–œè§’åº¦åŒ¹é…åº¦ (æƒé‡50%)
            if criteria['tilt_angle'][0] <= tilt <= criteria['tilt_angle'][1]:
                score += 50
            else:
                min_tilt, max_tilt = criteria['tilt_angle']
                if tilt < min_tilt:
                    deviation = abs(min_tilt - tilt) / 20
                else:
                    deviation = abs(tilt - max_tilt) / 20
                score += max(0, 50 - deviation * 100)
            
            if score > best_score:
                best_score = score
                best_match = shape_name
        
        confidence = best_score / 100.0
        
        return {
            'primary_type': best_match,
            'confidence': confidence
        }
    
    def generate_3d_recommendations(self, eye_shape, pose_info):
        """ç”Ÿæˆ3Dæ„ŸçŸ¥çš„è°ƒæ•´å»ºè®®"""
        shape_type = eye_shape['primary_type']
        config = self.EYE_SHAPE_CATEGORIES[shape_type]
        
        base_recommendations = {
            'recommended_adjustments': config['recommended_adjustments'],
            'contraindicated': config.get('contraindicated', []),
            'description': config['description']
        }
        
        # 3Då§¿æ€æ„ŸçŸ¥çš„å¼ºåº¦è°ƒæ•´
        if pose_info is not None:
            rotation_vector, _ = pose_info
            rotation_matrix, _ = cv2.Rodrigues(rotation_vector)
            sy = np.sqrt(rotation_matrix[0,0] * rotation_matrix[0,0] + rotation_matrix[1,0] * rotation_matrix[1,0])
            yaw = np.degrees(np.arctan2(-rotation_matrix[2,0], sy))
            
            # æ ¹æ®å§¿æ€è°ƒæ•´æ¨èå¼ºåº¦
            if abs(yaw) < 15:
                pose_type = 'frontal'
                pose_multiplier = config['pose_sensitivity']['frontal']
            else:
                pose_type = 'profile'
                pose_multiplier = config['pose_sensitivity']['profile']
            
            base_recommendations['pose_type'] = pose_type
            base_recommendations['pose_multiplier'] = pose_multiplier
            base_recommendations['yaw_angle'] = yaw
        
        return base_recommendations

class EyeCorner3DProcessor:
    """3Dæ„ŸçŸ¥çš„çœ¼è§’å¤„ç†å™¨"""
    
    def __init__(self):
        # MediaPipeè®¾ç½®
        self.mp_face_mesh = mp.solutions.face_mesh
        self.face_mesh = self.mp_face_mesh.FaceMesh(
            static_image_mode=True,
            max_num_faces=1,
            refine_landmarks=True,
            min_detection_confidence=0.8,
            min_tracking_confidence=0.8
        )
        
        # ç›¸æœºå‚æ•°
        self.camera_matrix = None
        self.dist_coeffs = None
        
        # åˆå§‹åŒ–çœ¼å½¢åˆ†æå™¨
        self.eye_analyzer = EyeShape3DAnalyzer()
        
        # 3Dé¢éƒ¨æ¨¡å‹ï¼ˆæ¯«ç±³å•ä½ï¼‰
        self.face_model_3d = np.array([
            [0.0, 0.0, 0.0],           # é¼»å°– (1)
            [0.0, -330.0, -65.0],      # ä¸‹å·´ (152)
            [-225.0, 170.0, -135.0],   # å·¦çœ¼å¤–è§’ (33)
            [225.0, 170.0, -135.0],    # å³çœ¼å¤–è§’ (263)
            [-150.0, -150.0, -125.0],  # å·¦å˜´è§’ (61)
            [150.0, -150.0, -125.0],   # å³å˜´è§’ (291)
        ], dtype=np.float32)
        
        self.pnp_indices = [1, 152, 33, 263, 61, 291]
        
        # 3Dæ„ŸçŸ¥çš„çœ¼è§’ç§»åŠ¨ç‚¹å®šä¹‰
        self.EYE_MOVEMENT_REGIONS = {
            'left_eye': {
                'outer_corner': [33],           # å·¦çœ¼å¤–çœ¦
                'inner_corner': [133],          # å·¦çœ¼å†…çœ¦
                'upper_lid': [157, 158, 159],   # ä¸Šçœ¼ç‘
                'lower_lid': [145, 153, 154],   # ä¸‹çœ¼ç‘
                'transition': [160, 161, 163]   # è¿‡æ¸¡åŒºåŸŸ
            },
            'right_eye': {
                'outer_corner': [263],          # å³çœ¼å¤–çœ¦
                'inner_corner': [362],          # å³çœ¼å†…çœ¦
                'upper_lid': [386, 387, 388],   # ä¸Šçœ¼ç‘
                'lower_lid': [374, 380, 384],   # ä¸‹çœ¼ç‘
                'transition': [385, 390, 466]   # è¿‡æ¸¡åŒºåŸŸ
            }
        }
        
        # è¿œç¨‹ç¨³å®šé”šç‚¹
        self.STABLE_ANCHORS = [
            1, 2, 5, 4, 6, 19, 20,      # é¼»å­åŒºåŸŸ
            9, 10, 151, 175,            # é¢å¤´å’Œä¸‹å·´
            61, 291, 39, 269, 270,      # å˜´å·´åŒºåŸŸ
            234, 93, 132, 454, 323, 361, # è„¸é¢Šè¾¹ç¼˜
            70, 296, 107, 276           # çœ‰æ¯›åŒºåŸŸ
        ]
        
        # å¯¹ç§°è¾…åŠ©ç‚¹
        self.SYMMETRY_HELPERS = [168, 6, 8, 9]
    
    def setup_camera(self, image_shape):
        """è®¾ç½®ç›¸æœºå‚æ•°"""
        h, w = image_shape[:2]
        focal_length = w
        center = (w/2, h/2)
        
        self.camera_matrix = np.array([
            [focal_length, 0, center[0]],
            [0, focal_length, center[1]],
            [0, 0, 1]
        ], dtype=np.float32)
        
        self.dist_coeffs = np.zeros((4,1), dtype=np.float32)
    
    def detect_landmarks_3d(self, image):
        """æ£€æµ‹é¢éƒ¨å…³é”®ç‚¹å¹¶è®¡ç®—3Då§¿æ€"""
        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        results = self.face_mesh.process(rgb_image)
        
        if not results.multi_face_landmarks:
            return None, None
        
        # è·å–2Då…³é”®ç‚¹
        landmarks_2d = []
        h, w = image.shape[:2]
        for landmark in results.multi_face_landmarks[0].landmark:
            x = int(landmark.x * w)
            y = int(landmark.y * h)
            landmarks_2d.append([x, y])
        
        landmarks_2d = np.array(landmarks_2d, dtype=np.float32)
        
        # è®¾ç½®ç›¸æœºå‚æ•°
        if self.camera_matrix is None:
            self.setup_camera(image.shape)
        
        # æå–ç”¨äºPnPçš„å…³é”®ç‚¹
        image_points = []
        for idx in self.pnp_indices:
            if idx < len(landmarks_2d):
                image_points.append(landmarks_2d[idx])
        
        if len(image_points) < 6:
            print("âš ï¸ PnPå…³é”®ç‚¹ä¸è¶³ï¼Œ3Då§¿æ€ä¼°è®¡å¤±è´¥")
            return landmarks_2d, None
        
        image_points = np.array(image_points, dtype=np.float32)
        
        # PnPæ±‚è§£3Då§¿æ€
        try:
            success, rotation_vector, translation_vector = cv2.solvePnP(
                self.face_model_3d, image_points, 
                self.camera_matrix, self.dist_coeffs,
                flags=cv2.SOLVEPNP_ITERATIVE
            )
            
            if success:
                return landmarks_2d, (rotation_vector, translation_vector)
            else:
                print("âš ï¸ PnPæ±‚è§£å¤±è´¥")
                return landmarks_2d, None
                
        except Exception as e:
            print(f"âš ï¸ PnPæ±‚è§£å¼‚å¸¸: {e}")
            return landmarks_2d, None
    
    def estimate_face_pose_3d(self, rotation_vector):
        """åŸºäº3Dæ—‹è½¬å‘é‡ä¼°è®¡é¢éƒ¨å§¿æ€"""
        if rotation_vector is None:
            return "frontal", 0.0, 0.0, 0.0
        
        rotation_matrix, _ = cv2.Rodrigues(rotation_vector)
        
        # è®¡ç®—æ¬§æ‹‰è§’
        sy = np.sqrt(rotation_matrix[0,0] * rotation_matrix[0,0] + rotation_matrix[1,0] * rotation_matrix[1,0])
        
        if sy > 1e-6:
            x = np.arctan2(rotation_matrix[2,1], rotation_matrix[2,2])
            y = np.arctan2(-rotation_matrix[2,0], sy)
            z = np.arctan2(rotation_matrix[1,0], rotation_matrix[0,0])
        else:
            x = np.arctan2(-rotation_matrix[1,2], rotation_matrix[1,1])
            y = np.arctan2(-rotation_matrix[2,0], sy)
            z = 0
        
        # è½¬æ¢ä¸ºåº¦æ•°
        pitch = np.degrees(x)
        yaw = np.degrees(y)
        roll = np.degrees(z)
        
        # åˆ¤æ–­ä¸»è¦å§¿æ€
        if abs(yaw) < 15 and abs(pitch) < 15:
            pose_type = "frontal"
        elif yaw > 15:
            pose_type = "right_profile"
        elif yaw < -15:
            pose_type = "left_profile"
        elif pitch > 15:
            pose_type = "looking_down"
        elif pitch < -15:
            pose_type = "looking_up"
        else:
            pose_type = "mixed"
        
        return pose_type, yaw, pitch, roll
    
    def calculate_3d_aware_eye_centers(self, landmarks_2d, pose_info, adjustment_type):
        """3Dæ„ŸçŸ¥çš„çœ¼çƒä¸­å¿ƒè®¡ç®—"""
        # åŸºç¡€å‡ ä½•ä¸­å¿ƒ
        basic_left_center = (landmarks_2d[33] + landmarks_2d[133]) / 2
        basic_right_center = (landmarks_2d[362] + landmarks_2d[263]) / 2
        
        if pose_info is None:
            return basic_left_center, basic_right_center
        
        rotation_vector, translation_vector = pose_info
        pose_type, yaw, pitch, roll = self.estimate_face_pose_3d(rotation_vector)
        
        # 3Dé€è§†æ ¡æ­£
        yaw_rad = np.radians(yaw)
        pitch_rad = np.radians(pitch)
        
        # é€è§†å˜å½¢æ ¡æ­£çŸ©é˜µ
        perspective_factor_x = np.cos(yaw_rad)
        perspective_factor_y = np.cos(pitch_rad)
        
        # æ ¹æ®è°ƒæ•´ç±»å‹å’Œ3Då§¿æ€è°ƒæ•´å‚è€ƒç‚¹
        if adjustment_type == "stretch":
            if abs(yaw) > 20:
                left_offset = np.array([2 / perspective_factor_x, 0])
                right_offset = np.array([2 / perspective_factor_x, 0])
            else:
                left_offset = np.array([0, 2])
                right_offset = np.array([0, 2])
                
        elif adjustment_type == "lift":
            if abs(pitch) > 20:
                vertical_correction = pitch * 0.1
                left_offset = np.array([0, vertical_correction])
                right_offset = np.array([0, vertical_correction])
            else:
                left_offset = np.array([0, 0])
                right_offset = np.array([0, 0])
                
        else:  # shapeæ¨¡å¼
            left_offset = np.array([1 / perspective_factor_x, 1 / perspective_factor_y])
            right_offset = np.array([1 / perspective_factor_x, 1 / perspective_factor_y])
        
        # åº”ç”¨3Dæ ¡æ­£
        left_center = basic_left_center + left_offset
        right_center = basic_right_center + right_offset
        
        print(f"ğŸ“ 3Dæ ¡æ­£çœ¼çƒä¸­å¿ƒ: å§¿æ€={pose_type}, yaw={yaw:.1f}Â°, pitch={pitch:.1f}Â°")
        
        return left_center, right_center
    
    def calculate_3d_adaptive_movements(self, landmarks_2d, eye_centers, pose_info, adjustment_type, intensity, eye_shape_info):
        """è®¡ç®—3Dè‡ªé€‚åº”çš„ç§»åŠ¨å‘é‡"""
        if pose_info is None:
            pose_type, yaw, pitch, roll = "frontal", 0.0, 0.0, 0.0
        else:
            rotation_vector, translation_vector = pose_info
            pose_type, yaw, pitch, roll = self.estimate_face_pose_3d(rotation_vector)
        
        left_center, right_center = eye_centers
        movements = {}
        
        # 3Då§¿æ€è‡ªé€‚åº”å¼ºåº¦
        pose_intensity_multiplier = self.get_pose_intensity_multiplier(pose_type, yaw, pitch, eye_shape_info)
        
        # å·¦å³çœ¼çš„ä¸å¯¹ç§°è°ƒæ•´ï¼ˆåŸºäºyawè§’ï¼‰
        if abs(yaw) > 10:
            if yaw > 0:  # å³è½¬ï¼Œå·¦çœ¼æ›´æ˜æ˜¾
                left_eye_multiplier = 1.0 + abs(yaw) * 0.01
                right_eye_multiplier = 1.0 - abs(yaw) * 0.008
            else:  # å·¦è½¬ï¼Œå³çœ¼æ›´æ˜æ˜¾
                left_eye_multiplier = 1.0 - abs(yaw) * 0.008
                right_eye_multiplier = 1.0 + abs(yaw) * 0.01
        else:
            left_eye_multiplier = right_eye_multiplier = 1.0
        
        print(f"ğŸ”§ 3Dè‡ªé€‚åº”å¼ºåº¦: åŸºç¡€={intensity:.2f} Ã— å§¿æ€={pose_intensity_multiplier:.2f}")
        
        # ä¸ºå·¦çœ¼è®¡ç®—3Dæ„ŸçŸ¥ç§»åŠ¨
        left_movements = self.calculate_single_eye_3d_movement(
            'left_eye', landmarks_2d, left_center, pose_info, adjustment_type,
            intensity * pose_intensity_multiplier * left_eye_multiplier, eye_shape_info
        )
        movements.update(left_movements)
        
        # ä¸ºå³çœ¼è®¡ç®—3Dæ„ŸçŸ¥ç§»åŠ¨
        right_movements = self.calculate_single_eye_3d_movement(
            'right_eye', landmarks_2d, right_center, pose_info, adjustment_type,
            intensity * pose_intensity_multiplier * right_eye_multiplier, eye_shape_info
        )
        movements.update(right_movements)
        
        return movements
    
    def get_pose_intensity_multiplier(self, pose_type, yaw, pitch, eye_shape_info):
        """æ ¹æ®3Då§¿æ€å’Œçœ¼å½¢è·å–å¼ºåº¦å€æ•°"""
        base_multiplier = 1.0
        
        if pose_type == "frontal":
            base_multiplier = 1.0
        elif pose_type in ["right_profile", "left_profile"]:
            base_multiplier = max(0.6, 1.0 - abs(yaw) * 0.008)
        elif pose_type in ["looking_up", "looking_down"]:
            base_multiplier = max(0.7, 1.0 - abs(pitch) * 0.006)
        else:
            base_multiplier = 0.8
        
        # åŸºäºçœ¼å½¢çš„å§¿æ€æ•æ„Ÿåº¦
        if eye_shape_info and 'recommendations' in eye_shape_info:
            recommendations = eye_shape_info['recommendations']
            if 'pose_multiplier' in recommendations:
                base_multiplier *= recommendations['pose_multiplier']
        
        return base_multiplier
    
    def calculate_single_eye_3d_movement(self, eye_side, landmarks_2d, eye_center, pose_info, adjustment_type, intensity, eye_shape_info):
        """è®¡ç®—å•çœ¼çš„3Dæ„ŸçŸ¥ç§»åŠ¨"""
        movements = {}
        regions = self.EYE_MOVEMENT_REGIONS[eye_side]
        
        # è·å–3Då§¿æ€ä¿¡æ¯
        if pose_info is None:
            pose_type, yaw, pitch, roll = "frontal", 0.0, 0.0, 0.0
        else:
            rotation_vector, translation_vector = pose_info
            pose_type, yaw, pitch, roll = self.estimate_face_pose_3d(rotation_vector)
        
        # ä¸ºæ¯ä¸ªåŒºåŸŸè®¡ç®—3Dæ„ŸçŸ¥ç§»åŠ¨
        for region_name, point_indices in regions.items():
            for point_idx in point_indices:
                if point_idx < len(landmarks_2d):
                    movement = self.calculate_3d_point_movement(
                        landmarks_2d[point_idx], eye_center, pose_type, yaw, pitch,
                        adjustment_type, intensity, region_name, eye_side, eye_shape_info
                    )
                    movements[point_idx] = movement
        
        return movements
    
    def calculate_3d_point_movement(self, point, eye_center, pose_type, yaw, pitch, adjustment_type, intensity, region_name, eye_side, eye_shape_info):
        """è®¡ç®—å•ä¸ªç‚¹çš„3Dæ„ŸçŸ¥ç§»åŠ¨"""
        # åŸºç¡€æ–¹å‘è®¡ç®—
        direction = point - eye_center
        direction_norm = np.linalg.norm(direction)
        
        if direction_norm <= 1e-6:
            return np.array([0.0, 0.0])
        
        direction = direction / direction_norm
        
        # åŒºåŸŸæƒé‡
        region_weights = {
            'outer_corner': 1.0,
            'inner_corner': 0.3,
            'upper_lid': 0.7,
            'lower_lid': 0.5,
            'transition': 0.4
        }
        
        base_weight = region_weights.get(region_name, 0.5)
        
        # 3Då§¿æ€æƒé‡è°ƒæ•´
        if pose_type != "frontal":
            if eye_side == 'left_eye' and yaw > 20:
                base_weight *= 0.8
            elif eye_side == 'right_eye' and yaw < -20:
                base_weight *= 0.8
        
        # æ ¹æ®è°ƒæ•´ç±»å‹è®¡ç®—ç§»åŠ¨å‘é‡
        if adjustment_type == "stretch":
            movement_vector = self.calculate_3d_stretch_vector(direction, pose_type, yaw, pitch, region_name)
            movement_scale = intensity * base_weight * 12
            
        elif adjustment_type == "lift":
            movement_vector = self.calculate_3d_lift_vector(direction, pose_type, yaw, pitch, region_name, eye_side)
            movement_scale = intensity * base_weight * 10
            
        else:  # shapeæ¨¡å¼
            stretch_vec = self.calculate_3d_stretch_vector(direction, pose_type, yaw, pitch, region_name)
            lift_vec = self.calculate_3d_lift_vector(direction, pose_type, yaw, pitch, region_name, eye_side)
            movement_vector = stretch_vec * 0.6 + lift_vec * 0.4
            movement_vector = movement_vector / np.linalg.norm(movement_vector)
            movement_scale = intensity * base_weight * 11
        
        return movement_vector * movement_scale
    
    def calculate_3d_stretch_vector(self, direction, pose_type, yaw, pitch, region_name):
        """è®¡ç®—3Dæ„ŸçŸ¥çš„æ‹‰é•¿å‘é‡"""
        if pose_type == "frontal":
            return direction
        else:
            # ä¾§è„¸æ—¶éœ€è¦é€è§†æ ¡æ­£
            yaw_rad = np.radians(yaw)
            perspective_correction = np.cos(yaw_rad)
            
            if region_name == 'outer_corner':
                # å¤–çœ¦ä¸»è¦æ²¿æ°´å¹³æ–¹å‘æ‹‰é•¿ï¼Œéœ€è¦é€è§†æ ¡æ­£
                corrected_direction = np.array([direction[0] / max(perspective_correction, 0.5), direction[1]])
                return corrected_direction / np.linalg.norm(corrected_direction)
            else:
                return direction * 0.8
    
    def calculate_3d_lift_vector(self, direction, pose_type, yaw, pitch, region_name, eye_side):
        """è®¡ç®—3Dæ„ŸçŸ¥çš„ä¸Šæ‰¬å‘é‡"""
        base_lift = np.array([0, -1])
        
        if pose_type == "frontal":
            if region_name == 'outer_corner':
                return direction * 0.4 + base_lift * 0.6
            else:
                return direction * 0.7 + base_lift * 0.3
        else:
            # 3Då§¿æ€æ—¶çš„ä¸Šæ‰¬æ ¡æ­£
            pitch_rad = np.radians(pitch)
            yaw_rad = np.radians(yaw)
            
            pitch_factor = 1.0 - pitch * 0.008
            
            if abs(yaw) > 20:
                rotated_lift = np.array([
                    base_lift[0] * np.cos(yaw_rad) - base_lift[1] * np.sin(yaw_rad),
                    base_lift[0] * np.sin(yaw_rad) + base_lift[1] * np.cos(yaw_rad)
                ]) * pitch_factor
            else:
                rotated_lift = base_lift * pitch_factor
            
            if region_name == 'outer_corner':
                return direction * 0.3 + rotated_lift * 0.7
            else:
                return direction * 0.8 + rotated_lift * 0.2
    
    def create_3d_aware_eye_mask(self, image_shape, landmarks_2d, pose_info):
        """åˆ›å»º3Dæ„ŸçŸ¥çš„çœ¼è§’mask"""
        h, w = image_shape[:2]
        mask = np.zeros((h, w), dtype=np.uint8)
        
        # æ”¶é›†æ‰€æœ‰çœ¼éƒ¨ç§»åŠ¨ç‚¹
        all_eye_points = []
        for eye_regions in self.EYE_MOVEMENT_REGIONS.values():
            for point_list in eye_regions.values():
                for idx in point_list:
                    if idx < len(landmarks_2d):
                        all_eye_points.append(landmarks_2d[idx])
        
        if len(all_eye_points) < 8:
            return mask
        
        all_eye_points = np.array(all_eye_points, dtype=np.int32)
        
        # 3Då§¿æ€è‡ªé€‚åº”æ‰©å±•
        if pose_info is None:
            expansion_factor = 1.5
        else:
            rotation_vector, _ = pose_info
            pose_type, yaw, pitch, roll = self.estimate_face_pose_3d(rotation_vector)
            
            if pose_type == "frontal":
                expansion_factor = 1.6
            else:
                expansion_factor = 1.3 - abs(yaw) * 0.005
                expansion_factor = max(expansion_factor, 1.1)
        
        # ä¸ºæ¯ä¸ªç‚¹åˆ›å»ºæ‰©å±•åœ†å½¢
        for point in all_eye_points:
            radius = int(10 * expansion_factor)
            cv2.circle(mask, tuple(point), radius, 255, -1)
        
        # å½¢æ€å­¦å¤„ç†
        kernel = np.ones((3,3), np.uint8)
        mask = cv2.dilate(mask, kernel, iterations=1)
        mask = cv2.erode(mask, kernel, iterations=1)
        
        return mask
    
    def apply_3d_eye_corner_transform(self, image, landmarks_2d, pose_info, adjustment_type="stretch", intensity=0.3, eye_shape_info=None):
        """åº”ç”¨3Dæ„ŸçŸ¥çš„çœ¼è§’å˜å½¢"""
        # 3Då§¿æ€åˆ†æ
        if pose_info is None:
            print("âš ï¸ 3Då§¿æ€ä¿¡æ¯æ— æ•ˆï¼Œä½¿ç”¨2Dæ¨¡å¼")
            pose_type, yaw, pitch, roll = "frontal", 0.0, 0.0, 0.0
        else:
            rotation_vector, translation_vector = pose_info
            pose_type, yaw, pitch, roll = self.estimate_face_pose_3d(rotation_vector)
            print(f"ğŸ” 3Då§¿æ€: {pose_type} (yaw={yaw:.1f}Â°, pitch={pitch:.1f}Â°, roll={roll:.1f}Â°)")
        
        # è®¡ç®—3Dæ„ŸçŸ¥çš„çœ¼çƒä¸­å¿ƒ
        eye_centers = self.calculate_3d_aware_eye_centers(landmarks_2d, pose_info, adjustment_type)
        
        # è®¡ç®—3Dè‡ªé€‚åº”ç§»åŠ¨å‘é‡
        movement_vectors = self.calculate_3d_adaptive_movements(
            landmarks_2d, eye_centers, pose_info, adjustment_type, intensity, eye_shape_info
        )
        
        # æ„å»ºæ§åˆ¶ç‚¹
        src_points = []
        dst_points = []
        used_indices = set()
        
        # æ·»åŠ ç§»åŠ¨ç‚¹
        movement_count = 0
        for point_idx, movement in movement_vectors.items():
            if point_idx < len(landmarks_2d):
                src_points.append(landmarks_2d[point_idx])
                dst_points.append(landmarks_2d[point_idx] + movement)
                used_indices.add(point_idx)
                movement_count += 1
        
        # æ·»åŠ ç¨³å®šé”šç‚¹
        anchor_count = 0
        for idx in self.STABLE_ANCHORS:
            if idx < len(landmarks_2d) and idx not in used_indices:
                src_points.append(landmarks_2d[idx])
                dst_points.append(landmarks_2d[idx])
                used_indices.add(idx)
                anchor_count += 1
        
        # æ·»åŠ å¯¹ç§°è¾…åŠ©ç‚¹
        symmetry_count = 0
        for idx in self.SYMMETRY_HELPERS:
            if idx < len(landmarks_2d) and idx not in used_indices:
                src_points.append(landmarks_2d[idx])
                dst_points.append(landmarks_2d[idx])
                used_indices.add(idx)
                symmetry_count += 1
        
        # æ·»åŠ è¾¹ç•Œé”šç‚¹
        h, w = image.shape[:2]
        boundary_points = [
            [30, 30], [w//2, 30], [w-30, 30],
            [30, h//2], [w-30, h//2],
            [30, h-30], [w//2, h-30], [w-30, h-30]
        ]
        
        for bp in boundary_points:
            src_points.append(bp)
            dst_points.append(bp)
        
        print(f"ğŸ”§ 3Dæ§åˆ¶ç‚¹: ç§»åŠ¨={movement_count}, é”šç‚¹={anchor_count}, å¯¹ç§°={symmetry_count}, è¾¹ç•Œ=8")
        
        # éªŒè¯æ§åˆ¶ç‚¹æ•°é‡
        if len(src_points) < 15:
            print("âŒ æ§åˆ¶ç‚¹æ•°é‡ä¸è¶³")
            return image
        
        # æ‰§è¡ŒTPSå˜å½¢
        try:
            src_points = np.array(src_points, dtype=np.float32)
            dst_points = np.array(dst_points, dtype=np.float32)
            
            tps = cv2.createThinPlateSplineShapeTransformer()
            matches = [cv2.DMatch(i, i, 0) for i in range(len(src_points))]
            
            print(f"ğŸ”„ å¼€å§‹3Dæ„ŸçŸ¥TPSå˜æ¢ï¼ˆ{adjustment_type}æ¨¡å¼ï¼Œå§¿æ€ï¼š{pose_type}ï¼‰...")
            tps.estimateTransformation(
                dst_points.reshape(1, -1, 2), 
                src_points.reshape(1, -1, 2), 
                matches
            )
            
            # TPSå˜å½¢
            transformed = tps.warpImage(image)
            
            if transformed is None:
                print("âŒ TPSå˜æ¢å¤±è´¥")
                return image
            
            # åˆ›å»º3Dæ„ŸçŸ¥mask
            eye_mask = self.create_3d_aware_eye_mask(image.shape, landmarks_2d, pose_info)
            
            # å®‰å…¨èåˆ
            mask_3d = cv2.merge([eye_mask, eye_mask, eye_mask]).astype(np.float32) / 255.0
            mask_blurred = cv2.GaussianBlur(mask_3d, (5, 5), 0)
            
            result = image.astype(np.float32) * (1 - mask_blurred) + transformed.astype(np.float32) * mask_blurred
            result = np.clip(result, 0, 255).astype(np.uint8)
            
            print("âœ… 3Dæ„ŸçŸ¥çœ¼è§’å˜å½¢æˆåŠŸ")
            return result
            
        except Exception as e:
            print(f"âŒ TPSå˜å½¢å¼‚å¸¸: {e}")
            return image
    
    def debug_3d_eye_detection(self, image, save_dir=None):
        """3Dæ„ŸçŸ¥çš„çœ¼è§’è°ƒè¯•"""
        landmarks_2d, pose_info = self.detect_landmarks_3d(image)
        if landmarks_2d is None:
            print("âŒ æœªæ£€æµ‹åˆ°é¢éƒ¨å…³é”®ç‚¹")
            return image
        
        # 3Dçœ¼å½¢åˆ†æ
        eye_shape_info = self.eye_analyzer.analyze_eye_shape_3d(landmarks_2d, pose_info)
        
        debug_img = image.copy()
        
        # ç»˜åˆ¶3Då§¿æ€ä¿¡æ¯
        if pose_info is not None:
            rotation_vector, translation_vector = pose_info
            pose_type, yaw, pitch, roll = self.estimate_face_pose_3d(rotation_vector)
            
            # æ˜¾ç¤º3Då§¿æ€
            cv2.putText(debug_img, f"3D Pose: {pose_type}", (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
            cv2.putText(debug_img, f"Yaw: {yaw:.1f}Â° Pitch: {pitch:.1f}Â° Roll: {roll:.1f}Â°", (10, 60), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
            
            # ç»˜åˆ¶3Dåæ ‡è½´
            try:
                axis_3d = np.array([
                    [0, 0, 0], [40, 0, 0], [0, 40, 0], [0, 0, -40]
                ], dtype=np.float32)
                
                projected_axis, _ = cv2.projectPoints(
                    axis_3d, rotation_vector, translation_vector,
                    self.camera_matrix, self.dist_coeffs
                )
                projected_axis = projected_axis.reshape(-1, 2).astype(int)
                
                origin = tuple(projected_axis[0])
                cv2.arrowedLine(debug_img, origin, tuple(projected_axis[1]), (0, 0, 255), 3)  # X-çº¢
                cv2.arrowedLine(debug_img, origin, tuple(projected_axis[2]), (0, 255, 0), 3)  # Y-ç»¿
                cv2.arrowedLine(debug_img, origin, tuple(projected_axis[3]), (255, 0, 0), 3)  # Z-è“
            except:
                pass
        
        # ç»˜åˆ¶çœ¼éƒ¨ç§»åŠ¨åŒºåŸŸ
        region_colors = {
            'outer_corner': (0, 255, 0),    # ç»¿è‰²
            'inner_corner': (255, 0, 0),    # çº¢è‰²
            'upper_lid': (0, 0, 255),       # è“è‰²
            'lower_lid': (255, 255, 0),     # é»„è‰²
            'transition': (255, 0, 255)     # ç´«è‰²
        }
        
        for eye_side, regions in self.EYE_MOVEMENT_REGIONS.items():
            for region_name, point_indices in regions.items():
                color = region_colors[region_name]
                for i, idx in enumerate(point_indices):
                    if idx < len(landmarks_2d):
                        point = landmarks_2d[idx].astype(int)
                        cv2.circle(debug_img, tuple(point), 6, color, -1)
                        cv2.putText(debug_img, f"{eye_side[0].upper()}{region_name[0].upper()}{i}", 
                                   tuple(point + 8), cv2.FONT_HERSHEY_SIMPLEX, 0.3, color, 1)
        
        # ç»˜åˆ¶3Dæ„ŸçŸ¥çš„çœ¼çƒä¸­å¿ƒ
        left_center, right_center = self.calculate_3d_aware_eye_centers(landmarks_2d, pose_info, "stretch")
        cv2.circle(debug_img, tuple(left_center.astype(int)), 8, (255, 255, 0), -1)
        cv2.circle(debug_img, tuple(right_center.astype(int)), 8, (255, 255, 0), -1)
        cv2.putText(debug_img, '3D-L', tuple(left_center.astype(int) + 10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)
        cv2.putText(debug_img, '3D-R', tuple(right_center.astype(int) + 10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)
        
        # æ˜¾ç¤º3Dçœ¼å½¢åˆ†æç»“æœ
        shape_info = eye_shape_info['eye_shape']
        measurements = eye_shape_info['measurements']
        
        info_y = 90
        cv2.putText(debug_img, f"3D Eye: {shape_info['primary_type']} ({shape_info['confidence']:.2f})", 
                   (10, info_y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        
        if 'pose_corrected' in measurements:
            cv2.putText(debug_img, f"3D L/W: {measurements['length_width_ratio']:.2f}", 
                       (10, info_y + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        
        # æ˜¾ç¤º3Dæ„ŸçŸ¥mask
        eye_mask = self.create_3d_aware_eye_mask(image.shape, landmarks_2d, pose_info)
        mask_overlay = debug_img.copy()
        mask_overlay[eye_mask > 0] = [255, 0, 255]
        debug_img = cv2.addWeighted(debug_img, 0.7, mask_overlay, 0.3, 0)
        
        if save_dir:
            os.makedirs(save_dir, exist_ok=True)
            cv2.imwrite(os.path.join(save_dir, "debug_3d_eye_corner.png"), debug_img)
            print(f"ğŸ“ 3Dè°ƒè¯•æ–‡ä»¶ä¿å­˜åˆ°: {save_dir}")
        
        return debug_img
    
    def process_image_3d(self, image, adjustment_type="stretch", intensity=0.3, save_debug=False, output_path=None):
        """3Dæ„ŸçŸ¥çš„å›¾åƒå¤„ç†ä¸»æ¥å£"""
        landmarks_2d, pose_info = self.detect_landmarks_3d(image)
        if landmarks_2d is None:
            print("âŒ æœªæ£€æµ‹åˆ°é¢éƒ¨å…³é”®ç‚¹")
            return image
        
        print(f"âœ… æ£€æµ‹åˆ° {len(landmarks_2d)} ä¸ªå…³é”®ç‚¹")
        
        # 3Dçœ¼å½¢åˆ†æ
        print("ğŸ” æ­£åœ¨è¿›è¡Œ3Dæ„ŸçŸ¥çœ¼å½¢åˆ†æ...")
        eye_shape_info = self.eye_analyzer.analyze_eye_shape_3d(landmarks_2d, pose_info)
        
        shape_result = eye_shape_info['eye_shape']
        measurements = eye_shape_info['measurements']
        
        print(f"ğŸ‘ï¸ 3Dçœ¼å½¢è¯†åˆ«ç»“æœ:")
        print(f"   ç±»å‹: {shape_result['primary_type']} (ç½®ä¿¡åº¦: {shape_result['confidence']:.2f})")
        if 'pose_corrected' in measurements:
            print(f"   3Dæ ¡æ­£é•¿å®½æ¯”: {measurements['length_width_ratio']:.2f}")
            print(f"   å¤´éƒ¨yawè§’: {measurements['yaw_angle']:.1f}Â°")
        
        # 3Dæ„ŸçŸ¥çš„æ¨è
        recommendations = eye_shape_info['recommendations']
        if 'pose_type' in recommendations:
            print(f"   3Då§¿æ€ç±»å‹: {recommendations['pose_type']}")
            print(f"   å§¿æ€å¼ºåº¦å€æ•°: {recommendations['pose_multiplier']:.2f}")
        
        # è°ƒè¯•æ¨¡å¼
        if save_debug and output_path:
            debug_dir = os.path.splitext(output_path)[0] + "_3d_debug"
            self.debug_3d_eye_detection(image, debug_dir)
        
        # åº”ç”¨3Dæ„ŸçŸ¥çš„çœ¼è§’å˜å½¢
        result = self.apply_3d_eye_corner_transform(
            image, landmarks_2d, pose_info, adjustment_type, intensity, eye_shape_info
        )
        
        return result

def main():
    parser = argparse.ArgumentParser(description='3Då§¿æ€æ„ŸçŸ¥çš„çœ¼è§’è°ƒæ•´å·¥å…·')
    parser.add_argument('--input', '-i', required=True, help='è¾“å…¥å›¾ç‰‡è·¯å¾„')
    parser.add_argument('--output', '-o', required=True, help='è¾“å‡ºå›¾ç‰‡è·¯å¾„')
    parser.add_argument('--type', '-t', choices=['stretch', 'lift', 'shape'], 
                       default='stretch', help='è°ƒæ•´ç±»å‹: stretch=æ°´å¹³æ‹‰é•¿, lift=çœ¼è§’ä¸Šæ‰¬, shape=ç»¼åˆè°ƒæ•´')
    parser.add_argument('--intensity', type=float, default=0.3, 
                       help='è°ƒæ•´å¼ºåº¦ (0.1-0.4)')
    parser.add_argument('--debug', action='store_true', help='3Dè°ƒè¯•æ¨¡å¼')
    parser.add_argument('--save-debug', action='store_true', help='ä¿å­˜3Dè°ƒè¯•æ–‡ä»¶')
    parser.add_argument('--comparison', action='store_true', help='ç”Ÿæˆå¯¹æ¯”å›¾')
    
    args = parser.parse_args()
    
    # åŠ è½½å›¾ç‰‡
    image = cv2.imread(args.input)
    if image is None:
        print(f"âŒ æ— æ³•åŠ è½½å›¾ç‰‡: {args.input}")
        return
    
    print(f"ğŸ“¸ å›¾ç‰‡å°ºå¯¸: {image.shape}")
    
    # å¼ºåº¦å®‰å…¨æ£€æŸ¥
    if args.intensity > 0.4:
        print(f"âš ï¸  å¼ºåº¦ {args.intensity} è¶…å‡ºå»ºè®®èŒƒå›´ï¼Œé™åˆ¶åˆ°0.4")
        args.intensity = 0.4
    elif args.intensity < 0.1:
        print(f"âš ï¸  å¼ºåº¦ {args.intensity} è¿‡å°ï¼Œæå‡åˆ°0.1")
        args.intensity = 0.1
    
    # åˆ›å»º3Dæ„ŸçŸ¥å¤„ç†å™¨
    processor = EyeCorner3DProcessor()
    
    # è°ƒè¯•æ¨¡å¼
    if args.debug:
        debug_result = processor.debug_3d_eye_detection(image)
        cv2.imwrite(args.output, debug_result)
        print(f"ğŸ” 3Dè°ƒè¯•å›¾ä¿å­˜åˆ°: {args.output}")
        return
    
    # å¤„ç†å›¾ç‰‡
    print(f"ğŸ”„ å¼€å§‹3Dæ„ŸçŸ¥çœ¼è§’å¤„ç†...")
    print(f"   è°ƒæ•´ç±»å‹: {args.type}")
    print(f"   è°ƒæ•´å¼ºåº¦: {args.intensity}")
    
    result = processor.process_image_3d(
        image, args.type, args.intensity, args.save_debug, args.output
    )
    
    # ä¿å­˜ç»“æœ
    cv2.imwrite(args.output, result)
    print(f"âœ… å¤„ç†å®Œæˆï¼Œä¿å­˜åˆ°: {args.output}")
    
    # æ£€æŸ¥å˜åŒ–ç»Ÿè®¡
    diff = cv2.absdiff(image, result)
    total_diff = np.sum(diff)
    max_diff = np.max(diff)
    changed_pixels = np.sum(diff > 0)
    
    print(f"ğŸ“Š åƒç´ å˜åŒ–ç»Ÿè®¡:")
    print(f"   æ€»å·®å¼‚: {total_diff}")
    print(f"   æœ€å¤§å·®å¼‚: {max_diff}")
    print(f"   å˜åŒ–åƒç´ æ•°: {changed_pixels}")
    
    if total_diff < 1000:
        print("âš ï¸  å˜åŒ–å¾ˆå°ï¼Œå¯èƒ½éœ€è¦ï¼š")
        print("   1. æé«˜ --intensity å‚æ•°")
        print("   2. æ£€æŸ¥3Då§¿æ€æ˜¯å¦å½±å“æ•ˆæœ (--debug)")
        print("   3. å°è¯•ä¸åŒçš„è°ƒæ•´ç±»å‹")
    
    # ç”Ÿæˆå¯¹æ¯”å›¾
    if args.comparison:
        comparison_path = args.output.replace('.', '_3d_comparison.')
        comparison = np.hstack([image, result])
        cv2.line(comparison, (image.shape[1], 0), (image.shape[1], image.shape[0]), (0, 255, 0), 3)
        
        cv2.putText(comparison, 'Original', (20, 50), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3)
        cv2.putText(comparison, f'3D-{args.type.upper()} {args.intensity:.2f}', 
                   (image.shape[1] + 20, 50), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)
        
        cv2.imwrite(comparison_path, comparison)
        print(f"ğŸ“Š 3Då¯¹æ¯”å›¾ä¿å­˜åˆ°: {comparison_path}")
    
    print("\nğŸŒŸ 3Då§¿æ€æ„ŸçŸ¥çœ¼è§’è°ƒæ•´ç‰¹è‰²:")
    print("âœ… çœŸå®3Då¤´éƒ¨å§¿æ€ä¼°è®¡: åŸºäºPnPç®—æ³•å’Œæ ‡å‡†3Dé¢éƒ¨æ¨¡å‹")
    print("âœ… é€è§†æ ¡æ­£çš„çœ¼å½¢åˆ†æ: è‡ªåŠ¨æ ¡æ­£ä¾§è„¸æ—¶çš„æµ‹é‡è¯¯å·®")
    print("âœ… å§¿æ€è‡ªé€‚åº”çš„ç§»åŠ¨ç­–ç•¥: æ­£é¢/ä¾§è„¸/ä¿¯ä»°ä¸åŒçš„å˜å½¢æ–¹å¼")
    print("âœ… 3Dæ„ŸçŸ¥çš„å¼ºåº¦è°ƒæ•´: æ ¹æ®å¤´éƒ¨è§’åº¦è‡ªåŠ¨è°ƒæ•´å˜å½¢å¼ºåº¦")
    print("âœ… æ™ºèƒ½çš„å·¦å³çœ¼ä¸å¯¹ç§°å¤„ç†: ä¾§è„¸æ—¶çªå‡ºå¯è§çœ¼éƒ¨çš„è°ƒæ•´")
    print("âœ… 3Dè¾¹ç•Œä¿æŠ¤: åŸºäºçœŸå®å§¿æ€çš„maskè¾¹ç•Œè®¡ç®—")
    
    print("\nğŸ“– ä½¿ç”¨ç¤ºä¾‹:")
    print("â€¢ 3Dæ™ºèƒ½çœ¼è§’è°ƒæ•´: python script.py -i input.jpg -o output.png --comparison")
    print("â€¢ 3Då§¿æ€è°ƒè¯•: python script.py -i input.jpg -o debug.png --debug")
    print("â€¢ ä¾§è„¸çœ¼è§’æ‹‰é•¿: python script.py -i profile.jpg -o output.png -t stretch --intensity 0.25")
    print("â€¢ ä¿¯è§†çœ¼è§’ä¸Šæ‰¬: python script.py -i looking_down.jpg -o output.png -t lift --intensity 0.3")

if __name__ == "__main__":
    main()
