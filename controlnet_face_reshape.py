#!/usr/bin/env python3
"""
ControlNet äººè„¸ç¾å½¢è„šæœ¬ - åŸºäºæ ‡å‡†è„¸å‹åˆ†ç±»çš„æ™ºèƒ½æç¤ºè¯ç³»ç»Ÿ
"""

import cv2
import numpy as np
import mediapipe as mp
import torch
from diffusers import StableDiffusionControlNetImg2ImgPipeline, ControlNetModel, UniPCMultistepScheduler
from PIL import Image
import argparse
import os

class ControlNetFaceReshaper:
    def __init__(self, model_path="./models/controlnet_mediapipe_face", sd_model_path="./models/stable-diffusion"):
        # è®¾å¤‡
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        # MediaPipe
        self.mp_face_mesh = mp.solutions.face_mesh
        self.face_mesh = self.mp_face_mesh.FaceMesh(
            static_image_mode=True,
            max_num_faces=1,
            refine_landmarks=True,
            min_detection_confidence=0.7
        )
        
        # é¢éƒ¨å…³é”®ç‚¹
        self.face_regions = {
            'face_contour': [10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136, 172, 58, 132, 93, 234, 127, 162, 21, 54, 103, 67, 109],
            'left_eye': [33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246],
            'right_eye': [362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398],
            'nose': [1, 2, 5, 4, 6, 19, 20, 94, 125, 141, 235, 236, 3, 51, 48, 115, 131, 134, 102, 49, 220, 305, 292, 284],
            'mouth': [61, 84, 17, 314, 405, 320, 307, 375, 321, 308, 324, 318, 78, 95, 88, 178, 87, 14, 317, 402, 318, 324],
            'left_cheek': [116, 117, 118, 119, 120, 121, 234],
            'right_cheek': [345, 346, 347, 348, 349, 350, 454]
        }
        
        # é»„é‡‘æ¯”ä¾‹æ ‡å‡†
        self.golden_ratios = {
            'face_width_height': 0.75,
            'eye_distance_face_width': 0.46,
            'nose_width_mouth_width': 0.67,
            'lower_face_total_face': 0.55
        }
        
        # åŠ è½½æ¨¡å‹
        self.load_models(model_path, sd_model_path)
        
        # åˆå§‹åŒ–CodeFormer
        self.load_codeformer()
    
    def load_codeformer(self):
        """åŠ è½½CodeFormeræ¨¡å‹"""
        try:
            import onnxruntime as ort
            
            codeformer_path = "./models/CodeFormer/codeformer.onnx"
            
            if not os.path.exists(codeformer_path):
                print(f"âš ï¸ CodeFormeræ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {codeformer_path}")
                self.codeformer_session = None
                return
            
            print("ğŸ“¥ åŠ è½½ CodeFormer æ¨¡å‹...")
            self.codeformer_session = ort.InferenceSession(
                codeformer_path,
                providers=['CUDAExecutionProvider', 'CPUExecutionProvider']
            )
            print("âœ… CodeFormer åŠ è½½å®Œæˆ")
            
        except ImportError:
            print("âš ï¸ onnxruntime æœªå®‰è£…ï¼ŒCodeFormeråŠŸèƒ½ä¸å¯ç”¨")
            self.codeformer_session = None
        except Exception as e:
            print(f"âš ï¸ CodeFormer åŠ è½½å¤±è´¥: {e}")
            self.codeformer_session = None
    
    def load_models(self, model_path, sd_model_path):
        """åŠ è½½ControlNetå’ŒStable Diffusionæ¨¡å‹"""
        try:
            print("ğŸ“¥ åŠ è½½ ControlNet æ¨¡å‹...")
            self.controlnet = ControlNetModel.from_pretrained(
                model_path,
                torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
                local_files_only=True
            )
            print("âœ… ControlNet åŠ è½½å®Œæˆ")
            
            print("ğŸ“¥ åŠ è½½ Stable Diffusion Pipeline...")
            self.pipe = StableDiffusionControlNetImg2ImgPipeline.from_single_file(
                os.path.join(sd_model_path, 'v2-1_768-ema-pruned.safetensors'),
                controlnet=self.controlnet,
                torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
                safety_checker=None,
                requires_safety_checker=False,
                local_files_only=True,
            )
            print("âœ… Pipeline åŠ è½½å®Œæˆ")
            
            print("âš™ï¸ é…ç½®è°ƒåº¦å™¨...")
            self.pipe.scheduler = UniPCMultistepScheduler.from_config(self.pipe.scheduler.config)
            
            print(f"ğŸ“± ç§»åŠ¨åˆ° {self.device}...")
            self.pipe = self.pipe.to(self.device)
            
            # GPUå†…å­˜ä¼˜åŒ–
            if self.device == "cuda":
                print("ğŸš€ å¯ç”¨GPUä¼˜åŒ–...")
                try:
                    self.pipe.enable_xformers_memory_efficient_attention()
                    self.pipe.enable_model_cpu_offload()
                    print("âœ… GPUä¼˜åŒ–å®Œæˆ")
                except Exception as e:
                    print(f"âš ï¸ ä¼˜åŒ–è®¾ç½®å¤±è´¥: {e}")
            
            print("ğŸ‰ æ¨¡å‹åˆå§‹åŒ–å®Œæˆ!")
                
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.pipe = None
            self.controlnet = None
    
    def extract_landmarks(self, image):
        """æå–å…³é”®ç‚¹ - è¾“å…¥å¿…é¡»æ˜¯numpyæ•°ç»„(BGRæ ¼å¼)"""
        try:
            rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            results = self.face_mesh.process(rgb_image)
            
            if not results.multi_face_landmarks:
                return None
            
            landmarks = []
            h, w = image.shape[:2]
            for landmark in results.multi_face_landmarks[0].landmark:
                x = int(landmark.x * w)
                y = int(landmark.y * h)
                landmarks.append([x, y])
            
            return np.array(landmarks)
            
        except Exception as e:
            print(f"âš ï¸ å…³é”®ç‚¹æå–å¤±è´¥: {e}")
            return None
    
    def calculate_face_ratios(self, landmarks):
        """è®¡ç®—å½“å‰é¢éƒ¨æ¯”ä¾‹"""
        try:
            # è„¸å®½é«˜æ¯”
            face_left = np.min(landmarks[:, 0])
            face_right = np.max(landmarks[:, 0])
            face_top = np.min(landmarks[:, 1])
            face_bottom = np.max(landmarks[:, 1])
            
            face_width = face_right - face_left
            face_height = face_bottom - face_top
            face_width_height = face_width / face_height if face_height > 0 else 0.75
            
            # åŒçœ¼é—´è·/è„¸å®½
            left_eye_center = np.mean(landmarks[self.face_regions['left_eye']], axis=0)
            right_eye_center = np.mean(landmarks[self.face_regions['right_eye']], axis=0)
            eye_distance = np.linalg.norm(right_eye_center - left_eye_center)
            eye_distance_face_width = eye_distance / face_width if face_width > 0 else 0.46
            
            # é¼»å®½/å˜´å®½
            nose_width = abs(landmarks[234][0] - landmarks[454][0]) * 0.3
            mouth_width = abs(landmarks[61][0] - landmarks[291][0]) if 291 < len(landmarks) else nose_width / 0.67
            nose_width_mouth_width = nose_width / mouth_width if mouth_width > 0 else 0.67
            
            # ä¸‹åŠè„¸/å…¨è„¸
            nose_tip_y = landmarks[1][1]
            lower_face_total_face = (face_bottom - nose_tip_y) / face_height if face_height > 0 else 0.55
            
            return {
                'face_width_height': face_width_height,
                'eye_distance_face_width': eye_distance_face_width,
                'nose_width_mouth_width': nose_width_mouth_width,
                'lower_face_total_face': lower_face_total_face
            }
        
        except Exception as e:
            print(f"âš ï¸ æ¯”ä¾‹è®¡ç®—å¤±è´¥: {e}")
            return self.golden_ratios
    
    def apply_golden_ratio_constraints(self, landmarks, params):
        """åº”ç”¨é»„é‡‘æ¯”ä¾‹çº¦æŸ"""
        current_ratios = self.calculate_face_ratios(landmarks)
        constrained_params = {}
        
        for param_name, value in params.items():
            if param_name == 'face_slim' and value > 0:
                current_width_height = current_ratios['face_width_height']
                reduction_factor = 1 - (value * 0.1)
                predicted_ratio = current_width_height * reduction_factor
                min_allowed_ratio = self.golden_ratios['face_width_height'] * 0.85
                
                if predicted_ratio < min_allowed_ratio:
                    max_reduction = 1 - (min_allowed_ratio / current_width_height)
                    max_allowed_slim = max_reduction / 0.1
                    constrained_params[param_name] = min(value, max(0, max_allowed_slim))
                    print(f"âš ï¸ ç˜¦è„¸å¼ºåº¦å—é»„é‡‘æ¯”ä¾‹çº¦æŸï¼Œä»{value:.2f}è°ƒæ•´ä¸º{constrained_params[param_name]:.2f}")
                else:
                    constrained_params[param_name] = value
            else:
                constrained_params[param_name] = value
        
        return constrained_params
    
    def apply_face_slim_adjustment(self, landmarks, intensity=0.3):
        """ç˜¦è„¸è°ƒæ•´"""
        adjusted_landmarks = landmarks.copy()
        face_center_x = landmarks[1][0]
        face_width = np.max(landmarks[:, 0]) - np.min(landmarks[:, 0])
        max_shrink = min(face_width * 0.08, 12)
        
        key_points = [234, 454, 172, 397]
        
        for idx in key_points:
            if idx >= len(landmarks):
                continue
            
            point = landmarks[idx]
            dist_to_center = abs(point[0] - face_center_x)
            
            if dist_to_center > 15:
                direction = 1 if point[0] > face_center_x else -1
                distance_factor = min(dist_to_center / (face_width * 0.3), 1.0)
                shrink_amount = intensity * max_shrink * distance_factor * 0.6
                new_x = point[0] - direction * shrink_amount
                adjusted_landmarks[idx][0] = int(max(0, min(new_x, landmarks.shape[0] - 1)))
        
        return adjusted_landmarks
    
    def apply_eye_enlargement(self, landmarks, intensity=0.2):
        """çœ¼éƒ¨æ”¾å¤§"""
        adjusted_landmarks = landmarks.copy()
        
        for eye_region in ['left_eye', 'right_eye']:
            eye_indices = self.face_regions[eye_region]
            eye_points = landmarks[eye_indices]
            eye_center = np.mean(eye_points, axis=0)
            
            for idx in eye_indices:
                if idx >= len(landmarks):
                    continue
                point = landmarks[idx]
                direction = point - eye_center
                
                if abs(direction[0]) > abs(direction[1]):
                    scale_factor = 1 + intensity * 0.5
                else:
                    scale_factor = 1 + intensity * 0.3
                
                enlarged_point = eye_center + direction * scale_factor
                adjusted_landmarks[idx] = enlarged_point.astype(int)
        
        return adjusted_landmarks
    
    def apply_nose_adjustment(self, landmarks, intensity=0.3):
        """é¼»éƒ¨è°ƒæ•´"""
        adjusted_landmarks = landmarks.copy()
        nose_bridge_indices = [6, 19, 20, 94, 125, 141, 235, 236]
        
        for idx in nose_bridge_indices:
            if idx >= len(landmarks):
                continue
            
            point = landmarks[idx]
            nose_center_x = landmarks[1][0]
            distance_from_center = abs(point[0] - nose_center_x)
            lift_factor = max(0, 1 - distance_from_center / 8)
            lift_amount = intensity * 3 * lift_factor
            adjusted_landmarks[idx][1] -= int(lift_amount)
        
        return adjusted_landmarks
    
    def apply_mouth_adjustment(self, landmarks, intensity=0.2):
        """å˜´éƒ¨è°ƒæ•´"""
        adjusted_landmarks = landmarks.copy()
        mouth_indices = self.face_regions['mouth']
        mouth_points = landmarks[mouth_indices]
        mouth_center = np.mean(mouth_points, axis=0)
        
        for idx in mouth_indices:
            if idx >= len(landmarks):
                continue
            point = landmarks[idx]
            direction = point - mouth_center
            adjusted_point = mouth_center + direction * (1 + intensity * 0.3)
            adjusted_landmarks[idx] = adjusted_point.astype(int)
        
        return adjusted_landmarks
    
    def create_landmark_image(self, landmarks, height, width):
        """åˆ›å»ºå…³é”®ç‚¹å›¾åƒ"""
        landmark_image = np.zeros((height, width, 3), dtype=np.uint8)
        
        # ç»˜åˆ¶é¢éƒ¨è½®å»“
        contour_indices = self.face_regions['face_contour']
        contour_points = landmarks[contour_indices]
        cv2.polylines(landmark_image, [contour_points], True, (255, 255, 255), 2)
        
        # ç»˜åˆ¶çœ¼éƒ¨è½®å»“
        for eye_region in ['left_eye', 'right_eye']:
            eye_indices = self.face_regions[eye_region]
            eye_points = landmarks[eye_indices]
            cv2.polylines(landmark_image, [eye_points], True, (192, 192, 192), 1)
        
        # ç»˜åˆ¶é¼»éƒ¨å’Œå˜´éƒ¨è½®å»“
        for region in ['nose', 'mouth']:
            region_indices = self.face_regions[region]
            region_points = landmarks[region_indices]
            hull = cv2.convexHull(region_points)
            cv2.polylines(landmark_image, [hull], True, (128, 128, 128), 1)
        
        # ç»˜åˆ¶å…³é”®ç‚¹
        for point in landmarks:
            cv2.circle(landmark_image, tuple(point), 1, (64, 64, 64), -1)
        
        return landmark_image
    
    def generate_advanced_prompt(self, params):
        """åŸºäºæ ‡å‡†è„¸å‹åˆ†ç±»çš„é«˜çº§æç¤ºè¯ç³»ç»Ÿ"""
        
        # åŸºç¡€è´¨é‡æç¤ºè¯
        base_quality = [
            "professional photography",
            "high resolution",
            "sharp focus",
            "natural lighting",
            "photorealistic",
            "detailed skin texture",
            "film grain"
        ]
        
        # æ ¹æ®è°ƒæ•´å‚æ•°ç”Ÿæˆå…·ä½“çš„è„¸å‹æè¿°
        facial_features = []
        
        # æ ‡å‡†è„¸å‹åˆ†ç±»
        if params.get('face_slim', 0) > 0:
            intensity = params['face_slim']
            if intensity >= 0.7:
                facial_features.append("pointed chin face")
            elif intensity >= 0.5:
                facial_features.append("oval face shape")
            elif intensity >= 0.3:
                facial_features.append("oblong face shape")
            elif intensity >= 0.1:
                facial_features.append("square face shape")
            else:
                facial_features.append("round face shape")
        
        # æ ‡å‡†çœ¼å‹åˆ†ç±»
        if params.get('eye_enlarge', 0) > 0:
            intensity = params['eye_enlarge']
            if intensity >= 0.4:
                facial_features.append("wide-set eyes")
            elif intensity >= 0.3:
                facial_features.append("almond eyes")
            elif intensity >= 0.2:
                facial_features.append("round eyes")
            elif intensity >= 0.1:
                facial_features.append("monolid eyes")
            else:
                facial_features.append("double eyelid eyes")
        
        # æ ‡å‡†é¼»å‹åˆ†ç±»
        if params.get('nose_lift', 0) > 0:
            intensity = params['nose_lift']
            if intensity >= 0.6:
                facial_features.append("aquiline nose")
            elif intensity >= 0.4:
                facial_features.append("straight nose")
            elif intensity >= 0.3:
                facial_features.append("Roman nose")
            elif intensity >= 0.2:
                facial_features.append("snub nose")
            else:
                facial_features.append("button nose")
        
        # æ ‡å‡†å”‡å‹åˆ†ç±»
        if params.get('mouth_adjust', 0) > 0:
            intensity = params['mouth_adjust']
            if intensity >= 0.4:
                facial_features.append("full lips")
            elif intensity >= 0.3:
                facial_features.append("Cupid's bow lips")
            elif intensity >= 0.2:
                facial_features.append("wide mouth")
            elif intensity >= 0.1:
                facial_features.append("thin lips")
            else:
                facial_features.append("small mouth")
        
        # é¢éƒ¨è½®å»“ç»†èŠ‚æè¿°
        contour_details = []
        total_face_adjustment = params.get('face_slim', 0)
        if total_face_adjustment > 0.5:
            contour_details.extend([
                "prominent cheekbones",
                "defined jawline",
                "angular facial structure"
            ])
        elif total_face_adjustment > 0.3:
            contour_details.extend([
                "visible cheekbones",
                "tapered jaw",
                "structured facial contours"
            ])
        elif total_face_adjustment > 0.1:
            contour_details.extend([
                "soft cheekbones",
                "gentle jaw curve",
                "balanced facial structure"
            ])
        
        # ç¾å­¦æ¯”ä¾‹æè¿°
        aesthetic_terms = [
            "golden ratio facial proportions",
            "symmetrical features",
            "classical facial aesthetics",
            "harmonious facial geometry"
        ]
        
        # çš®è‚¤å’Œè´¨æ„Ÿ
        texture_terms = [
            "natural skin texture",
            "healthy skin tone",
            "realistic skin details",
            "natural skin luminosity"
        ]
        
        # æ‘„å½±æŠ€æœ¯æè¿°
        photography_terms = [
            "professional portrait lighting",
            "natural shadow placement",
            "authentic light reflection",
            "studio quality headshot"
        ]
        
        # ç»„åˆæ‰€æœ‰æè¿°
        all_prompts = []
        all_prompts.extend(base_quality)
        all_prompts.extend(facial_features)
        all_prompts.extend(contour_details[:2])
        all_prompts.extend(aesthetic_terms[:2])
        all_prompts.extend(texture_terms[:2])
        all_prompts.extend(photography_terms[:2])
        
        return ", ".join(all_prompts)
    
    def generate_advanced_negative_prompt(self, params):
        """ç”Ÿæˆé«˜çº§è´Ÿé¢æç¤ºè¯"""
        
        # åŸºç¡€è´Ÿé¢è¯
        base_negative = [
            "blurry", "out of focus", "low quality", "low resolution",
            "pixelated", "jpeg artifacts", "compression artifacts"
        ]
        
        # é¢éƒ¨ç¼ºé™·
        facial_defects = [
            "asymmetrical face", "crooked features", "unnatural proportions",
            "distorted facial features", "malformed face", "weird facial structure",
            "abnormal face shape", "deformed eyes", "uneven eyes"
        ]
        
        # AIç”Ÿæˆç—•è¿¹
        ai_artifacts = [
            "artificial looking", "computer generated appearance",
            "digital art style", "cartoon style", "anime style",
            "painting style", "illustration style", "rendered look",
            "synthetic appearance", "fake looking"
        ]
        
        # çš®è‚¤é—®é¢˜
        skin_issues = [
            "plastic skin", "waxy skin", "unrealistic skin",
            "overly smooth skin", "artificial skin texture",
            "doll-like skin", "overprocessed skin"
        ]
        
        # èº«ä»½å˜åŒ–ç›¸å…³
        identity_issues = [
            "different person", "changed identity", "face swap",
            "different facial structure", "unrecognizable"
        ]
        
        # æ ¹æ®è°ƒæ•´å¼ºåº¦åŠ¨æ€æ·»åŠ 
        dynamic_negative = []
        total_intensity = sum([
            params.get('face_slim', 0),
            params.get('eye_enlarge', 0),
            params.get('nose_lift', 0),
            params.get('mouth_adjust', 0)
        ])
        
        if total_intensity > 1.0:
            dynamic_negative.extend([
                "over-edited", "heavily modified", "unnatural enhancement",
                "excessive editing", "overdone effects"
            ])
        
        # ç»„åˆè´Ÿé¢æç¤ºè¯
        all_negative = []
        all_negative.extend(base_negative)
        all_negative.extend(facial_defects[:6])
        all_negative.extend(ai_artifacts[:5])
        all_negative.extend(skin_issues[:4])
        all_negative.extend(identity_issues)
        all_negative.extend(dynamic_negative)
        
        return ", ".join(all_negative)
    
    def enhance_face_realism_with_codeformer(self, image):
        """ä½¿ç”¨CodeFormerå¢å¼ºäººè„¸çœŸå®æ„Ÿ"""
        if self.codeformer_session is None:
            return image
        
        try:
            # é¢„å¤„ç†
            h, w = image.shape[:2]
            
            # CodeFormeré€šå¸¸éœ€è¦512x512è¾“å…¥
            resized = cv2.resize(image, (512, 512))
            
            # è½¬æ¢ä¸ºRGBå¹¶å½’ä¸€åŒ–
            rgb_image = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)
            input_tensor = rgb_image.astype(np.float32) / 255.0
            
            # è°ƒæ•´ç»´åº¦é¡ºåºï¼šHWC -> CHW
            input_tensor = np.transpose(input_tensor, (2, 0, 1))
            
            # æ·»åŠ batchç»´åº¦
            input_tensor = np.expand_dims(input_tensor, axis=0)
            
            # ONNXæ¨ç†
            w_value = np.array(0.95 , dtype=np.float64)  # ä¿®å¤è´¨é‡æƒé‡ï¼Œ0.5æ˜¯å¹³è¡¡å€¼
            outputs = self.codeformer_session.run(None, {
                'x': input_tensor,  # è¾“å…¥å›¾åƒ
                'w': w_value        # ä¿®å¤æƒé‡
            })
            
            # åå¤„ç†
            output_tensor = outputs[0][0]  # ç§»é™¤batchç»´åº¦
            output_tensor = np.transpose(output_tensor, (1, 2, 0))  # CHW -> HWC
            output_tensor = np.clip(output_tensor * 255, 0, 255).astype(np.uint8)
            
            # è½¬æ¢å›BGR
            result_bgr = cv2.cvtColor(output_tensor, cv2.COLOR_RGB2BGR)
            
            # è°ƒæ•´å›åŸå°ºå¯¸
            result_resized = cv2.resize(result_bgr, (w, h))
            
            return result_resized
            
        except Exception as e:
            print(f"âš ï¸ CodeFormerå¤„ç†å¤±è´¥: {e}")
            return image
    
    def blend_with_original_for_realism(self, original, enhanced, blend_ratio=0.8):
        """ä¸åŸå›¾æ··åˆä»¥ä¿æŒçœŸå®æ„Ÿ"""
        try:
            # ç¡®ä¿å›¾åƒå°ºå¯¸ä¸€è‡´
            if original.shape != enhanced.shape:
                enhanced = cv2.resize(enhanced, (original.shape[1], original.shape[0]))
            
            # åŠ æƒæ··åˆ
            result = cv2.addWeighted(enhanced, blend_ratio, original, 1 - blend_ratio, 0)
            
            return result
            
        except Exception as e:
            print(f"âš ï¸ å›¾åƒæ··åˆå¤±è´¥: {e}")
            return enhanced
    
    def reshape_face(self, image, params):
        """ç¾å½¢å¤„ç†ä¸»å‡½æ•° - è¾“å…¥è¾“å‡ºéƒ½æ˜¯numpyæ•°ç»„(BGRæ ¼å¼)"""
        if self.pipe is None:
            return image
        
        try:
            # å‰ç«¯ä¼ å…¥çš„æ˜¯numpyæ•°ç»„(BGRæ ¼å¼)
            height, width = image.shape[:2]
            
            # æå–å…³é”®ç‚¹
            landmarks = self.extract_landmarks(image)
            if landmarks is None:
                print("âš ï¸ æœªæ£€æµ‹åˆ°äººè„¸å…³é”®ç‚¹")
                return image
            
            # åº”ç”¨é»„é‡‘æ¯”ä¾‹çº¦æŸ
            constrained_params = self.apply_golden_ratio_constraints(landmarks, params)
            
            # è°ƒæ•´å…³é”®ç‚¹
            adjusted_landmarks = landmarks.copy()
            
            if constrained_params.get('face_slim', 0) > 0:
                adjusted_landmarks = self.apply_face_slim_adjustment(adjusted_landmarks, constrained_params['face_slim'])
            
            if constrained_params.get('eye_enlarge', 0) > 0:
                adjusted_landmarks = self.apply_eye_enlargement(adjusted_landmarks, constrained_params['eye_enlarge'])
            
            if constrained_params.get('nose_lift', 0) > 0:
                adjusted_landmarks = self.apply_nose_adjustment(adjusted_landmarks, constrained_params['nose_lift'])
            
            if constrained_params.get('mouth_adjust', 0) > 0:
                adjusted_landmarks = self.apply_mouth_adjustment(adjusted_landmarks, constrained_params['mouth_adjust'])
            
            # åˆ›å»ºæ§åˆ¶å›¾åƒ
            control_image = self.create_landmark_image(adjusted_landmarks, height, width)
            control_pil = Image.fromarray(control_image)
            
            # è½¬æ¢ä¸ºPILç”¨äºControlNet
            input_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
            
            # ç”Ÿæˆé«˜çº§æç¤ºè¯
            positive_prompt = self.generate_advanced_prompt(constrained_params)
            negative_prompt = self.generate_advanced_negative_prompt(constrained_params)
            
            # ControlNetç”Ÿæˆ
            result = self.pipe(
                prompt=positive_prompt,
                negative_prompt=negative_prompt,
                image=input_pil,
                control_image=control_pil,
                strength=0.25,
                num_inference_steps=20,
                guidance_scale=8.0,
                controlnet_conditioning_scale=0.6,
                height=768,
                width=768,
                eta=0.0,
                generator=torch.manual_seed(42)
            ).images[0]
            
            # è½¬æ¢å›numpyæ•°ç»„(BGRæ ¼å¼)è¿”å›ç»™å‰ç«¯
            result_np = np.array(result)
            result_bgr = cv2.cvtColor(result_np, cv2.COLOR_RGB2BGR)
            
            # è°ƒæ•´å›åŸå›¾å°ºå¯¸
            result_resized = cv2.resize(result_bgr, (width, height))
            
            # ä½¿ç”¨CodeFormerå¢å¼ºçœŸå®æ„Ÿ
            # if self.codeformer_session is not None:
            #     print("ğŸ¨ ä½¿ç”¨CodeFormerå¢å¼ºçœŸå®æ„Ÿ...")
            #     realistic_result = self.enhance_face_realism_with_codeformer(result_resized)
                
            #     # ä¸åŸå›¾é€‚åº¦æ··åˆï¼Œä¿æŒä¸€äº›åŸå§‹ç‰¹å¾
            #     final_result = self.blend_with_original_for_realism(
            #         original=image, 
            #         enhanced=realistic_result, 
            #         blend_ratio=0.75  # 75%å¢å¼ºç»“æœï¼Œ25%åŸå›¾
            #     )
                
            #     print("âœ… çœŸå®æ„Ÿå¢å¼ºå®Œæˆ")
            #     return final_result
            # else:
            #     print("âš ï¸ CodeFormerä¸å¯ç”¨ï¼Œè¿”å›åŸå§‹ControlNetç»“æœ")
            return result_resized
            
        except Exception as e:
            print(f"âŒ ControlNetç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return image

def main():
    parser = argparse.ArgumentParser(description='ControlNetäººè„¸ç¾å½¢å·¥å…·')
    parser.add_argument('--input', '-i', required=True, help='è¾“å…¥å›¾ç‰‡')
    parser.add_argument('--output', '-o', required=True, help='è¾“å‡ºå›¾ç‰‡')
    parser.add_argument('--face_slim', type=float, default=0.2, help='ç˜¦è„¸å¼ºåº¦ (0-0.5)')
    parser.add_argument('--eye_enlarge', type=float, default=0.1, help='çœ¼éƒ¨æ”¾å¤§ (0-0.3)')
    parser.add_argument('--nose_lift', type=float, default=0.1, help='é¼»æ¢å¢é«˜ (0-0.3)')
    parser.add_argument('--mouth_adjust', type=float, default=0.05, help='å˜´å‹è°ƒæ•´ (0-0.2)')
    parser.add_argument('--disable_codeformer', action='store_true', help='ç¦ç”¨CodeFormerçœŸå®æ„Ÿå¢å¼º')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.input):
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
        return
    
    # åŠ è½½å›¾ç‰‡
    image = cv2.imread(args.input)
    if image is None:
        print(f"âŒ æ— æ³•åŠ è½½å›¾ç‰‡: {args.input}")
        return
    
    print(f"ğŸ“· å¤„ç†å›¾ç‰‡: {image.shape}")
    
    # åˆ›å»ºç¾å½¢å™¨
    reshaper = ControlNetFaceReshaper()
    
    # å¦‚æœç”¨æˆ·ç¦ç”¨CodeFormer
    if args.disable_codeformer:
        reshaper.codeformer_session = None
        print("âš ï¸ ç”¨æˆ·ç¦ç”¨äº†CodeFormerçœŸå®æ„Ÿå¢å¼º")
    
    # è®¾ç½®å‚æ•°
    params = {
        'face_slim': max(0, min(0.5, args.face_slim)),
        'eye_enlarge': max(0, min(0.3, args.eye_enlarge)),
        'nose_lift': max(0, min(0.3, args.nose_lift)),
        'mouth_adjust': max(0, min(0.2, args.mouth_adjust))
    }
    
    print(f"ğŸ¯ ç¾å½¢å‚æ•°: {params}")
    
    # æ‰§è¡Œç¾å½¢
    print("ğŸš€ å¼€å§‹ç¾å½¢å¤„ç†...")
    result = reshaper.reshape_face(image, params)
    
    # ä¿å­˜ç»“æœ
    cv2.imwrite(args.output, result)
    print(f"âœ… ç¾å½¢å®Œæˆ! ç»“æœä¿å­˜åˆ°: {args.output}")

if __name__ == "__main__":
    main()
