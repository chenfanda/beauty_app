#!/usr/bin/env python3
"""
ä¼˜åŒ–çš„5å±‚æ¶æ„3Dä¸‹å·´è°ƒæ•´è„šæœ¬ - chin_adjust_optimized.py
è§£å†³è¾¹ç¼˜æ‰­æ›²é—®é¢˜ï¼Œå®ç°æ›´è‡ªç„¶çš„å˜å½¢æ•ˆæœ
åŸºäº5å±‚ç‚¹ä½æ¶æ„ï¼šç¡¬é”šç‚¹â†’å¼±é”šç‚¹â†’åŠ¨æ€é”šç‚¹â†’è¿‡æ¸¡å±‚â†’ä¸»æ§å˜å½¢ç‚¹
"""

import cv2
import numpy as np
import mediapipe as mp
import argparse
import os
from typing import List, Tuple, Optional

class OptimizedChin3DAdjustment:
    def __init__(self):
        # MediaPipeè®¾ç½®
        self.mp_face_mesh = mp.solutions.face_mesh
        self.face_mesh = self.mp_face_mesh.FaceMesh(
            static_image_mode=True,
            max_num_faces=1,
            refine_landmarks=True,
            min_detection_confidence=0.8,
            min_tracking_confidence=0.8
        )
        
        # ç›¸æœºå‚æ•°
        self.camera_matrix = None
        self.dist_coeffs = None
        
        # ğŸ¯ ä¼˜åŒ–çš„5å±‚æ¶æ„ç‚¹ä½ç³»ç»Ÿ
        # ç¬¬1å±‚ï¼šç¡¬é”šç‚¹ï¼ˆç»å¯¹ç¨³å®šï¼‰- è„¸å‹åŸºå‡†æ¡†æ¶
        self.HARD_ANCHORS = [10, 338, 297]  # é¢å¤´ä¸­ç‚¹å’Œä¸¤ä¾§é¢§éª¨ç‚¹
        
        # ç¬¬2å±‚ï¼šå¼±é”šç‚¹ï¼ˆå¾®è·Ÿéšç¨³å®šï¼‰- ä¸­è„¸åŒºåŸŸé˜²æŠ¤
        self.WEAK_ANCHORS = [117, 123, 147, 346, 352, 376]  # è„¸é¢ŠåŒºåŸŸç¨³å®šç‚¹
        
        # ç¬¬3å±‚ï¼šåŠ¨æ€é”šç‚¹ï¼ˆä»»åŠ¡è‡ªé€‚åº”ï¼‰- æ ¹æ®å˜å½¢ç±»å‹å’Œå§¿æ€åŠ¨æ€å¯ç”¨
        self.DYNAMIC_ANCHORS = [234, 454, 93, 323]  # ä¸‹é¢Œèµ·å§‹ç‚¹
        
        # ç¬¬4å±‚ï¼šè¿‡æ¸¡å±‚ï¼ˆæ¸å˜è·Ÿéšï¼‰- é”šç‚¹åˆ°å˜å½¢ç‚¹çš„å¹³æ»‘è¿‡æ¸¡
        self.TRANSITION_LAYER = [132, 58, 288, 361]  # ä¸‹é¢Œçº¿ä¸­æ®µ
        
        # ç¬¬5å±‚ï¼šä¸»æ§å˜å½¢ç‚¹ï¼ˆå®Œå…¨æ§åˆ¶ï¼‰- æ ¸å¿ƒå˜å½¢åŒºåŸŸ
        self.CHIN_CENTER_SYSTEM = [152, 176, 400, 378]  # 152ä¸»å¯¼ï¼Œå…¶ä»–æ”¯æ’‘
        self.OTHER_CONTOUR = [172, 136, 150, 149, 148, 377, 365, 379, 397, 205, 200, 424, 427]
        
        # æ ‡å‡†3Dé¢éƒ¨æ¨¡å‹å…³é”®ç‚¹
        self.face_model_3d = np.array([
            [0.0, 0.0, 0.0],           # é¼»å°– (1)
            [0.0, -330.0, -65.0],      # ä¸‹å·´ (152)  
            [-225.0, 170.0, -135.0],   # å·¦çœ¼å¤–è§’ (33)
            [225.0, 170.0, -135.0],    # å³çœ¼å¤–è§’ (263)
            [-150.0, -150.0, -125.0],  # å·¦å˜´è§’ (61)
            [150.0, -150.0, -125.0],   # å³å˜´è§’ (291)
        ], dtype=np.float32)
        
        # å¯¹åº”çš„MediaPipeç´¢å¼•
        self.pnp_indices = [1, 152, 33, 263, 61, 291]
    
    def setup_camera(self, image_shape):
        """è®¾ç½®ç›¸æœºå‚æ•°"""
        h, w = image_shape[:2]
        focal_length = w
        center = (w/2, h/2)
        
        self.camera_matrix = np.array([
            [focal_length, 0, center[0]],
            [0, focal_length, center[1]],
            [0, 0, 1]
        ], dtype=np.float32)
        
        self.dist_coeffs = np.zeros((4,1), dtype=np.float32)
    
    def detect_landmarks_3d(self, image):
        """æ£€æµ‹é¢éƒ¨å…³é”®ç‚¹å¹¶è®¡ç®—3Då§¿æ€"""
        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        results = self.face_mesh.process(rgb_image)
        
        if not results.multi_face_landmarks:
            return None, None
        
        landmarks_2d = []
        h, w = image.shape[:2]
        for landmark in results.multi_face_landmarks[0].landmark:
            x = int(landmark.x * w)
            y = int(landmark.y * h)
            landmarks_2d.append([x, y])
        
        landmarks_2d = np.array(landmarks_2d, dtype=np.float32)
        
        if self.camera_matrix is None:
            self.setup_camera(image.shape)
        
        # æå–ç”¨äºPnPçš„å…³é”®ç‚¹
        image_points = []
        for idx in self.pnp_indices:
            if idx < len(landmarks_2d):
                image_points.append(landmarks_2d[idx])
        
        if len(image_points) < 6:
            print("PnPå…³é”®ç‚¹ä¸è¶³")
            return landmarks_2d, None
        
        image_points = np.array(image_points, dtype=np.float32)
        
        # PnPæ±‚è§£3Då§¿æ€
        try:
            success, rotation_vector, translation_vector = cv2.solvePnP(
                self.face_model_3d, image_points, 
                self.camera_matrix, self.dist_coeffs,
                flags=cv2.SOLVEPNP_ITERATIVE
            )
            
            if not success:
                print("PnPæ±‚è§£å¤±è´¥")
                return landmarks_2d, None
            
            return landmarks_2d, (rotation_vector, translation_vector)
            
        except Exception as e:
            print(f"PnPæ±‚è§£å¼‚å¸¸: {e}")
            return landmarks_2d, None
    
    def estimate_face_pose_3d(self, rotation_vector):
        """åŸºäº3Dæ—‹è½¬å‘é‡ä¼°è®¡é¢éƒ¨å§¿æ€"""
        if rotation_vector is None:
            return "frontal"
        
        rotation_matrix, _ = cv2.Rodrigues(rotation_vector)
        sy = np.sqrt(rotation_matrix[0,0] * rotation_matrix[0,0] + rotation_matrix[1,0] * rotation_matrix[1,0])
        
        if sy > 1e-6:
            y = np.arctan2(-rotation_matrix[2,0], sy)
        else:
            y = np.arctan2(-rotation_matrix[2,0], sy)
        
        yaw = np.degrees(y)
        print(f"3Då§¿æ€æ£€æµ‹: Yaw = {yaw:.1f}åº¦")
        
        if abs(yaw) < 15:
            return "frontal"
        elif yaw > 15:
            return "right_profile"
        else:
            return "left_profile"
    
    def get_dynamic_anchors(self, transform_type, pose_3d):
        """æ ¹æ®å˜å½¢ç±»å‹å’Œå§¿æ€åŠ¨æ€é€‰æ‹©é”šç‚¹"""
        base_anchors = self.DYNAMIC_ANCHORS.copy()
        
        print(f"ğŸ”„ åŠ¨æ€é”šç‚¹ç­–ç•¥: {transform_type} + {pose_3d}")
        
        if transform_type == "width":
            # å®½åº¦è°ƒæ•´æ—¶ï¼Œå‡å°‘å¯èƒ½å†²çªçš„ä¾§é¢çº¦æŸ
            selected = [93, 323]  # åªä¿ç•™ä¸Šæ–¹çš„ç‚¹ï¼Œé¿å…å®½åº¦å†²çª
            print(f"   å®½åº¦æ¨¡å¼ï¼šé€‰æ‹©ä¸Šæ–¹é”šç‚¹ {selected}")
            return selected
            
        elif pose_3d == "left_profile":
            # å¤´å‘å·¦è½¬ï¼Œå³ä¾§å¯è§ï¼Œå·¦ä¾§è¢«é®æŒ¡
            selected = [454, 323]  # åªä¿ç•™å³ä¾§å¯è§çš„ç‚¹
            print(f"   å·¦è½¬å¤´åƒï¼šé€‰æ‹©å³ä¾§å¯è§ç‚¹ {selected}")
            return selected
            
        elif pose_3d == "right_profile":
            # å¤´å‘å³è½¬ï¼Œå·¦ä¾§å¯è§ï¼Œå³ä¾§è¢«é®æŒ¡
            selected = [234, 93]   # åªä¿ç•™å·¦ä¾§å¯è§çš„ç‚¹
            print(f"   å³è½¬å¤´åƒï¼šé€‰æ‹©å·¦ä¾§å¯è§ç‚¹ {selected}")
            return selected
        else:
            # æ­£è„¸æ—¶å…¨éƒ¨å¯ç”¨
            print(f"   æ­£è„¸æ¨¡å¼ï¼šå¯ç”¨å…¨éƒ¨é”šç‚¹ {base_anchors}")
            return base_anchors
    
    def create_optimized_chin_mask(self, image_shape, landmarks_2d, pose_3d):
        """åŸºäºå˜å½¢ç‚¹åˆ›å»ºä¼˜åŒ–çš„ä¸‹å·´mask"""
        h, w = image_shape[:2]
        mask = np.zeros((h, w), dtype=np.uint8)
        
        # åŸºäºæ‰€æœ‰å˜å½¢ç›¸å…³çš„ç‚¹åˆ›å»ºmask
        mask_points = []
        
        # åŒ…å«ä¸»æ§å˜å½¢ç‚¹å’Œè½®å»“ç‚¹
        for idx in self.CHIN_CENTER_SYSTEM + self.OTHER_CONTOUR:
            if idx < len(landmarks_2d):
                mask_points.append(landmarks_2d[idx])
        
        if len(mask_points) >= 3:
            mask_points = np.array(mask_points, dtype=np.int32)
            hull = cv2.convexHull(mask_points)
            
            # è®¡ç®—maskåŒºåŸŸçš„å®é™…å°ºå¯¸
            mask_center = np.mean(hull.reshape(-1, 2), axis=0)
            mask_width = np.max(hull[:, :, 0]) - np.min(hull[:, :, 0])
            mask_height = np.max(hull[:, :, 1]) - np.min(hull[:, :, 1])
            
            # ä¼˜åŒ–æ‰©å±•ç­–ç•¥
            if pose_3d == "frontal":
                horizontal_expand = 1.4
                vertical_expand = 1.4
            else:  # ä¾§è„¸
                horizontal_expand = 1.2
                vertical_expand = 1.2
            
            # æ‰©å±•mask
            expanded_hull = []
            for point in hull.reshape(-1, 2):
                dx = point[0] - mask_center[0]
                dy = point[1] - mask_center[1]
                
                new_x = mask_center[0] + dx * horizontal_expand
                new_y = mask_center[1] + dy * vertical_expand
                
                expanded_hull.append([new_x, new_y])
            
            expanded_hull = np.array(expanded_hull, dtype=np.int32)
            cv2.fillPoly(mask, [expanded_hull], 255)
            
            # è¾¹ç•Œä¿æŠ¤
            mouth_y = max(landmarks_2d[61][1], landmarks_2d[291][1]) if 61 < len(landmarks_2d) and 291 < len(landmarks_2d) else h//2
            mask_top = np.min(expanded_hull[:, 1])
            
            if mask_top < mouth_y + 8:
                mask[:int(mouth_y + 8), :] = 0
                print("âš ï¸  Maskä¸Šè¾¹ç•Œä¿æŠ¤")
            
            print(f"âœ… ä¼˜åŒ–Mask: å§¿æ€={pose_3d}, æ‰©å±•={horizontal_expand:.1f}x{vertical_expand:.1f}")
        
        return mask
    
    def apply_optimized_chin_transform(self, image, landmarks_2d, pose_info, transform_type="length", intensity=0.3):
        """åŸºäº5å±‚æ¶æ„çš„ä¼˜åŒ–ä¸‹å·´å˜å½¢ - å•ä¸€ä¸»å¯¼ç‚¹+åè°ƒè·Ÿéšæ–¹æ¡ˆ"""
        if pose_info is None:
            print("3Då§¿æ€ä¿¡æ¯æ— æ•ˆï¼Œä½¿ç”¨2Dæ¨¡å¼")
            return image
        
        rotation_vector, translation_vector = pose_info
        pose_3d = self.estimate_face_pose_3d(rotation_vector)
        
        # 3Då§¿æ€å¼ºåº¦è°ƒæ•´
        if pose_3d != "frontal":
            intensity = intensity * 0.75
            print(f"3Dä¾§è„¸æ£€æµ‹ï¼Œå¼ºåº¦è°ƒæ•´åˆ°: {intensity:.2f}")
        
        # è·å–åŠ¨æ€é”šç‚¹
        active_dynamic_anchors = self.get_dynamic_anchors(transform_type, pose_3d)
        
        # æ„å»º5å±‚æ§åˆ¶ç‚¹ç³»ç»Ÿ
        src_points = []
        dst_points = []
        h, w = image.shape[:2]
        
        print(f"ğŸ¯ 5å±‚æ¶æ„å˜å½¢ç³»ç»Ÿ - {transform_type} (ç»Ÿä¸€ä¸»å¯¼æ¨¡å¼):")
        
        # è·å–152å·ç‚¹ä½œä¸ºä¸»å¯¼å‚è€ƒç‚¹
        chin_center_152 = landmarks_2d[152] if 152 < len(landmarks_2d) else np.array([w//2, h*0.8])
        chin_center_x = chin_center_152[0]
        chin_center_y = chin_center_152[1]
        
        # ğŸ”§ ç¬¬1å±‚ï¼šç¡¬é”šç‚¹ï¼ˆç»å¯¹ç¨³å®šï¼Œ0%å˜å½¢ï¼‰
        hard_count = 0
        for idx in self.HARD_ANCHORS:
            if idx < len(landmarks_2d):
                point = landmarks_2d[idx]
                src_points.append(point)
                dst_points.append(point)  # ç»å¯¹ä¸å˜
                hard_count += 1
        print(f"   ç¬¬1å±‚-ç¡¬é”šç‚¹: {hard_count}ä¸ª (0%å˜å½¢)")
        
        # ğŸ”§ ç¬¬2å±‚ï¼šå¼±é”šç‚¹ï¼ˆå¾®è·Ÿéšï¼Œ5-10%å˜å½¢ï¼‰
        weak_count = 0
        weak_follow_ratio = 0.08  # 8%è·Ÿéšå˜å½¢
        
        # è®¡ç®—ä¸»å˜å½¢æ–¹å‘ï¼ˆç”¨äºå¼±é”šç‚¹è·Ÿéšï¼‰
        main_transform_vector = [0, 0]
        if transform_type == "length":
            main_transform_vector = [0, intensity * 12]  # ä¸»è¦æ˜¯å‚ç›´å˜å½¢
        elif transform_type == "width":
            main_transform_vector = [intensity * 6, 0]   # ä¸»è¦æ˜¯æ°´å¹³å˜å½¢
        elif transform_type == "sharp":
            main_transform_vector = [0, intensity * 8]   # å‘ä¸‹æ”¶ç¼©
        elif transform_type == "round":
            main_transform_vector = [0, -intensity * 6]  # å‘ä¸Šæ‰©å±•
        
        for idx in self.WEAK_ANCHORS:
            if idx < len(landmarks_2d):
                point = landmarks_2d[idx]
                src_points.append(point)
                
                # å¼±è·Ÿéšå˜å½¢
                follow_x = main_transform_vector[0] * weak_follow_ratio
                follow_y = main_transform_vector[1] * weak_follow_ratio
                
                # æ ¹æ®è·ç¦»è°ƒæ•´è·Ÿéšå¼ºåº¦
                distance_to_center = abs(point[0] - chin_center_x)
                distance_factor = min(distance_to_center / (w * 0.3), 1.0)
                follow_x *= (1 - distance_factor * 0.5)
                follow_y *= (1 - distance_factor * 0.5)
                
                new_point = [point[0] + follow_x, point[1] + follow_y]
                dst_points.append(new_point)
                weak_count += 1
        print(f"   ç¬¬2å±‚-å¼±é”šç‚¹: {weak_count}ä¸ª ({weak_follow_ratio*100:.0f}%è·Ÿéš)")
        
        # ğŸ”§ ç¬¬3å±‚ï¼šåŠ¨æ€é”šç‚¹ï¼ˆä»»åŠ¡è‡ªé€‚åº”ï¼‰
        dynamic_count = 0
        for idx in active_dynamic_anchors:
            if idx < len(landmarks_2d):
                point = landmarks_2d[idx]
                src_points.append(point)
                
                # æ ¹æ®å˜å½¢ç±»å‹å†³å®šæ˜¯å¦è·Ÿéš
                if transform_type == "width" and abs(intensity) > 0.2:
                    # å®½åº¦è°ƒæ•´æ—¶ï¼ŒåŠ¨æ€é”šç‚¹å¯ä»¥æœ‰å¾®å°è·Ÿéš
                    is_left_side = point[0] < chin_center_x
                    micro_follow = 1.5 if (intensity > 0) == is_left_side else -1.5
                    new_point = [point[0] + micro_follow, point[1]]
                    dst_points.append(new_point)
                else:
                    # å…¶ä»–æƒ…å†µä¿æŒç¨³å®š
                    dst_points.append(point)
                dynamic_count += 1
        print(f"   ç¬¬3å±‚-åŠ¨æ€é”šç‚¹: {dynamic_count}ä¸ª (è‡ªé€‚åº”)")
        
        # ğŸ”§ ç¬¬4å±‚ï¼šè¿‡æ¸¡å±‚ï¼ˆæ¸å˜è·Ÿéšï¼Œ30-50%å˜å½¢ï¼‰
        transition_count = 0
        transition_ratio = 0.4  # 40%è·Ÿéšä¸»å˜å½¢
        
        for idx in self.TRANSITION_LAYER:
            if idx < len(landmarks_2d):
                point = landmarks_2d[idx]
                src_points.append(point)
                
                # è®¡ç®—ç›¸å¯¹äº152çš„ä½ç½®å…³ç³»
                relative_vector = point - chin_center_152
                distance_from_152 = np.linalg.norm(relative_vector)
                max_distance = w * 0.15
                distance_ratio = min(distance_from_152 / max_distance, 1.0)
                adjusted_ratio = transition_ratio * (1 - distance_ratio * 0.3)
                
                # 3Då§¿æ€è°ƒæ•´
                is_left_side = point[0] < chin_center_x
                if pose_3d == "left_profile" and is_left_side:
                    adjusted_ratio *= 0.7  # ä¸å¯è§ä¾§é™ä½
                elif pose_3d == "right_profile" and not is_left_side:
                    adjusted_ratio *= 0.7  # ä¸å¯è§ä¾§é™ä½
                
                # ğŸ¯ ç»Ÿä¸€ä¸»å¯¼æ¨¡å¼ï¼šéƒ½åŸºäº152çš„ä¸»å¯¼å˜å½¢è¿›è¡Œåè°ƒè·Ÿéš
                if transform_type == "length":
                    # 152ä¸»å¯¼å‘ä¸‹ï¼Œè¿‡æ¸¡å±‚è·Ÿéš+çºµå‘æ‹‰ä¼¸
                    follow_y = intensity * 12 * adjusted_ratio
                    stretch_effect = intensity * 3 * adjusted_ratio  # å¢åŠ æ‹‰ä¼¸æ•ˆæœ
                    new_point = [point[0], point[1] + follow_y + stretch_effect]
                elif transform_type == "width":
                    # 152å¾®è°ƒæ°´å¹³ï¼Œè¿‡æ¸¡å±‚å¾„å‘æ”¶ç¼©/æ‰©å±•
                    if distance_from_152 > 5:  # é¿å…é™¤é›¶
                        radial_direction = relative_vector / distance_from_152
                        radial_move = radial_direction * intensity * 8 * adjusted_ratio
                        new_point = point + radial_move
                    else:
                        new_point = point
                elif transform_type == "sharp":
                    # 152ä¸»å¯¼å‘ä¸‹ï¼Œè¿‡æ¸¡å±‚å‘152æ”¶ç¼©+è·Ÿéšå‘ä¸‹
                    shrink_ratio = 0.3 * adjusted_ratio
                    follow_down_ratio = 0.5 * adjusted_ratio
                    if distance_from_152 > 5:
                        shrink_vector = -relative_vector * shrink_ratio
                        follow_down = [0, intensity * 10 * follow_down_ratio]
                        new_point = point + shrink_vector + follow_down
                    else:
                        new_point = [point[0], point[1] + intensity * 10 * follow_down_ratio]
                elif transform_type == "round":
                    # 152ä¸»å¯¼å‘ä¸Šï¼Œè¿‡æ¸¡å±‚è¿œç¦»152+è·Ÿéšå‘ä¸Š
                    expand_ratio = 0.2 * adjusted_ratio
                    follow_up_ratio = 0.3 * adjusted_ratio
                    if distance_from_152 > 5:
                        expand_vector = relative_vector * expand_ratio
                        follow_up = [0, -intensity * 8 * follow_up_ratio]
                        new_point = point + expand_vector + follow_up
                    else:
                        new_point = [point[0], point[1] - intensity * 8 * follow_up_ratio]
                else:
                    new_point = point
                
                dst_points.append(new_point)
                transition_count += 1
        print(f"   ç¬¬4å±‚-è¿‡æ¸¡å±‚: {transition_count}ä¸ª ({transition_ratio*100:.0f}%åè°ƒè·Ÿéš)")
        
        # ğŸ”§ ç¬¬5å±‚ï¼šä¸»æ§å˜å½¢ç‚¹ï¼ˆå®Œå…¨æ§åˆ¶ï¼Œ100%å˜å½¢ï¼‰- ğŸ¯ç»Ÿä¸€ä¸»å¯¼æ¨¡å¼
        main_count = 0
        
        # ğŸ¯ ç»Ÿä¸€ä¸»å¯¼ç®—æ³•ï¼šæ¯ç§æ¨¡å¼éƒ½æœ‰æ˜ç¡®çš„ä¸»å¯¼ç‚¹å’Œåè°ƒè§„åˆ™
        if transform_type == "length":
            # 152ä¸»å¯¼å‘ä¸‹ + å¢å¼ºçºµå‘æ‹‰ä¼¸åœºæ•ˆåº”
            if 152 < len(landmarks_2d):
                point = landmarks_2d[152]
                src_points.append(point)
                main_move = intensity * 18  # ä¸»å¯¼ç§»åŠ¨å¢å¼º
                new_point = [point[0], point[1] + main_move]
                dst_points.append(new_point)
                main_count += 1
                print(f"     152ä¸»å¯¼å‘ä¸‹: {main_move:.1f}åƒç´ ")
            
            # ä¸­è½´ç³»ç»Ÿåè°ƒè·Ÿéš + æ‹‰ä¼¸åœºæ•ˆåº”
            for idx in [176, 400, 378]:
                if idx < len(landmarks_2d):
                    point = landmarks_2d[idx]
                    src_points.append(point)
                    
                    relative_vector = point - chin_center_152
                    distance_from_152 = np.linalg.norm(relative_vector)
                    follow_ratio = 0.7 * max(0.3, 1 - distance_from_152 / (w * 0.1))
                    
                    # è·Ÿéšå‘ä¸‹ + çºµå‘æ‹‰ä¼¸æ•ˆåº”
                    follow_down = intensity * 18 * follow_ratio
                    stretch_effect = intensity * 5 * follow_ratio  # æ‹‰ä¼¸åœº
                    new_point = [point[0], point[1] + follow_down + stretch_effect]
                    dst_points.append(new_point)
                    main_count += 1
        
        elif transform_type == "width":
            # 152å¾®è°ƒæ°´å¹³ä½ç½®ä½œä¸ºå®½åº¦è§†è§‰é”šç‚¹
            if 152 < len(landmarks_2d):
                point = landmarks_2d[152]
                src_points.append(point)
                # è½»å¾®æ°´å¹³åç§»ä½œä¸ºè§†è§‰å¼•å¯¼
                horizontal_shift = intensity * 4
                new_point = [point[0] + horizontal_shift, point[1]]
                dst_points.append(new_point)
                main_count += 1
                print(f"     152æ°´å¹³å¼•å¯¼: {horizontal_shift:.1f}åƒç´ ")
            
            # ä¸­è½´ç³»ç»Ÿç»Ÿä¸€å¾„å‘ç§»åŠ¨
            for idx in [176, 400, 378]:
                if idx < len(landmarks_2d):
                    point = landmarks_2d[idx]
                    src_points.append(point)
                    
                    relative_vector = point - chin_center_152
                    distance_from_152 = np.linalg.norm(relative_vector)
                    
                    if distance_from_152 > 5:
                        # ç»Ÿä¸€å¾„å‘ç§»åŠ¨ï¼šæ”¶ç¼©æˆ–æ‰©å±•
                        radial_direction = relative_vector / distance_from_152
                        radial_move = radial_direction * intensity * 12
                        new_point = point + radial_move
                    else:
                        new_point = point
                    
                    dst_points.append(new_point)
                    main_count += 1
        
        elif transform_type == "sharp":
            # 152ä¸»å¯¼å‘ä¸‹å°–é”
            if 152 < len(landmarks_2d):
                point = landmarks_2d[152]
                src_points.append(point)
                sharp_down = intensity * 20  # å¢å¼ºä¸»å¯¼æ•ˆæœ
                new_point = [point[0], point[1] + sharp_down]
                dst_points.append(new_point)
                main_count += 1
                print(f"     152å°–é”ä¸»å¯¼: {sharp_down:.1f}åƒç´ ")
            
            # ä¸­è½´ç³»ç»Ÿç»Ÿä¸€å‘152æ”¶ç¼©+è·Ÿéšå‘ä¸‹
            for idx in [176, 400, 378]:
                if idx < len(landmarks_2d):
                    point = landmarks_2d[idx]
                    src_points.append(point)
                    
                    relative_vector = point - chin_center_152
                    distance_from_152 = np.linalg.norm(relative_vector)
                    
                    # æ”¶ç¼©æ¯”ä¾‹å’Œè·Ÿéšæ¯”ä¾‹
                    shrink_ratio = 0.4
                    follow_ratio = 0.6
                    
                    if distance_from_152 > 5:
                        # å‘152æ”¶ç¼©
                        shrink_vector = -relative_vector * shrink_ratio
                        # è·Ÿéšå‘ä¸‹
                        follow_down = [0, intensity * 15 * follow_ratio]
                        new_point = point + shrink_vector + follow_down
                    else:
                        new_point = [point[0], point[1] + intensity * 15 * follow_ratio]
                    
                    dst_points.append(new_point)
                    main_count += 1
        
        elif transform_type == "round":
            # 152ä¸»å¯¼å‘ä¸Šæ”¶ç¼©
            if 152 < len(landmarks_2d):
                point = landmarks_2d[152]
                src_points.append(point)
                round_up = intensity * 15  # ä¸»å¯¼å‘ä¸Š
                new_point = [point[0], point[1] - round_up]
                dst_points.append(new_point)
                main_count += 1
                print(f"     152åœ†æ¶¦ä¸»å¯¼: -{round_up:.1f}åƒç´ ")
            
            # ä¸­è½´ç³»ç»Ÿç»Ÿä¸€è¿œç¦»152+å¾®è·Ÿéšå‘ä¸Š
            for idx in [176, 400, 378]:
                if idx < len(landmarks_2d):
                    point = landmarks_2d[idx]
                    src_points.append(point)
                    
                    relative_vector = point - chin_center_152
                    distance_from_152 = np.linalg.norm(relative_vector)
                    
                    # æ‰©å±•æ¯”ä¾‹å’Œè·Ÿéšæ¯”ä¾‹
                    expand_ratio = 0.25
                    follow_ratio = 0.4
                    
                    if distance_from_152 > 5:
                        # è¿œç¦»152æ‰©å±•
                        expand_vector = relative_vector * expand_ratio
                        # è½»å¾®è·Ÿéšå‘ä¸Š
                        follow_up = [0, -intensity * 8 * follow_ratio]
                        new_point = point + expand_vector + follow_up
                    else:
                        new_point = [point[0], point[1] - intensity * 8 * follow_ratio]
                    
                    dst_points.append(new_point)
                    main_count += 1
        
        # ğŸ¯ å…¶ä»–è½®å»“ç‚¹ï¼šç»Ÿä¸€é‡‡ç”¨åè°ƒè·Ÿéšæ¨¡å¼
        for idx in self.OTHER_CONTOUR:
            if idx < len(landmarks_2d):
                point = landmarks_2d[idx]
                src_points.append(point)
                
                # è®¡ç®—ç›¸å¯¹äº152çš„å…³ç³»
                relative_vector = point - chin_center_152
                distance_from_152 = np.linalg.norm(relative_vector)
                max_distance = w * 0.15
                distance_ratio = min(distance_from_152 / max_distance, 1.0)
                is_left_side = point[0] < chin_center_x
                
                # 3Då§¿æ€è°ƒæ•´
                multiplier = 1.0
                if pose_3d == "left_profile" and is_left_side:
                    multiplier = 0.8
                elif pose_3d == "right_profile" and not is_left_side:
                    multiplier = 0.8
                
                # ğŸ¯ ç»Ÿä¸€åè°ƒè·Ÿéšç®—æ³•
                if transform_type == "length":
                    # è·Ÿéš152å‘ä¸‹ + æ‹‰ä¼¸åœºæ•ˆåº”
                    follow_ratio = 0.5 * (1 - distance_ratio * 0.3) * multiplier
                    follow_down = intensity * 18 * follow_ratio
                    stretch_effect = intensity * 4 * follow_ratio
                    new_point = [point[0], point[1] + follow_down + stretch_effect]
                    
                elif transform_type == "width":
                    # å¾„å‘ç§»åŠ¨è·Ÿéš
                    if distance_from_152 > 5:
                        radial_direction = relative_vector / distance_from_152
                        radial_intensity = intensity * 10 * (1 - distance_ratio * 0.4) * multiplier
                        radial_move = radial_direction * radial_intensity
                        new_point = point + radial_move
                    else:
                        new_point = point
                        
                elif transform_type == "sharp":
                    # å‘152æ”¶ç¼© + è·Ÿéšå‘ä¸‹
                    shrink_ratio = 0.25 * (1 - distance_ratio * 0.3) * multiplier
                    follow_ratio = 0.4 * (1 - distance_ratio * 0.2) * multiplier
                    
                    if distance_from_152 > 5:
                        shrink_vector = -relative_vector * shrink_ratio
                        follow_down = [0, intensity * 15 * follow_ratio]
                        new_point = point + shrink_vector + follow_down
                    else:
                        new_point = [point[0], point[1] + intensity * 15 * follow_ratio]
                        
                elif transform_type == "round":
                    # è¿œç¦»152æ‰©å±• + è½»å¾®å‘ä¸Š
                    expand_ratio = 0.2 * (1 - distance_ratio * 0.3) * multiplier
                    follow_ratio = 0.3 * (1 - distance_ratio * 0.2) * multiplier
                    
                    if distance_from_152 > 5:
                        expand_vector = relative_vector * expand_ratio
                        follow_up = [0, -intensity * 10 * follow_ratio]
                        new_point = point + expand_vector + follow_up
                    else:
                        new_point = [point[0], point[1] - intensity * 10 * follow_ratio]
                else:
                    new_point = point
                
                dst_points.append(new_point)
                main_count += 1
        
        print(f"   ç¬¬5å±‚-ä¸»æ§å˜å½¢: {main_count}ä¸ª (ç»Ÿä¸€ä¸»å¯¼æ¨¡å¼)")
        
        # æ·»åŠ å…¶ä»–ç¨³å®šåŒºåŸŸï¼ˆçœ¼éƒ¨ã€é¼»å­ã€å˜´éƒ¨ï¼‰
        other_stable = [33, 133, 362, 263, 1, 2, 5, 61, 291, 9, 151]
        other_count = 0
        for idx in other_stable:
            if idx < len(landmarks_2d):
                src_points.append(landmarks_2d[idx])
                dst_points.append(landmarks_2d[idx])
                other_count += 1
        print(f"   å…¶ä»–ç¨³å®šåŒºåŸŸ: {other_count}ä¸ª")
        
        # æ·»åŠ è¾¹ç•Œé”šç‚¹
        boundary_margin = 25
        boundary_points = [
            [boundary_margin, boundary_margin], 
            [w//2, boundary_margin], 
            [w-boundary_margin, boundary_margin],
            [boundary_margin, h//2], 
            [w-boundary_margin, h//2],
            [boundary_margin, h-boundary_margin], 
            [w//2, h-boundary_margin], 
            [w-boundary_margin, h-boundary_margin]
        ]
        
        for bp in boundary_points:
            src_points.append(bp)
            dst_points.append(bp)
        
        total_points = len(src_points)
        print(f"   è¾¹ç•Œä¿æŠ¤: 8ä¸ª")
        print(f"   æ€»è®¡æ§åˆ¶ç‚¹: {total_points}ä¸ª")
        
        if total_points < 15:
            print("âŒ æ§åˆ¶ç‚¹ä¸è¶³")
            return image
        
        # æ‰§è¡ŒTPSå˜æ¢
        try:
            src_points = np.array(src_points, dtype=np.float32)
            dst_points = np.array(dst_points, dtype=np.float32)
            
            tps = cv2.createThinPlateSplineShapeTransformer()
            matches = [cv2.DMatch(i, i, 0) for i in range(len(src_points))]
            
            tps.estimateTransformation(
                dst_points.reshape(1, -1, 2), 
                src_points.reshape(1, -1, 2), 
                matches
            )
            
            # TPSå˜å½¢
            transformed = tps.warpImage(image)
            
            if transformed is None:
                print("âŒ TPSå˜æ¢å¤±è´¥")
                return image
            
            # åˆ›å»ºä¼˜åŒ–mask
            chin_mask = self.create_optimized_chin_mask(image.shape, landmarks_2d, pose_3d)
            
            # èåˆ
            mask_3d = cv2.merge([chin_mask, chin_mask, chin_mask]).astype(np.float32) / 255.0
            kernel_size = max(17, min(w, h) // 45)
            if kernel_size % 2 == 0:
                kernel_size += 1
            mask_blurred = cv2.GaussianBlur(mask_3d, (kernel_size, kernel_size), kernel_size//3)
            
            result = image.astype(np.float32) * (1 - mask_blurred) + transformed.astype(np.float32) * mask_blurred
            result = np.clip(result, 0, 255).astype(np.uint8)
            
            print("âœ… ç»Ÿä¸€ä¸»å¯¼æ¨¡å¼å˜å½¢æˆåŠŸ")
            return result
            
        except Exception as e:
            print(f"âŒ ç»Ÿä¸€ä¸»å¯¼å˜å½¢å¼‚å¸¸: {e}")
            return image
    
    def debug_optimized_detection(self, image, save_dir=None):
        """è°ƒè¯•5å±‚æ¶æ„çš„å…³é”®ç‚¹æ£€æµ‹"""
        landmarks_2d, pose_info = self.detect_landmarks_3d(image)
        if landmarks_2d is None:
            print("æœªæ£€æµ‹åˆ°é¢éƒ¨å…³é”®ç‚¹")
            return image
        
        debug_img = image.copy()
        
        # ğŸ¯ æŒ‰5å±‚æ¶æ„ç»˜åˆ¶å…³é”®ç‚¹
        layer_configs = [
            (self.HARD_ANCHORS, (255, 255, 0), "HARD", 10),           # ç¡¬é”šç‚¹-é»„è‰²-å¤§åœ†
            (self.WEAK_ANCHORS, (0, 255, 255), "WEAK", 8),            # å¼±é”šç‚¹-é’è‰²-ä¸­åœ†  
            (self.DYNAMIC_ANCHORS, (255, 0, 255), "DYN", 7),          # åŠ¨æ€é”šç‚¹-ç´«è‰²-ä¸­åœ†
            (self.TRANSITION_LAYER, (0, 255, 0), "TRANS", 6),         # è¿‡æ¸¡å±‚-ç»¿è‰²-å°åœ†
            (self.CHIN_CENTER_SYSTEM, (0, 0, 255), "CENTER", 8),      # ä¸­è½´ç³»ç»Ÿ-çº¢è‰²-ä¸­åœ†
            (self.OTHER_CONTOUR, (255, 0, 0), "CONT", 5),             # å…¶ä»–è½®å»“-è“è‰²-å°åœ†
        ]
        
        for indices, color, prefix, radius in layer_configs:
            for i, idx in enumerate(indices):
                if idx < len(landmarks_2d):
                    point = landmarks_2d[idx].astype(int)
                    
                    # 152ç”¨ç‰¹å¤§åœ†çªå‡ºæ˜¾ç¤º
                    if idx == 152:
                        radius = 12
                    
                    cv2.circle(debug_img, tuple(point), radius, color, -1)
                    cv2.circle(debug_img, tuple(point), radius + 2, color, 2)
                    cv2.putText(debug_img, f"{prefix}{idx}", tuple(point + 12), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
        
        # æ˜¾ç¤ºPnPå…³é”®ç‚¹ï¼ˆç”¨äº3Då§¿æ€æ±‚è§£çš„6ä¸ªç‚¹ï¼‰
        pnp_colors = [(255, 255, 255), (255, 255, 0), (0, 255, 255), (255, 0, 255), (128, 255, 128), (255, 128, 128)]
        for i, idx in enumerate(self.pnp_indices):
            if idx < len(landmarks_2d):
                point = landmarks_2d[idx].astype(int)
                cv2.circle(debug_img, tuple(point), 9, pnp_colors[i], 3)
                cv2.putText(debug_img, f"PnP{idx}", tuple(point + 15), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, pnp_colors[i], 2)
        
        # æ˜¾ç¤º3Då§¿æ€ä¿¡æ¯å’ŒåŠ¨æ€é”šç‚¹é€‰æ‹©
        if pose_info is not None:
            rotation_vector, translation_vector = pose_info
            pose_3d = self.estimate_face_pose_3d(rotation_vector)
            cv2.putText(debug_img, f"3D Pose: {pose_3d}", (10, 30), 
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
            
            # æ˜¾ç¤ºåŠ¨æ€é”šç‚¹é€‰æ‹©ç»“æœ
            active_anchors = self.get_dynamic_anchors("length", pose_3d)  # ç¤ºä¾‹ç”¨length
            cv2.putText(debug_img, f"Active Dynamic: {active_anchors}", (10, 60), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 255), 2)
        
        # æ˜¾ç¤º5å±‚æ¶æ„ç»Ÿè®¡
        stats_text = f"5-Layer: HARD({len(self.HARD_ANCHORS)}) WEAK({len(self.WEAK_ANCHORS)}) DYN({len(self.DYNAMIC_ANCHORS)}) TRANS({len(self.TRANSITION_LAYER)}) MAIN({len(self.CHIN_CENTER_SYSTEM)+len(self.OTHER_CONTOUR)})"
        cv2.putText(debug_img, stats_text, (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
        
        # æ˜¾ç¤ºä¼˜åŒ–mask
        if pose_info is not None:
            pose_3d = self.estimate_face_pose_3d(pose_info[0])
            chin_mask = self.create_optimized_chin_mask(image.shape, landmarks_2d, pose_3d)
            mask_overlay = debug_img.copy()
            mask_overlay[chin_mask > 0] = [128, 0, 128]  # æ·±ç´«è‰²mask
            debug_img = cv2.addWeighted(debug_img, 0.75, mask_overlay, 0.25, 0)
        
        # æ›´æ–°å›¾ä¾‹è¯´æ˜ï¼ˆ5å±‚æ¶æ„ï¼‰
        legend_y = 120
        cv2.putText(debug_img, "YELLOW: Hard Anchors (Absolute Stable)", (10, legend_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)
        cv2.putText(debug_img, "CYAN: Weak Anchors (8% Follow)", (10, legend_y + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
        cv2.putText(debug_img, "MAGENTA: Dynamic Anchors (Task Adaptive)", (10, legend_y + 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 1)
        cv2.putText(debug_img, "GREEN: Transition Layer (40% Follow)", (10, legend_y + 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
        cv2.putText(debug_img, "RED: Main Control (100% Transform)", (10, legend_y + 80), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)
        cv2.putText(debug_img, "BLUE: Other Contour Points", (10, legend_y + 100), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)
        cv2.putText(debug_img, "WHITE: PnP Points for 3D Pose", (10, legend_y + 120), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        cv2.putText(debug_img, "PURPLE: Optimized Transform Mask", (10, legend_y + 140), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (128, 0, 128), 1)
        
        # ç»˜åˆ¶å±‚çº§è¿æ¥çº¿ï¼ˆæ˜¾ç¤º5å±‚å…³ç³»ï¼‰
        if len(self.CHIN_CENTER_SYSTEM) >= 2:
            # è¿æ¥ä¸­è½´ç³»ç»Ÿçš„ç‚¹
            center_points = []
            for idx in self.CHIN_CENTER_SYSTEM:
                if idx < len(landmarks_2d):
                    center_points.append(landmarks_2d[idx].astype(int))
            
            if len(center_points) >= 2:
                for i in range(len(center_points) - 1):
                    cv2.line(debug_img, tuple(center_points[i]), tuple(center_points[i+1]), (0, 0, 255), 2)
        
        # è¿æ¥è¿‡æ¸¡å±‚ç‚¹ï¼ˆæ˜¾ç¤ºæ¸å˜å…³ç³»ï¼‰
        if len(self.TRANSITION_LAYER) >= 2:
            trans_points = []
            for idx in self.TRANSITION_LAYER:
                if idx < len(landmarks_2d):
                    trans_points.append(landmarks_2d[idx].astype(int))
            
            if len(trans_points) >= 2:
                for i in range(len(trans_points) - 1):
                    cv2.line(debug_img, tuple(trans_points[i]), tuple(trans_points[i+1]), (0, 255, 0), 1)
        
        if save_dir:
            os.makedirs(save_dir, exist_ok=True)
            cv2.imwrite(os.path.join(save_dir, "debug_chin_5layer_optimized.png"), debug_img)
            print(f"5å±‚æ¶æ„è°ƒè¯•æ–‡ä»¶ä¿å­˜åˆ°: {save_dir}")
        
        return debug_img
    
    def process_image(self, image, transform_type="length", intensity=0.3, save_debug=False, output_path=None):
        """å¤„ç†å›¾åƒä¸»å‡½æ•°"""
        landmarks_2d, pose_info = self.detect_landmarks_3d(image)
        if landmarks_2d is None:
            print("æœªæ£€æµ‹åˆ°é¢éƒ¨å…³é”®ç‚¹")
            return image
        
        print(f"âœ… æ£€æµ‹åˆ° {len(landmarks_2d)} ä¸ª2Då…³é”®ç‚¹")
        
        if save_debug and output_path:
            debug_dir = os.path.splitext(output_path)[0] + "_debug"
            self.debug_optimized_detection(image, debug_dir)
        
        return self.apply_optimized_chin_transform(image, landmarks_2d, pose_info, transform_type, intensity)

def main():
    parser = argparse.ArgumentParser(description='ä¼˜åŒ–çš„5å±‚æ¶æ„3Dä¸‹å·´è°ƒæ•´å·¥å…· - è§£å†³è¾¹ç¼˜æ‰­æ›²é—®é¢˜')
    parser.add_argument('--input', '-i', required=True, help='è¾“å…¥å›¾ç‰‡è·¯å¾„')
    parser.add_argument('--output', '-o', required=True, help='è¾“å‡ºå›¾ç‰‡è·¯å¾„')
    parser.add_argument('--type', '-t', choices=['length', 'width', 'sharp', 'round'], 
                       default='length', help='è°ƒæ•´ç±»å‹ï¼šlength=é•¿åº¦, width=å®½åº¦, sharp=å°–é”, round=åœ†æ¶¦')
    parser.add_argument('--intensity', type=float, default=0.3, help='è°ƒæ•´å¼ºåº¦ (0.1-0.5)')
    parser.add_argument('--debug', action='store_true', help='5å±‚æ¶æ„è°ƒè¯•æ¨¡å¼')
    parser.add_argument('--save-debug', action='store_true', help='ä¿å­˜è°ƒè¯•æ–‡ä»¶')
    parser.add_argument('--comparison', action='store_true', help='ç”Ÿæˆå¯¹æ¯”å›¾')
    
    args = parser.parse_args()
    
    # åŠ è½½å›¾ç‰‡
    image = cv2.imread(args.input)
    if image is None:
        print(f"æ— æ³•åŠ è½½å›¾ç‰‡: {args.input}")
        return
    
    print(f"å›¾ç‰‡å°ºå¯¸: {image.shape}")
    
    # åˆ›å»ºä¼˜åŒ–å¤„ç†å™¨
    processor = OptimizedChin3DAdjustment()
    
    # è°ƒè¯•æ¨¡å¼
    if args.debug:
        debug_result = processor.debug_optimized_detection(image)
        cv2.imwrite(args.output, debug_result)
        print(f"5å±‚æ¶æ„è°ƒè¯•å›¾ä¿å­˜åˆ°: {args.output}")
        return
    
    # å¼ºåº¦å®‰å…¨æ£€æŸ¥
    if args.intensity > 0.5:
        print(f"è­¦å‘Šï¼šå¼ºåº¦ {args.intensity} å¯èƒ½é€ æˆæ‰­æ›²ï¼Œè‡ªåŠ¨é™åˆ¶åˆ°0.5")
        args.intensity = 0.5
    elif args.intensity < -0.5:
        print(f"è­¦å‘Šï¼šå¼ºåº¦ {args.intensity} å¯èƒ½é€ æˆæ‰­æ›²ï¼Œè‡ªåŠ¨é™åˆ¶åˆ°-0.5")
        args.intensity = -0.5
    
    # å¤„ç†å›¾ç‰‡
    print(f"å¼€å§‹5å±‚æ¶æ„ä¼˜åŒ–å¤„ç† - ç±»å‹: {args.type}, å¼ºåº¦: {args.intensity}")
    result = processor.process_image(image, args.type, args.intensity, args.save_debug, args.output)
    
    # ä¿å­˜ç»“æœ
    cv2.imwrite(args.output, result)
    print(f"å¤„ç†å®Œæˆï¼Œä¿å­˜åˆ°: {args.output}")
    
    # æ£€æŸ¥å˜åŒ–
    diff = cv2.absdiff(image, result)
    total_diff = np.sum(diff)
    changed_pixels = np.sum(diff > 0)
    max_diff = np.max(diff)
    print(f"ğŸ“Š åƒç´ å˜åŒ–ç»Ÿè®¡:")
    print(f"   æ€»å·®å¼‚: {total_diff}")
    print(f"   æœ€å¤§å·®å¼‚: {max_diff}")
    print(f"   å˜åŒ–åƒç´ æ•°: {changed_pixels}")
    
    if total_diff < 1000:
        print("âš ï¸  å˜åŒ–å¾ˆå°ï¼Œå¯èƒ½éœ€è¦ï¼š")
        print("   1. æé«˜ --intensity å‚æ•°")
        print("   2. æ£€æŸ¥å…³é”®ç‚¹æ˜¯å¦æ­£ç¡®æ£€æµ‹")
        print("   3. å°è¯•ä¸åŒçš„å˜å½¢ç±»å‹")
    
    # ç”Ÿæˆå¯¹æ¯”å›¾
    if args.comparison:
        comparison_path = args.output.replace('.', '_5layer_comparison.')
        comparison = np.hstack([image, result])
        cv2.line(comparison, (image.shape[1], 0), (image.shape[1], image.shape[0]), (0, 255, 0), 3)
        
        # æ·»åŠ æ ‡ç­¾
        cv2.putText(comparison, 'Original', (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3)
        cv2.putText(comparison, f'5Layer-{args.type.upper()} {args.intensity}', (image.shape[1] + 20, 50), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3)
        
        cv2.imwrite(comparison_path, comparison)
        print(f"5å±‚æ¶æ„å¯¹æ¯”å›¾ä¿å­˜åˆ°: {comparison_path}")
    
    print("\nâœ… 5å±‚æ¶æ„ä¼˜åŒ–ç‰¹æ€§:")
    print("ğŸ”§ ç¬¬1å±‚: ç¡¬é”šç‚¹ - ç»å¯¹ç¨³å®šè„¸å‹åŸºå‡† [10,338,297]")
    print("ğŸ”§ ç¬¬2å±‚: å¼±é”šç‚¹ - 8%è·Ÿéšé˜²æŠ¤ä¸­è„¸ [117,123,147,346,352,376]")
    print("ğŸ”§ ç¬¬3å±‚: åŠ¨æ€é”šç‚¹ - ä»»åŠ¡è‡ªé€‚åº”é€‰æ‹© [234,454,93,323]")
    print("ğŸ”§ ç¬¬4å±‚: è¿‡æ¸¡å±‚ - 40%æ¸å˜å¹³æ»‘è¿‡æ¸¡ [132,58,288,361]")
    print("ğŸ”§ ç¬¬5å±‚: ä¸»æ§å˜å½¢ - 100%ç²¾ç¡®æ§åˆ¶å˜å½¢")
    print("\nğŸ¯ è§£å†³çš„é—®é¢˜:")
    print("â€¢ âœ… æ¶ˆé™¤è¾¹ç¼˜æ‰­æ›²ï¼šå¼±é”šç‚¹+è¿‡æ¸¡å±‚æä¾›å¹³æ»‘æ¢¯åº¦")
    print("â€¢ âœ… ä¾§è„¸è‡ªé€‚åº”ï¼šåŠ¨æ€é”šç‚¹æ ¹æ®å§¿æ€æ™ºèƒ½é€‰æ‹©")
    print("â€¢ âœ… å˜å½¢è‡ªç„¶åº¦ï¼š5å±‚ç²¾ç»†å¼ºåº¦åˆ†çº§æ§åˆ¶")
    print("â€¢ âœ… è„¸å‹ç¨³å®šæ€§ï¼šç¡¬é”šç‚¹ç¡®ä¿æ•´ä½“ä¸æ¼‚ç§»")
    print("\nğŸ“– ä½¿ç”¨ç¤ºä¾‹:")
    print("â€¢ ä¸‹å·´æ‹‰é•¿: python chin_adjust_optimized.py -i input.jpg -o output.png -t length --intensity 0.3 --comparison")
    print("â€¢ ä¸‹å·´æ”¶çª„: python chin_adjust_optimized.py -i input.jpg -o output.png -t width --intensity -0.2 --comparison")
    print("â€¢ å°–ä¸‹å·´:   python chin_adjust_optimized.py -i input.jpg -o output.png -t sharp --intensity 0.25 --comparison")
    print("â€¢ åœ†ä¸‹å·´:   python chin_adjust_optimized.py -i input.jpg -o output.png -t round --intensity 0.2 --comparison")
    print("â€¢ è°ƒè¯•æ¨¡å¼: python chin_adjust_optimized.py -i input.jpg -o debug.png --debug")
    print("\nâš ï¸  é‡è¦å‚æ•°:")
    print("â€¢ å¼ºåº¦èŒƒå›´: -0.5 åˆ° 0.5")
    print("â€¢ 5å±‚æ¶æ„è‡ªåŠ¨é˜²æ‰­æ›²")
    print("â€¢ 3Då§¿æ€è‡ªé€‚åº”é”šç‚¹")

if __name__ == "__main__":
    main()